"""
For assembling datasets, running ML experiments, and reading/writing static
files for battery prediction given a feature set.
"""
import json
import copy
import hashlib
import os
from typing import List, Union
from functools import reduce

import pandas as pd
from monty.json import MSONable
from monty.serialization import loadfn, dumpfn
from monty.io import zopen

from beep.features.base import BEEPFeaturizer


class BEEPDatasetError(BaseException):
    """ Raise when there is a BEEP-specific problem with a dataset"""
    pass


class BEEPFeatureMatrix(MSONable):
    """
    Create an (n battery cycler files) x (k features) array
    composed of m BEEPFeaturizer objects.
    """

    OP_DELIMITER = "::"

    def __init__(self, beepfeaturizers: List[BEEPFeaturizer]):

        if beepfeaturizers:
            dfs_by_file = {bf.paths.get("structured", "no file found"): [] for bf in beepfeaturizers}
            # big_df_rows = {bf.__class__.__name__: [] for bf in beepfeaturizers}
            unique_features = {}
            for i, bf in enumerate(beepfeaturizers):
                if bf.features is None:
                    raise BEEPDatasetError(f"BEEPFeaturizer {bf} has not created features")
                elif bf.features.shape[0] != 1:
                    raise BEEPDatasetError(f"BEEPFeaturizer {bf} features are not 1-dimensional.")
                else:
                    bfcn = bf.__class__.__name__

                    fname = bf.paths.get("structured", None)
                    if not fname:
                        raise BEEPDatasetError(
                            "Cannot join features automatically as no linking can be done "
                            "based on original structured filename."
                        )

                    # Check for any possible feature collisions using identical featurizers
                    # on identical files

                    # sort params for this featurizer obj by key
                    params = sorted(list(bf.hyperparameters.items()),key=lambda x: x[0])

                    # Prevent identical features from identical input files
                    # create a unique operation string for the application of this featurizer
                    # on a specific file, this op string will be the same as long as
                    # the featurizer class name, hyperparameters, and class are the same

                    param_str = "-".join([f"{k}:{v}" for k, v in params])
                    param_hash = hashlib.sha256(param_str.encode("utf-8")).hexdigest()

                    # Get an id for this featurizer operation (including hyperparameters)
                    # regardless of the file it is applied on
                    feature_op_id = f"{bfcn}{self.OP_DELIMITER}{param_hash}"

                    # Get an id for this featurizer operation (including hyperparameters)
                    # on THIS SPECIFIC file.
                    file_feature_op_id = f"{fname}{self.OP_DELIMITER}{bfcn}{self.OP_DELIMITER}{param_hash}"

                    # Get a unique id for every feature generated by a specific
                    # featurizer on a specific file.
                    this_file_feature_columns_ids = \
                        [
                            f"{file_feature_op_id}{self.OP_DELIMITER}{c}" for c in bf.features.columns
                        ]

                    # Check to make sure there are no duplicates of the exact same feature for
                    # the exact same featurizer with the exact same hyperparameters on the exact
                    # same file.
                    collisions = {c: f for c, f in unique_features.items() if c in this_file_feature_columns_ids}
                    if collisions:
                        raise BEEPDatasetError(
                            f"Multiple features generated with identical classes and identical hyperparameters"
                            f" attempted to be joined into same dataset; \n"
                            f"{bfcn} features collide with existing: \n{collisions}"
                        )
                    for c in this_file_feature_columns_ids:
                        unique_features[c] = bfcn

                    # Create consistent scheme for naming features regardless of file
                    df = copy.deepcopy(bf.features)
                    consistent_column_names = [f"{c}{self.OP_DELIMITER}{feature_op_id}" for c in df.columns]
                    df.columns = consistent_column_names

                    df.index = [fname] * df.shape[0]
                    df.index.rename("filename", inplace=True)
                    dfs_by_file[fname].append(df)

            rows = []
            for filename, dfs in dfs_by_file.items():
                row = pd.concat(dfs, axis=1)
                row = row[sorted(row.columns)]
                rows.append(row)
            self.matrix = pd.concat(rows, axis=0)

        else:
            self.matrix = None

        self.featurizers = beepfeaturizers

    def as_dict(self):
        """Serialize a BEEPDatapath as a dictionary.

        Must not be loaded from legacy.

        Returns:
            (dict): corresponding to dictionary for serialization.

        """

        return {
            "@module": self.__class__.__module__,
            "@class": self.__class__.__name__,

            # Core parts of BEEPFeaturizer
            "featurizers": [f.as_dict() for f in self.featurizers],
            "matrix": self.matrix.to_dict("list"),
        }

    @classmethod
    def from_dict(cls, d):
        """Create a BEEPDatapath object from a dictionary.

        Args:
            d (dict): dictionary represenation.

        Returns:
            beep.structure.ProcessedCyclerRun: deserialized ProcessedCyclerRun.
        """

        # no need for original datapath
        featurizers = [BEEPFeaturizer.from_dict(f) for f in d["featurizers"]]
        return cls(featurizers)

    @classmethod
    def from_json_file(cls, filename):
        """Load a structured run previously saved to file.

        .json.gz files are supported.

        Loads a BEEPFeatureMatrix from json.

        Can be used in combination with files serialized with BEEPFeatures.to_json_file.

        Args:
            filename (str, Pathlike): a json file from a structured run, serialzed with to_json_file.

        Returns:
            None
        """
        return loadfn(d)

    def to_json_file(self, filename):
        """Save a BEEPFeatureMatrix to disk as a json.

        .json.gz files are supported.

        Not named from_json to avoid conflict with MSONable.from_json(*)

        Args:
            filename (str, Pathlike): The filename to save the file to.
            omit_raw (bool): If True, saves only structured (NOT RAW) data.
                More efficient for saving/writing to disk.

        Returns:
            None
        """
        d = self.as_dict()
        dumpfn(d, filename)





class BEEPMLExperiment(MSONable):
    """
    A class for training, predicting, managing, and (de)serializing
    BEEP-based ML battery cycler experiments.

    """

    MODEL_SPACE = {
        "linear": {"regularization": ("lasso", "ridge", "elastic")}

    }

    def __init__(self, dataset, model_name, model_hps):
        self.dataset = dataset


if __name__ == "__main__":
    from monty.serialization import loadfn


    bfs = []
    dirname = "/Users/ardunn/alex/tri/code/beep/beep/CLI_TEST_FILES_FEATURIZATION/output"
    for fname in os.listdir(dirname):
        abs_fname = os.path.join(dirname, fname)
        d = loadfn(abs_fname)
        bfs.append(d)

    bfm = BEEPFeatureMatrix(bfs)

    print(bfm.matrix)
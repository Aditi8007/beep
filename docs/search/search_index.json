{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 BEEP is a set of tools designed to support Battery Evaluation and Early Prediction of cycle life corresponding to the research of the d3batt program and the Toyota Research Institute . BEEP enables parsing and handling of electrochemical battery cycling data via data objects reflecting cycling run data, experimental protocols, featurization, and modeling of cycle life with machine learning. Currently BEEP supports: Arbin Instruments cyclers Novonix Group cyclers MACCOR cyclers BioLogic cyclers Battery Archive data With partial and forthcoming support for: Indigo cyclers Neware cyclers BEEP provides a standardized interface for working with cycler data ranging in scale from a single file on a local laptop to running thousands of cycler files with massive throughput on large computing systems. We are currently looking for experienced python developers to help us improve this package and implement new features. Please contact any of the maintainers for more information. Installation \u00b6 To a base install, do: pip install beep If you want to develop BEEP and run tests, clone the repo via git and use pip (or python setup.py develop ) for an editable install: git clone git@github.com:ToyotaResearchInstitute/BEEP.git cd BEEP pip install -e . [ tests ] Testing \u00b6 Make sure you have installed the required testing packages (see installation). pytest beep How to cite \u00b6 If you use BEEP, please cite this article: P. Herring, C. Balaji Gopal, M. Aykol, J.H. Montoya, A. Anapolsky, P.M. Attia, W. Gent, J.S. Hummelsh\u00f8j, L. Hung, H.-K. Kwon, P. Moore, D. Schweigert, K.A. Severson, S. Suram, Z. Yang, R.D. Braatz, B.D. Storey, SoftwareX 11 (2020) 100506. https://doi.org/10.1016/j.softx.2020.100506","title":"Introduction"},{"location":"#introduction","text":"BEEP is a set of tools designed to support Battery Evaluation and Early Prediction of cycle life corresponding to the research of the d3batt program and the Toyota Research Institute . BEEP enables parsing and handling of electrochemical battery cycling data via data objects reflecting cycling run data, experimental protocols, featurization, and modeling of cycle life with machine learning. Currently BEEP supports: Arbin Instruments cyclers Novonix Group cyclers MACCOR cyclers BioLogic cyclers Battery Archive data With partial and forthcoming support for: Indigo cyclers Neware cyclers BEEP provides a standardized interface for working with cycler data ranging in scale from a single file on a local laptop to running thousands of cycler files with massive throughput on large computing systems. We are currently looking for experienced python developers to help us improve this package and implement new features. Please contact any of the maintainers for more information.","title":"Introduction"},{"location":"#installation","text":"To a base install, do: pip install beep If you want to develop BEEP and run tests, clone the repo via git and use pip (or python setup.py develop ) for an editable install: git clone git@github.com:ToyotaResearchInstitute/BEEP.git cd BEEP pip install -e . [ tests ]","title":"Installation"},{"location":"#testing","text":"Make sure you have installed the required testing packages (see installation). pytest beep","title":"Testing"},{"location":"#how-to-cite","text":"If you use BEEP, please cite this article: P. Herring, C. Balaji Gopal, M. Aykol, J.H. Montoya, A. Anapolsky, P.M. Attia, W. Gent, J.S. Hummelsh\u00f8j, L. Hung, H.-K. Kwon, P. Moore, D. Schweigert, K.A. Severson, S. Suram, Z. Yang, R.D. Braatz, B.D. Storey, SoftwareX 11 (2020) 100506. https://doi.org/10.1016/j.softx.2020.100506","title":"How to cite"},{"location":"contributing/","text":"Contribution guidelines \u00b6 Here are some simple contribution guidelines which you may find useful if you are considering adding features, bug fixes, or other updates to beep . Working within these guidelines will help your pull request be added in a timely fashion! Note this guide is meant primarily for battery scientists with limited experience in software development, particularly in python. In general, our goal here is to implement ideas which can be complex, convoluted, or confusing in the simplest, most concise, and most reusable manner possible. Before you begin \u00b6 Create an issue where new proposals can be discussed before any coding is done. Create a personal fork of the master repo. Download the source code onto your local system, by cloning the repository (or your fork of the repository). Create a branch of this repo on your own fork where all changes will be made Install BEEP with the developer options . Test if your installation worked. pytest beep . Code standards \u00b6 General \u00b6 Don't write boilerplate code : If repeated or similar lines of code can be encapsulated in a function, define a function and reuse the function. Good code should be easily readable on a line by line basis : Generally, we try to keep the total number of lines of code to a minimum. However, each line of code should be readable and as short as possible. If you are stuck choosing between fewer (yet more complex) lines of code and more (yet simpler), usually you should opt for more (yet simpler) code. Don't use highly complex one-liners : Although python allows for list and generator comprehensions in a single line, nesting these comprehensions or making them overly complex makes code very difficult to read. Often, it is easier to read an explicit for loop than to decompose a complex one-line comprehension or boolean condition. Example 1: # Bad - incomprehensible at a glance x = [ t for t in { yi : yj for yi , yj in y_dict . items () if yi in yset } . values () if ( t != 42 and t is not None )] # Better - can at least understand each line at a glance y = {} for yi , yj in y_dict . items (): if yi in yset : y [ yi ] = yj x = [] for t in y . values () if t != 42 and not t : x . append ( t ) Example 2: # Bad - impossible to read if ( t != 42 and t is not None ) or ( array [ 0 ] != 42 and int ( abs ( max ( array )))) not in forbidden_arrays ): do_something () # Better - can at least understand each line at a glance t_valid = t not in ( 42 , None ) array_valid = array [ 0 ] != 42 array_forbidden = int ( abs ( max ( array ))) in forbidden_arrays if t_valid or ( array_valid and not array_forbidden ): do_something () Limit the number of arguments to functions/methods to ~10 : Usually methods or functions with more than 10 arguments are hard to read. Use informative variable names : Use properly formatted, minimal, and informative names for variables, functions, and module names. Example: # Bad - a few examples of uninformative or ambiguous variable names output_value = V / R OutputValue = V / R CurrentValue = V / R # Better - minimal and informative variable names current = V / R current_amps = voltage_volts / resistance_ohms Use builtin libraries whenever possible : The python standard library has many useful libraries. Usually, working with the standard library modules is a reasonably performant, well supported, and highly error tolerant solution. Using external libraries or writing your own alternatives to the standard library's functions are encouraged only when there are significant performance, usability, or code clarity advantages Use informative exceptions : It is much easier to debug code with thoughtfully constructed exceptions (errors) than to reverse-engineer. For example, when an input is outside the expected range, use a raise ValueError(\"Explanation goes here\") . Discuss code changes on Github : Whether you are using a new external dependency or are unsure of how your code should be incorporated into beep, make an issue to discuss with the developers on github! Formatting \u00b6 Adhering to any formatting standard (numpy-style, Google style, etc.) ensures your code can be read more easily. We encourage using the Google python standard style guide The PEP8 style guidelines can also be quite helpful for cleaning up your code. Programmatic tools : We encourage you to check your code with flake8 and pycodestyle ; these are the tools we use for automatically linting new pull requests. Documenting your code \u00b6 Well-documented code ensures others can use and improve upon your code. Inline comments \u00b6 In general, your code should explain itself; it should not need clarification from additional comments. However, it is occasionally necessary to add inline comments for explaining or citing particular methods, especially if those methods are esoteric or not explained elsewhere. Here is an example of a good block comment: # Regression according to Mathiesen's method; constants taken from # this publication: https://doi.org/10.101/12345 my_variable2 = (input1 * input2**2)/some_constant final_answer = constant3 * my_variable2 Docstrings and module comments \u00b6 It is imperative that each function, method, class, and module you write are comprehensively documented. See Section 3.8 of the Google Python style guide for some examples of how to do this. Writing unittests \u00b6 Unittests are a way to check that your code works as intended. Code with new functionality must have tests! Testing your code means writing \"test\" methods which call a desired function/method with some known ground truth inputs and output. If the real output of your function/method matches the expected ground truth output, the test passes. In general, you should write unittests for each new functionality your code performs. Writing unittests at the same time you add a new piece of code (function, method, class) is the easiest way to do this. The fundamental unit of unittesting is a TestCase class. A TestCase class holds a set of related tests. TestCase s go in modules specific for testing - for example, beep.structure.test.test_validate is a testing module. For more information on the syntax for checking the correctness of statements (e.g., self.assertTrue ), see the official python unittesting documentation. Step 1: Find the correct module for adding your tests \u00b6 If your code is in an existing module (e.g., beep.features.intracell_analysis ), your tests will go in that module's test module (e.g., beep.features.tests.test_intracell_analysis ) If your code is in a new module (e.g., beep.structure.my_new_module ), your tests will go either: in a new module in that test directory ( beep.structure.tests.test_my_new_module ) in an existing module which implements tests for code similar to yours (e.g., if you are adding a new cycler datapath, beep.structure.test_cyclerpaths ) If you are not sure where your test code should go, ask a developer in your pull request! Step 2: Create one or more TestCase s \u00b6 A unittest TestCase is a set of methods which will run to test your new code. If your contribution is a small bug fix, you will add testing code inside an existing TestCase class. If your contribution adds new methods to an existing class or new functions to an existing module, your tests will go inside an existing TestCase class. If you are adding a new class, your tests should go in a new TestCase class. If you are adding multiple new classes or a new module, your tests shoudl go in multiple TestCase classes. For example, if you are adding Class1 and Class2 as new classes, you should probably have TestClass1 and TestClass2 as TestCases . Step 3: Create one test method for each method or function in your TestCase s \u00b6 Inside your TestCase class, implement some basic - yet realistic - test cases to ensure your code is working as intended. This is where you will use python's unittesting library's self.assert* methods to check the outputs of code for correctness. If you are adding a class, there should be one testing method for each method of your new class. If you are adding one or more functions, there should be one testing method for each function added. Make sure your test cases work for: Minimal basic inputs with known outputs; ensure these tests are simple yet realistic. Edge cases which likely will be encountered (e.g., a numerical input is maximized, a numerical input is minimized, etc.) Erroneous input throws the expected exceptions using self.assertRaises Unittesting template \u00b6 Here is a template/example of how to write unittests for a new class. The easiest way to get started is to copy+paste this code and replace the code with our own tests. import unittest from beep.my_new_module import MyNewClass class TestMyNewClass ( unittest . TestCase ) def test_my_new_class ( self ): # testing the __init__ behavior of your class, for example inputs = [ \"A\" , 1 , 15.2 ] mnc = MyNewClass ( * inputs ) self . assertTrue ( mnc . some_attr ) self . assertFalse ( mnc . some_attr2 ) def test_compute ( self ): # testing a particular method \"compute\" of your \"MyNewClass\" # class against a bunch of inputs mnc = MyNewClass ( \"B\" , 2 , 21.3 ) arg1 = SomeObject () x = range ( 1 , 5 ) for i in x : self . assertEqual ( mnc . compute ( arg1 , i ), 10 ) self . assertAlmostEqual ( mnc . compute ( arg1 , i , as_float = True ), 9.999999 ) # Make sure compute fails in the way we expect with self . assertRaises ( TypeError ): mnc . compute ( arg1 , \"bad_input\" ) Step 4: Run your tests! \u00b6 While all tests are checked by the Github continuous integration, you should run your tests locally. First, run your tests by themselves. Make sure you have the requirements from requirements-test.txt installed. You can then run your new test cases by adding the following code at the bottom of the test file and running it. if __name__ == \"__main__\" : # replace TestMyNewClass with your TestCase name! unittest . main ( TestMyNewClass ()) If your test passed, congrats! You might also want to make sure your new code did not break any other tests. You can do this from the command line in the base beep directory (the same directory as setup.py ): $: pytest beep --color = yes Some tips for writing tests \u00b6 Find more info for each of these tips on the python unittesting docs. You can define a special setUp method for performing the same setup actions (e.g., clearing or resetting class attributes, creating a common input file) for all of your test methods. This can cut down on your boilerplate code. You can define a special setUpClass class method which will run once before any of the test methods run. You can define a special tearDown method for performing the same post-test actions after each test. This is useful for cleaning up leftover files. This is similar to setUp . You can define a special tearDownClass class method which will run once at the end of the TestCase .","title":"Contribution guidelines"},{"location":"contributing/#contribution-guidelines","text":"Here are some simple contribution guidelines which you may find useful if you are considering adding features, bug fixes, or other updates to beep . Working within these guidelines will help your pull request be added in a timely fashion! Note this guide is meant primarily for battery scientists with limited experience in software development, particularly in python. In general, our goal here is to implement ideas which can be complex, convoluted, or confusing in the simplest, most concise, and most reusable manner possible.","title":"Contribution guidelines"},{"location":"contributing/#before-you-begin","text":"Create an issue where new proposals can be discussed before any coding is done. Create a personal fork of the master repo. Download the source code onto your local system, by cloning the repository (or your fork of the repository). Create a branch of this repo on your own fork where all changes will be made Install BEEP with the developer options . Test if your installation worked. pytest beep .","title":"Before you begin"},{"location":"contributing/#code-standards","text":"","title":"Code standards"},{"location":"contributing/#general","text":"Don't write boilerplate code : If repeated or similar lines of code can be encapsulated in a function, define a function and reuse the function. Good code should be easily readable on a line by line basis : Generally, we try to keep the total number of lines of code to a minimum. However, each line of code should be readable and as short as possible. If you are stuck choosing between fewer (yet more complex) lines of code and more (yet simpler), usually you should opt for more (yet simpler) code. Don't use highly complex one-liners : Although python allows for list and generator comprehensions in a single line, nesting these comprehensions or making them overly complex makes code very difficult to read. Often, it is easier to read an explicit for loop than to decompose a complex one-line comprehension or boolean condition. Example 1: # Bad - incomprehensible at a glance x = [ t for t in { yi : yj for yi , yj in y_dict . items () if yi in yset } . values () if ( t != 42 and t is not None )] # Better - can at least understand each line at a glance y = {} for yi , yj in y_dict . items (): if yi in yset : y [ yi ] = yj x = [] for t in y . values () if t != 42 and not t : x . append ( t ) Example 2: # Bad - impossible to read if ( t != 42 and t is not None ) or ( array [ 0 ] != 42 and int ( abs ( max ( array )))) not in forbidden_arrays ): do_something () # Better - can at least understand each line at a glance t_valid = t not in ( 42 , None ) array_valid = array [ 0 ] != 42 array_forbidden = int ( abs ( max ( array ))) in forbidden_arrays if t_valid or ( array_valid and not array_forbidden ): do_something () Limit the number of arguments to functions/methods to ~10 : Usually methods or functions with more than 10 arguments are hard to read. Use informative variable names : Use properly formatted, minimal, and informative names for variables, functions, and module names. Example: # Bad - a few examples of uninformative or ambiguous variable names output_value = V / R OutputValue = V / R CurrentValue = V / R # Better - minimal and informative variable names current = V / R current_amps = voltage_volts / resistance_ohms Use builtin libraries whenever possible : The python standard library has many useful libraries. Usually, working with the standard library modules is a reasonably performant, well supported, and highly error tolerant solution. Using external libraries or writing your own alternatives to the standard library's functions are encouraged only when there are significant performance, usability, or code clarity advantages Use informative exceptions : It is much easier to debug code with thoughtfully constructed exceptions (errors) than to reverse-engineer. For example, when an input is outside the expected range, use a raise ValueError(\"Explanation goes here\") . Discuss code changes on Github : Whether you are using a new external dependency or are unsure of how your code should be incorporated into beep, make an issue to discuss with the developers on github!","title":"General"},{"location":"contributing/#formatting","text":"Adhering to any formatting standard (numpy-style, Google style, etc.) ensures your code can be read more easily. We encourage using the Google python standard style guide The PEP8 style guidelines can also be quite helpful for cleaning up your code. Programmatic tools : We encourage you to check your code with flake8 and pycodestyle ; these are the tools we use for automatically linting new pull requests.","title":"Formatting"},{"location":"contributing/#documenting-your-code","text":"Well-documented code ensures others can use and improve upon your code.","title":"Documenting your code"},{"location":"contributing/#inline-comments","text":"In general, your code should explain itself; it should not need clarification from additional comments. However, it is occasionally necessary to add inline comments for explaining or citing particular methods, especially if those methods are esoteric or not explained elsewhere. Here is an example of a good block comment: # Regression according to Mathiesen's method; constants taken from # this publication: https://doi.org/10.101/12345 my_variable2 = (input1 * input2**2)/some_constant final_answer = constant3 * my_variable2","title":"Inline comments"},{"location":"contributing/#docstrings-and-module-comments","text":"It is imperative that each function, method, class, and module you write are comprehensively documented. See Section 3.8 of the Google Python style guide for some examples of how to do this.","title":"Docstrings and module comments"},{"location":"contributing/#writing-unittests","text":"Unittests are a way to check that your code works as intended. Code with new functionality must have tests! Testing your code means writing \"test\" methods which call a desired function/method with some known ground truth inputs and output. If the real output of your function/method matches the expected ground truth output, the test passes. In general, you should write unittests for each new functionality your code performs. Writing unittests at the same time you add a new piece of code (function, method, class) is the easiest way to do this. The fundamental unit of unittesting is a TestCase class. A TestCase class holds a set of related tests. TestCase s go in modules specific for testing - for example, beep.structure.test.test_validate is a testing module. For more information on the syntax for checking the correctness of statements (e.g., self.assertTrue ), see the official python unittesting documentation.","title":"Writing unittests"},{"location":"contributing/#step-1-find-the-correct-module-for-adding-your-tests","text":"If your code is in an existing module (e.g., beep.features.intracell_analysis ), your tests will go in that module's test module (e.g., beep.features.tests.test_intracell_analysis ) If your code is in a new module (e.g., beep.structure.my_new_module ), your tests will go either: in a new module in that test directory ( beep.structure.tests.test_my_new_module ) in an existing module which implements tests for code similar to yours (e.g., if you are adding a new cycler datapath, beep.structure.test_cyclerpaths ) If you are not sure where your test code should go, ask a developer in your pull request!","title":"Step 1: Find the correct module for adding your tests"},{"location":"contributing/#step-2-create-one-or-more-testcases","text":"A unittest TestCase is a set of methods which will run to test your new code. If your contribution is a small bug fix, you will add testing code inside an existing TestCase class. If your contribution adds new methods to an existing class or new functions to an existing module, your tests will go inside an existing TestCase class. If you are adding a new class, your tests should go in a new TestCase class. If you are adding multiple new classes or a new module, your tests shoudl go in multiple TestCase classes. For example, if you are adding Class1 and Class2 as new classes, you should probably have TestClass1 and TestClass2 as TestCases .","title":"Step 2: Create one or more TestCases"},{"location":"contributing/#step-3-create-one-test-method-for-each-method-or-function-in-your-testcases","text":"Inside your TestCase class, implement some basic - yet realistic - test cases to ensure your code is working as intended. This is where you will use python's unittesting library's self.assert* methods to check the outputs of code for correctness. If you are adding a class, there should be one testing method for each method of your new class. If you are adding one or more functions, there should be one testing method for each function added. Make sure your test cases work for: Minimal basic inputs with known outputs; ensure these tests are simple yet realistic. Edge cases which likely will be encountered (e.g., a numerical input is maximized, a numerical input is minimized, etc.) Erroneous input throws the expected exceptions using self.assertRaises","title":"Step 3: Create one test method for each method or function in your TestCases"},{"location":"contributing/#unittesting-template","text":"Here is a template/example of how to write unittests for a new class. The easiest way to get started is to copy+paste this code and replace the code with our own tests. import unittest from beep.my_new_module import MyNewClass class TestMyNewClass ( unittest . TestCase ) def test_my_new_class ( self ): # testing the __init__ behavior of your class, for example inputs = [ \"A\" , 1 , 15.2 ] mnc = MyNewClass ( * inputs ) self . assertTrue ( mnc . some_attr ) self . assertFalse ( mnc . some_attr2 ) def test_compute ( self ): # testing a particular method \"compute\" of your \"MyNewClass\" # class against a bunch of inputs mnc = MyNewClass ( \"B\" , 2 , 21.3 ) arg1 = SomeObject () x = range ( 1 , 5 ) for i in x : self . assertEqual ( mnc . compute ( arg1 , i ), 10 ) self . assertAlmostEqual ( mnc . compute ( arg1 , i , as_float = True ), 9.999999 ) # Make sure compute fails in the way we expect with self . assertRaises ( TypeError ): mnc . compute ( arg1 , \"bad_input\" )","title":"Unittesting template"},{"location":"contributing/#step-4-run-your-tests","text":"While all tests are checked by the Github continuous integration, you should run your tests locally. First, run your tests by themselves. Make sure you have the requirements from requirements-test.txt installed. You can then run your new test cases by adding the following code at the bottom of the test file and running it. if __name__ == \"__main__\" : # replace TestMyNewClass with your TestCase name! unittest . main ( TestMyNewClass ()) If your test passed, congrats! You might also want to make sure your new code did not break any other tests. You can do this from the command line in the base beep directory (the same directory as setup.py ): $: pytest beep --color = yes","title":"Step 4: Run your tests!"},{"location":"contributing/#some-tips-for-writing-tests","text":"Find more info for each of these tips on the python unittesting docs. You can define a special setUp method for performing the same setup actions (e.g., clearing or resetting class attributes, creating a common input file) for all of your test methods. This can cut down on your boilerplate code. You can define a special setUpClass class method which will run once before any of the test methods run. You can define a special tearDown method for performing the same post-test actions after each test. This is useful for cleaning up leftover files. This is similar to setUp . You can define a special tearDownClass class method which will run once at the end of the TestCase .","title":"Some tips for writing tests"},{"location":"data/","text":"Cycler data requirements \u00b6 BEEP automatically parses and structures data based on specific outputs from various battery cyclers. The following column headers marked \"required\" are required for downstream processing of each cycler. BEEP currently supports five brands of battery cyclers: Novonix Arbin Maccor Indigo BioLogic Neware Novonix \u00b6 Novonix data files are of the form name_of_file_CHXX.csv containing both tabular cycler data and metadata/protocol steps. There may also be a tabular cycler-produced summary file .csv which can also be ingested and processed with beep. Cycler Data \u00b6 Column name (case insensitive) Required Explanation Unit Data Type Date and Time \u2713 date time string in '%Y-%m-%d %I:%M:%S %p' format str Cycle Number \u2713 index of the cycle int32 Step Type \u2713 integer correspondent to the charge/discharge type of this step int32 Run Time (h) \u2713 total time of the cycler run hours float64 Step Time (h) \u2713 current run time since the beginning of the current step hours float64 Current (A) \u2713 measured value of the present channel current Amp float64 Potential (V) \u2713 measured value of the present channel voltage Volt float64 Capacity (Ah) \u2713 value of the channel capacity Amp-hr float64 Temperature (\u00b0C) temperature of channel \u00b0Celsius float64 Circuit Temperature (\u00b0C) temperature of circuit \u00b0Celsius float64 Energy (Wh) \u2713 computed present energy of cell Watt-hr float64 dVdt (I/h) first order change rate of voltage float64 dIdt (V/h) first order change rate of current float64 Step Number \u2713 step number within cycle int32 Step position int32 Metadata \u00b6 Metadata for Novonix files is contained within the raw data itself. Field name Required Channel Cell Serial Number Description Protocol Mass (g) Capacity (Ah) Area (cm2) DC Offset Voltage (V) Started Version Summary file \u00b6 The summary file is a csv with one row corresponding to the summary of one cycle. No particular column names are required for ingestion. Arbin \u00b6 Arbin data files are of the form name_of_file_CHXX.csv with an associated metadata file name_of_file_CHXX_Metadata.csv Cycler Data \u00b6 Column name (case insensitive) Required Explanation Unit Data Type data_point index of this data point int32 test_time time of data point relative to start seconds float32 datetime \u2713 time of data point relative to epoch time seconds float32 step_time elapsed time counted from the starting point of present active step seconds float32 step_index \u2713 currently running step number in the active schedule int16 cycle_index \u2713 currently active test cycle number int32 current \u2713 measured value of present channel current Amps float32 voltage \u2713 measured value of present channel voltage Volts float32 charge_capacity \u2713 cumulative value of present channel charge capacity Amp-hr float64 discharge_capacity \u2713 cumulative value of present channel discharge capacity Amp-hr float64 charge_energy \u2713 cumulative value of present channel charge energy Watt-hr float64 discharge_energy \u2713 cumulative value of present channel discharge energy Watt-hr float64 dv/dt the first-order change rate of voltage Volts/seconds float32 internal_resistance calculated internal resistance Ohms float32 temperature cell temperature \u00b0Celsius float32 Metadata \u00b6 Field name Required test_id device_id iv_ch_id first_start_datetime schedule_file_name item_id resumed_times last_end_datetime databases grade_id has_aux has_special schedule_version log_aux_data_flag log_special_data_flag rowstate canconfig_filename m_ncanconfigmd5 value value2 Maccor \u00b6 Maccor files are single tabular text files matching the regex pattern \".*\\\\d{5,6}.*\\\\d{3}\" . Column name (case insensitive) Required Explanation Unit Data Type rec# \u2713 data point number (index) int32 cyc# \u2713 cycle number int32 step \u2713 step number int16 test (sec) \u2713 total time elapsed seconds float32 step (sec) \u2713 time within this step seconds float32 amp-hr \u2713 charge capacity Amp-hr float64 watt-hr \u2713 charge energy Watt-hr float64 amps \u2713 channel current Amps float32 volts \u2713 channel voltage Volts float32 state \u2713 charging/discharging/etc. state of the battery category es \u2713 category dpt time \u2713 date and time of data point Date-Time str acimp/ohms \u2713 AC impedance of circuit Ohm float32 dcir/ohms \u2713 DC internal resistance Ohm float32 wf chg cap \u2713 charge capacity (based on waveform, if available) Amp-hh float32 wf dis cap \u2713 discharge capacity (based on waveform, if available) Amp-hr float32 wf chg e \u2713 charge energy (based on waveform, if available) Watt-hr float32 wf dis e \u2713 discharge energy (based on waveform, if available) Watt-hr float32 range \u2713 uint8 var1 \u2713 float16 var2 \u2713 float16 var3 \u2713 float16 var4 \u2713 float16 var5 \u2713 float16 var6 \u2713 float16 var7 \u2713 float16 var8 \u2713 float16 var9 \u2713 float16 var10 \u2713 float16 var11 \u2713 float16 var12 \u2713 float16 var13 \u2713 float16 var14 \u2713 float16 var15 \u2713 float16 Indigo \u00b6 Indigo files are single hierarchical data files ( *.h5 ) with the mandatory group store field \"time_series_data\" . Column name (case insensitive) Required Explanation Unit Data Type cell_coulomb_count_c \u2713 instantaneous cell charge Coulombs cell_current_a \u2713 A cell_energy_j \u2713 cell energy Joules cell_id \u2713 identifier of the cell cell_power_w instantaneous cell power Watts cell_temperature_c temperature of the cell \u00b0Celsius cell_voltage_v \u2713 voltage of the cell Volts cycle_count \u2713 index of the cycle experiment_count index of the experiment experiment_type half_cycle_count \u2713 system_time_us \u2713 test time of data point relative to epoch microseconds time_s time elapsed since test beginning seconds BioLogic \u00b6 BioLogic files are ASCII text files of the form *.mpt with matching *.mpl log/metadata files. BioLogic cycler data is currently only supported for structuring operations (e.g., ingestion via BioLogicDatapath analysis) and is not supported for downstream processing. Column name Required Explanation Unit Data Type cycle number \u2713 index of this cycle int half cycle \u2713 int Ecell/V \u2713 cell potential Volts float I/mA \u2713 cell current mAmps float Q discharge/mA.h \u2713 discharge capacity mAmp-hr float Q charge/mA.h \u2713 charge capacty mAmp-hr float Energy charge/W.h \u2713 charge energy Watt-hr float Energy discharge/W.h \u2713 discharge energy Watt-hr float Various other fields in BioLogic data or metadata files are not required. Neware \u00b6 Neware files are singular *.csv files. Note: Neware files use non-standard csv formatting; some fields may require further processing or structuring before input to beep . Column name Required Explanation Unit Data Type Record ID \u2713 index of this data point int32 Realtime \u2713 date-time format for this point Time(h:min:s.ms) \u2713 recorded time for this point seconds float32 Step ID \u2713 index of this step int16 Cycle ID \u2713 index of this cycle int32 Current(mA) \u2713 cell current mAmps float32 Voltage(V) \u2713 cell voltage Volts float32 Capacitance_Chg(mAh) \u2713 charge capacity mAmp-hr float64 Capacitance_DChg(mAh) \u2713 discharge capacity mAmp-hr float64 Engy_Chg(mWh) \u2713 charge energy mWatt-hr float64 Engy_DChg(mWh) \u2713 discharge energy mWatt-hr float64 DCIR(O) \u2713 DC internal resistance float32 Capacity(mAh) \u2713 mAmp-hr Capacity Density(mAh/g) \u2713 mAmp-hr/gram Energy(mWh) \u2713 mWatt-hr CmpEng(mWh/g) \u2713 mWatt-hr/gram Min-T(C) \u2713 mimumum cell temperature \u00b0Celsius Max-T(C) \u2713 max cell temperature \u00b0Celsius Avg-T(C) \u2713 average cell temperature \u00b0Celsius Power(mW) \u2713 instantaneous power mWatt dQ/dV(mAh/V) \u2713 differential capacity mAmp-hr/Volt dQm/dV(mAh/V.g) \u2713 differential capacity density mAmp-hr/Volt-gram Temperature(C) \u2713 temperature (alternate sensor) \u00b0Celsius float32 Battery Archive \u00b6 Battery Archive files are singular csvs matching the file pattern *timeseries*.csv . Column name (case insensitive) Required Explanation Unit Data Type Cycle_Index \u2713 index of this cycle int Current (A) \u2713 cell current Amps float Voltage (V) \u2713 cell potential Volts float Charge_Capacity (Ah) \u2713 charge capacity amp-hr float Discharge_Capacity (Ah) \u2713 discharge capacity amp-hr float Charge_Energy (Wh) \u2713 charge energy watt-hr float Discharge_Energy (Wh) \u2713 discharge energy watt-hr float Cell_Temperature (C) \u2713 temperature of the cell \u00b0Celsius float Environmental_Temperature (C) environmental temperature \u00b0Celsius float Test_Time (s) \u2713 test time seconds float Date_Time \u2713 datetime string, in '%Y-%m-%d %H:%M:%S.%f' format str No metadata ingestion is supported for Battery Archive files at this time.","title":"Cycler data requirements"},{"location":"data/#cycler-data-requirements","text":"BEEP automatically parses and structures data based on specific outputs from various battery cyclers. The following column headers marked \"required\" are required for downstream processing of each cycler. BEEP currently supports five brands of battery cyclers: Novonix Arbin Maccor Indigo BioLogic Neware","title":"Cycler data requirements"},{"location":"data/#novonix","text":"Novonix data files are of the form name_of_file_CHXX.csv containing both tabular cycler data and metadata/protocol steps. There may also be a tabular cycler-produced summary file .csv which can also be ingested and processed with beep.","title":"Novonix"},{"location":"data/#cycler-data","text":"Column name (case insensitive) Required Explanation Unit Data Type Date and Time \u2713 date time string in '%Y-%m-%d %I:%M:%S %p' format str Cycle Number \u2713 index of the cycle int32 Step Type \u2713 integer correspondent to the charge/discharge type of this step int32 Run Time (h) \u2713 total time of the cycler run hours float64 Step Time (h) \u2713 current run time since the beginning of the current step hours float64 Current (A) \u2713 measured value of the present channel current Amp float64 Potential (V) \u2713 measured value of the present channel voltage Volt float64 Capacity (Ah) \u2713 value of the channel capacity Amp-hr float64 Temperature (\u00b0C) temperature of channel \u00b0Celsius float64 Circuit Temperature (\u00b0C) temperature of circuit \u00b0Celsius float64 Energy (Wh) \u2713 computed present energy of cell Watt-hr float64 dVdt (I/h) first order change rate of voltage float64 dIdt (V/h) first order change rate of current float64 Step Number \u2713 step number within cycle int32 Step position int32","title":"Cycler Data"},{"location":"data/#metadata","text":"Metadata for Novonix files is contained within the raw data itself. Field name Required Channel Cell Serial Number Description Protocol Mass (g) Capacity (Ah) Area (cm2) DC Offset Voltage (V) Started Version","title":"Metadata"},{"location":"data/#summary-file","text":"The summary file is a csv with one row corresponding to the summary of one cycle. No particular column names are required for ingestion.","title":"Summary file"},{"location":"data/#arbin","text":"Arbin data files are of the form name_of_file_CHXX.csv with an associated metadata file name_of_file_CHXX_Metadata.csv","title":"Arbin"},{"location":"data/#cycler-data_1","text":"Column name (case insensitive) Required Explanation Unit Data Type data_point index of this data point int32 test_time time of data point relative to start seconds float32 datetime \u2713 time of data point relative to epoch time seconds float32 step_time elapsed time counted from the starting point of present active step seconds float32 step_index \u2713 currently running step number in the active schedule int16 cycle_index \u2713 currently active test cycle number int32 current \u2713 measured value of present channel current Amps float32 voltage \u2713 measured value of present channel voltage Volts float32 charge_capacity \u2713 cumulative value of present channel charge capacity Amp-hr float64 discharge_capacity \u2713 cumulative value of present channel discharge capacity Amp-hr float64 charge_energy \u2713 cumulative value of present channel charge energy Watt-hr float64 discharge_energy \u2713 cumulative value of present channel discharge energy Watt-hr float64 dv/dt the first-order change rate of voltage Volts/seconds float32 internal_resistance calculated internal resistance Ohms float32 temperature cell temperature \u00b0Celsius float32","title":"Cycler Data"},{"location":"data/#metadata_1","text":"Field name Required test_id device_id iv_ch_id first_start_datetime schedule_file_name item_id resumed_times last_end_datetime databases grade_id has_aux has_special schedule_version log_aux_data_flag log_special_data_flag rowstate canconfig_filename m_ncanconfigmd5 value value2","title":"Metadata"},{"location":"data/#maccor","text":"Maccor files are single tabular text files matching the regex pattern \".*\\\\d{5,6}.*\\\\d{3}\" . Column name (case insensitive) Required Explanation Unit Data Type rec# \u2713 data point number (index) int32 cyc# \u2713 cycle number int32 step \u2713 step number int16 test (sec) \u2713 total time elapsed seconds float32 step (sec) \u2713 time within this step seconds float32 amp-hr \u2713 charge capacity Amp-hr float64 watt-hr \u2713 charge energy Watt-hr float64 amps \u2713 channel current Amps float32 volts \u2713 channel voltage Volts float32 state \u2713 charging/discharging/etc. state of the battery category es \u2713 category dpt time \u2713 date and time of data point Date-Time str acimp/ohms \u2713 AC impedance of circuit Ohm float32 dcir/ohms \u2713 DC internal resistance Ohm float32 wf chg cap \u2713 charge capacity (based on waveform, if available) Amp-hh float32 wf dis cap \u2713 discharge capacity (based on waveform, if available) Amp-hr float32 wf chg e \u2713 charge energy (based on waveform, if available) Watt-hr float32 wf dis e \u2713 discharge energy (based on waveform, if available) Watt-hr float32 range \u2713 uint8 var1 \u2713 float16 var2 \u2713 float16 var3 \u2713 float16 var4 \u2713 float16 var5 \u2713 float16 var6 \u2713 float16 var7 \u2713 float16 var8 \u2713 float16 var9 \u2713 float16 var10 \u2713 float16 var11 \u2713 float16 var12 \u2713 float16 var13 \u2713 float16 var14 \u2713 float16 var15 \u2713 float16","title":"Maccor"},{"location":"data/#indigo","text":"Indigo files are single hierarchical data files ( *.h5 ) with the mandatory group store field \"time_series_data\" . Column name (case insensitive) Required Explanation Unit Data Type cell_coulomb_count_c \u2713 instantaneous cell charge Coulombs cell_current_a \u2713 A cell_energy_j \u2713 cell energy Joules cell_id \u2713 identifier of the cell cell_power_w instantaneous cell power Watts cell_temperature_c temperature of the cell \u00b0Celsius cell_voltage_v \u2713 voltage of the cell Volts cycle_count \u2713 index of the cycle experiment_count index of the experiment experiment_type half_cycle_count \u2713 system_time_us \u2713 test time of data point relative to epoch microseconds time_s time elapsed since test beginning seconds","title":"Indigo"},{"location":"data/#biologic","text":"BioLogic files are ASCII text files of the form *.mpt with matching *.mpl log/metadata files. BioLogic cycler data is currently only supported for structuring operations (e.g., ingestion via BioLogicDatapath analysis) and is not supported for downstream processing. Column name Required Explanation Unit Data Type cycle number \u2713 index of this cycle int half cycle \u2713 int Ecell/V \u2713 cell potential Volts float I/mA \u2713 cell current mAmps float Q discharge/mA.h \u2713 discharge capacity mAmp-hr float Q charge/mA.h \u2713 charge capacty mAmp-hr float Energy charge/W.h \u2713 charge energy Watt-hr float Energy discharge/W.h \u2713 discharge energy Watt-hr float Various other fields in BioLogic data or metadata files are not required.","title":"BioLogic"},{"location":"data/#neware","text":"Neware files are singular *.csv files. Note: Neware files use non-standard csv formatting; some fields may require further processing or structuring before input to beep . Column name Required Explanation Unit Data Type Record ID \u2713 index of this data point int32 Realtime \u2713 date-time format for this point Time(h:min:s.ms) \u2713 recorded time for this point seconds float32 Step ID \u2713 index of this step int16 Cycle ID \u2713 index of this cycle int32 Current(mA) \u2713 cell current mAmps float32 Voltage(V) \u2713 cell voltage Volts float32 Capacitance_Chg(mAh) \u2713 charge capacity mAmp-hr float64 Capacitance_DChg(mAh) \u2713 discharge capacity mAmp-hr float64 Engy_Chg(mWh) \u2713 charge energy mWatt-hr float64 Engy_DChg(mWh) \u2713 discharge energy mWatt-hr float64 DCIR(O) \u2713 DC internal resistance float32 Capacity(mAh) \u2713 mAmp-hr Capacity Density(mAh/g) \u2713 mAmp-hr/gram Energy(mWh) \u2713 mWatt-hr CmpEng(mWh/g) \u2713 mWatt-hr/gram Min-T(C) \u2713 mimumum cell temperature \u00b0Celsius Max-T(C) \u2713 max cell temperature \u00b0Celsius Avg-T(C) \u2713 average cell temperature \u00b0Celsius Power(mW) \u2713 instantaneous power mWatt dQ/dV(mAh/V) \u2713 differential capacity mAmp-hr/Volt dQm/dV(mAh/V.g) \u2713 differential capacity density mAmp-hr/Volt-gram Temperature(C) \u2713 temperature (alternate sensor) \u00b0Celsius float32","title":"Neware"},{"location":"data/#battery-archive","text":"Battery Archive files are singular csvs matching the file pattern *timeseries*.csv . Column name (case insensitive) Required Explanation Unit Data Type Cycle_Index \u2713 index of this cycle int Current (A) \u2713 cell current Amps float Voltage (V) \u2713 cell potential Volts float Charge_Capacity (Ah) \u2713 charge capacity amp-hr float Discharge_Capacity (Ah) \u2713 discharge capacity amp-hr float Charge_Energy (Wh) \u2713 charge energy watt-hr float Discharge_Energy (Wh) \u2713 discharge energy watt-hr float Cell_Temperature (C) \u2713 temperature of the cell \u00b0Celsius float Environmental_Temperature (C) environmental temperature \u00b0Celsius float Test_Time (s) \u2713 test time seconds float Date_Time \u2713 datetime string, in '%Y-%m-%d %H:%M:%S.%f' format str No metadata ingestion is supported for Battery Archive files at this time.","title":"Battery Archive"},{"location":"Command%20Line%20Interface/1%20-%20overview/","text":"Overview \u00b6 The beep base command specifies options for creating metadata and logging for all subcommands. This page is a general overview of options that are common among any beep subcommand. You can expect options on this page to pertain to basically any beep CLI operation's inputs, outputs, and file formats. Basics \u00b6 The BEEP CLI can be used like: $: beep <options> <subcommand> Options for the base beep command are specified before the subcommand. All beep subcommands take at least one file as input and return one or more files as output. Beep has six subcommands: beep structure : Parse, interpolate, clean, and standardize a wide range of battery cycler output files. beep featurize : Generate features for learning from structured files. beep train : Train a machine learning model based on features. beep predict : Predict battery degradation based on learning features and a previously trained model. beep protocol : Generate cycler protocol from pre-made templates for a wide range of cyclers. beep inspect : Visually inspect and debug beep files on disk. For more info on any command or the base command, simply pass --help as an option. The help dialog for beep base command looks like: $: beep --help Usage: beep [ OPTIONS ] COMMAND [ ARGS ] ... Base BEEP command. Options: -l, --log-file FILE File to log formatted json to. Log will still be output in human readable form to stdout, but if --log-file is specified, it will be additionally logged to a jsonl ( json-lines ) formatted file. -r, --run-id INTEGER An integer run_id which can be optionally assigned to this run. It will be output in the metadata status json for any subcommand if the status json is enabled. -t, --tags TEXT Add optional tags to the status json metadata. Can be later used forlarge-scale queries on database data about sets of BEEP runs. Example: 'experiments_for_kristin' . -s, --output-status-json FILE File to output with JSON info about the states of files which have had any beep subcommand operationrun on them ( e.g., structuring ) . Contains comprehensiveinfo about the success of the operation for all files.1 status json = 1 operation. --halt-on-error Set to halt BEEP if critical featurization errors are encountered on any file with any featurizer. Otherwise, logs critical errors to the status json. --help Show this message and exit. Commands: featurize Featurize one or more files. predict Run a previously trained model to predict degradation... protocol Generate protocol for battery cyclers from a csv file input. structure Structure and/or validate one or more files. train Train a machine learning model using all available data and... Output streams \u00b6 The beep base command options are used for specifying if and where to output the metadata and status of any CLI operation. Human-readable output will always be logged to stdout, for example: 2021-09-21 16:14:43 INFO Structuring 1 files 2021-09-21 16:14:43 DEBUG Hashing file '/beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv' to MD5 2021-09-21 16:14:43 INFO File 1 of 1: Reading raw file /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv from disk... 2021-09-21 16:14:44 INFO File 1 of 1: Validating: /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv according to schema file '/beep/beep/validation_schemas/schema-arbin-lfp.yaml' 2021-09-21 16:14:44 INFO File 1 of 1: Validated: /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv 2021-09-21 16:14:44 INFO File 1 of 1: Structuring: Read from /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv 2021-09-21 16:14:44 INFO Beginning structuring along charge axis 'charge_capacity' and discharge axis 'voltage'. 2021-09-21 16:15:21 INFO File 1 of 1: Structured: Written to /beep/beep/CLI_TEST_FILES_FEATURIZATION/tmp.json.gz 2021-09-21 16:15:21 INFO Structuring report: 2021-09-21 16:15:21 INFO Succeeded: 1/1 2021-09-21 16:15:21 INFO Invalid: 0/1 2021-09-21 16:15:21 INFO Failed: 0/1 But other output streams are also available: --log-file \u00b6 Machine-readable json log file to write. If not specified, no log file will be created. Example: {\"time\": \"2021-09-21 16:13:48,938\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Structuring 1 files\"} {\"time\": \"2021-09-21 16:13:48,939\", \"level\": \"DEBUG\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Hashing file '/beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json' to MD5\"} {\"time\": \"2021-09-21 16:13:49,228\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"File 1 of 1: Reading raw file /beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json from disk...\"} {\"time\": \"2021-09-21 16:13:50,390\", \"level\": \"ERROR\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"File 1 of 1: Failed/invalid: (EmptyDataError): /beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Structuring report:\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" Succeeded: 0/1\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" Invalid: 1/1\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" - /beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" Failed: 0/1\"} {\"time\": \"2021-09-21 16:14:43,291\", \"level\": \"INFO\", \"process\": \"67264\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Structuring 1 files\"} {\"time\": \"2021-09-21 16:14:43,291\", \"level\": \"DEBUG\", \"process\": \"67264\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Hashing file '/beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv' to MD5\"} {\"time\": \"2021-09-21 16:14:43,385\", \"level\": \"INFO\", \"process\": \"67264\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"File 1 of 1: Reading raw file /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv from disk.. --output-status-json \u00b6 JSON file to write containing comprehensive structured metadata about any operation and all of its sub-operations. If not specified, no status json will be written. Example: { \"op_type\": \"featurize\", \"feature_matrix\": { \"created\": true, \"traceback\": null, \"output\": \"/beep/beep/CLI_TEST_FILES_FEATURIZATION/features.json.gz\" }, \"files\": { \"/beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json\": { \"walltime\": 8.546396970748901, \"output\": null, \"processed_md5_chksum\": \"5848d8598584e45addfa8129bb078d95\", \"featurizers\": { \"HPPCResistanceVoltageFeatures\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 1.2403650283813477, \"traceback\": null, \"subop_md5_chksum\": null }, \"DeltaQFastCharge\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 0.05008506774902344, \"traceback\": null, \"subop_md5_chksum\": null }, \"DiagnosticSummaryStats\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 0.19507122039794922, \"traceback\": null, \"subop_md5_chksum\": null }, \"CycleSummaryStats\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 0.013413190841674805, \"traceback\": null, \"subop_md5_chksum\": null } } }, ... \"metadata\": { \"beep_verison\": \"2021.8.2.15\", \"op_datetime_utc\": \"2021-09-04 00:40:12\", \"run_id\": null, \"tags\": [] } } Any one beep command (e.g., beep structure * ), regardless of how many files it intakes or generates, will always produce exactly one status json if --output-status-json is defined. Fault-tolerance \u00b6 --halt-on-error \u00b6 By default, BEEP runs all operations in a fault-tolerant manner. This means that if the CLI command syntax is valid, but internally an operation or sub-operation fails, the process will return successful. To disable this behavior, which will cause any error in any operation or sub-operation to fail the entire command use the --halt-on-error flag. Extra metadata and run-tracking with status json \u00b6 Running many experiments can make it difficult to keep track of which input and output files correspond to which experiment. Data about input files and output files is kept in the status json, but for further tracking there are two arguments which can be specified: --run-id \u00b6 An integer run_id to associate with this operation. The run-id is recorded in the metadata field of any operation in its status json. --tags \u00b6 A list of string tags to associate with this operation. The tags are recorded in the metadata field of any operation in its status json. An example of a status json containing a user run id and user tags: # in status json output ... \"metadata\": { \"beep_verison\": \"2021.8.2.15\", \"op_datetime_utc\": \"2021-09-04 00:40:12\", \"run_id\": 234, \"tags\": [\"my_tag_1\", \"TRI_experiments_2021\", \"debugging\"] } Controlling compression and output file formats \u00b6 Serialization in beep is done by the monty library ; to use compression on any output files, status files, or intermediate files in any beep subcommand, append .gz to the end of the output filename(s). For example: # For example, write our status json to a regular (uncompressed) json file # And write our feature matrix output artifact to a gzipped json file $: beep -s status.json featurize * outputFeatureMatrix.json.gz Although they are not officially supported, other compression methods (such as .bz2 ) and file formats ( .yaml ) may be serialized to/from beep if they are supported by the current version of monty .","title":"Overview"},{"location":"Command%20Line%20Interface/1%20-%20overview/#overview","text":"The beep base command specifies options for creating metadata and logging for all subcommands. This page is a general overview of options that are common among any beep subcommand. You can expect options on this page to pertain to basically any beep CLI operation's inputs, outputs, and file formats.","title":"Overview"},{"location":"Command%20Line%20Interface/1%20-%20overview/#basics","text":"The BEEP CLI can be used like: $: beep <options> <subcommand> Options for the base beep command are specified before the subcommand. All beep subcommands take at least one file as input and return one or more files as output. Beep has six subcommands: beep structure : Parse, interpolate, clean, and standardize a wide range of battery cycler output files. beep featurize : Generate features for learning from structured files. beep train : Train a machine learning model based on features. beep predict : Predict battery degradation based on learning features and a previously trained model. beep protocol : Generate cycler protocol from pre-made templates for a wide range of cyclers. beep inspect : Visually inspect and debug beep files on disk. For more info on any command or the base command, simply pass --help as an option. The help dialog for beep base command looks like: $: beep --help Usage: beep [ OPTIONS ] COMMAND [ ARGS ] ... Base BEEP command. Options: -l, --log-file FILE File to log formatted json to. Log will still be output in human readable form to stdout, but if --log-file is specified, it will be additionally logged to a jsonl ( json-lines ) formatted file. -r, --run-id INTEGER An integer run_id which can be optionally assigned to this run. It will be output in the metadata status json for any subcommand if the status json is enabled. -t, --tags TEXT Add optional tags to the status json metadata. Can be later used forlarge-scale queries on database data about sets of BEEP runs. Example: 'experiments_for_kristin' . -s, --output-status-json FILE File to output with JSON info about the states of files which have had any beep subcommand operationrun on them ( e.g., structuring ) . Contains comprehensiveinfo about the success of the operation for all files.1 status json = 1 operation. --halt-on-error Set to halt BEEP if critical featurization errors are encountered on any file with any featurizer. Otherwise, logs critical errors to the status json. --help Show this message and exit. Commands: featurize Featurize one or more files. predict Run a previously trained model to predict degradation... protocol Generate protocol for battery cyclers from a csv file input. structure Structure and/or validate one or more files. train Train a machine learning model using all available data and...","title":"Basics"},{"location":"Command%20Line%20Interface/1%20-%20overview/#output-streams","text":"The beep base command options are used for specifying if and where to output the metadata and status of any CLI operation. Human-readable output will always be logged to stdout, for example: 2021-09-21 16:14:43 INFO Structuring 1 files 2021-09-21 16:14:43 DEBUG Hashing file '/beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv' to MD5 2021-09-21 16:14:43 INFO File 1 of 1: Reading raw file /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv from disk... 2021-09-21 16:14:44 INFO File 1 of 1: Validating: /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv according to schema file '/beep/beep/validation_schemas/schema-arbin-lfp.yaml' 2021-09-21 16:14:44 INFO File 1 of 1: Validated: /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv 2021-09-21 16:14:44 INFO File 1 of 1: Structuring: Read from /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv 2021-09-21 16:14:44 INFO Beginning structuring along charge axis 'charge_capacity' and discharge axis 'voltage'. 2021-09-21 16:15:21 INFO File 1 of 1: Structured: Written to /beep/beep/CLI_TEST_FILES_FEATURIZATION/tmp.json.gz 2021-09-21 16:15:21 INFO Structuring report: 2021-09-21 16:15:21 INFO Succeeded: 1/1 2021-09-21 16:15:21 INFO Invalid: 0/1 2021-09-21 16:15:21 INFO Failed: 0/1 But other output streams are also available:","title":"Output streams"},{"location":"Command%20Line%20Interface/1%20-%20overview/#-log-file","text":"Machine-readable json log file to write. If not specified, no log file will be created. Example: {\"time\": \"2021-09-21 16:13:48,938\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Structuring 1 files\"} {\"time\": \"2021-09-21 16:13:48,939\", \"level\": \"DEBUG\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Hashing file '/beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json' to MD5\"} {\"time\": \"2021-09-21 16:13:49,228\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"File 1 of 1: Reading raw file /beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json from disk...\"} {\"time\": \"2021-09-21 16:13:50,390\", \"level\": \"ERROR\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"File 1 of 1: Failed/invalid: (EmptyDataError): /beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Structuring report:\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" Succeeded: 0/1\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" Invalid: 1/1\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" - /beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json\"} {\"time\": \"2021-09-21 16:13:50,391\", \"level\": \"INFO\", \"process\": \"67214\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \" Failed: 0/1\"} {\"time\": \"2021-09-21 16:14:43,291\", \"level\": \"INFO\", \"process\": \"67264\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Structuring 1 files\"} {\"time\": \"2021-09-21 16:14:43,291\", \"level\": \"DEBUG\", \"process\": \"67264\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"Hashing file '/beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv' to MD5\"} {\"time\": \"2021-09-21 16:14:43,385\", \"level\": \"INFO\", \"process\": \"67264\", \"module\": \"cmd\", \"func\": \"structure\", \"msg\": \"File 1 of 1: Reading raw file /beep/beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv from disk..","title":"--log-file"},{"location":"Command%20Line%20Interface/1%20-%20overview/#-output-status-json","text":"JSON file to write containing comprehensive structured metadata about any operation and all of its sub-operations. If not specified, no status json will be written. Example: { \"op_type\": \"featurize\", \"feature_matrix\": { \"created\": true, \"traceback\": null, \"output\": \"/beep/beep/CLI_TEST_FILES_FEATURIZATION/features.json.gz\" }, \"files\": { \"/beep/beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json\": { \"walltime\": 8.546396970748901, \"output\": null, \"processed_md5_chksum\": \"5848d8598584e45addfa8129bb078d95\", \"featurizers\": { \"HPPCResistanceVoltageFeatures\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 1.2403650283813477, \"traceback\": null, \"subop_md5_chksum\": null }, \"DeltaQFastCharge\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 0.05008506774902344, \"traceback\": null, \"subop_md5_chksum\": null }, \"DiagnosticSummaryStats\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 0.19507122039794922, \"traceback\": null, \"subop_md5_chksum\": null }, \"CycleSummaryStats\": { \"output\": null, \"valid\": true, \"featurized\": true, \"walltime\": 0.013413190841674805, \"traceback\": null, \"subop_md5_chksum\": null } } }, ... \"metadata\": { \"beep_verison\": \"2021.8.2.15\", \"op_datetime_utc\": \"2021-09-04 00:40:12\", \"run_id\": null, \"tags\": [] } } Any one beep command (e.g., beep structure * ), regardless of how many files it intakes or generates, will always produce exactly one status json if --output-status-json is defined.","title":"--output-status-json"},{"location":"Command%20Line%20Interface/1%20-%20overview/#fault-tolerance","text":"","title":"Fault-tolerance"},{"location":"Command%20Line%20Interface/1%20-%20overview/#-halt-on-error","text":"By default, BEEP runs all operations in a fault-tolerant manner. This means that if the CLI command syntax is valid, but internally an operation or sub-operation fails, the process will return successful. To disable this behavior, which will cause any error in any operation or sub-operation to fail the entire command use the --halt-on-error flag.","title":"--halt-on-error"},{"location":"Command%20Line%20Interface/1%20-%20overview/#extra-metadata-and-run-tracking-with-status-json","text":"Running many experiments can make it difficult to keep track of which input and output files correspond to which experiment. Data about input files and output files is kept in the status json, but for further tracking there are two arguments which can be specified:","title":"Extra metadata and run-tracking with status json"},{"location":"Command%20Line%20Interface/1%20-%20overview/#-run-id","text":"An integer run_id to associate with this operation. The run-id is recorded in the metadata field of any operation in its status json.","title":"--run-id"},{"location":"Command%20Line%20Interface/1%20-%20overview/#-tags","text":"A list of string tags to associate with this operation. The tags are recorded in the metadata field of any operation in its status json. An example of a status json containing a user run id and user tags: # in status json output ... \"metadata\": { \"beep_verison\": \"2021.8.2.15\", \"op_datetime_utc\": \"2021-09-04 00:40:12\", \"run_id\": 234, \"tags\": [\"my_tag_1\", \"TRI_experiments_2021\", \"debugging\"] }","title":"--tags"},{"location":"Command%20Line%20Interface/1%20-%20overview/#controlling-compression-and-output-file-formats","text":"Serialization in beep is done by the monty library ; to use compression on any output files, status files, or intermediate files in any beep subcommand, append .gz to the end of the output filename(s). For example: # For example, write our status json to a regular (uncompressed) json file # And write our feature matrix output artifact to a gzipped json file $: beep -s status.json featurize * outputFeatureMatrix.json.gz Although they are not officially supported, other compression methods (such as .bz2 ) and file formats ( .yaml ) may be serialized to/from beep if they are supported by the current version of monty .","title":"Controlling compression and output file formats"},{"location":"Command%20Line%20Interface/2%20-%20structuring/","text":"Structure \u00b6 The beep structure command takes in N raw battery cycler files (mostly text or csv) and produces N standardized, structured data json files. The structured json files can be loaded either with the BEEP python BEEPDatapath interface (see Advanced Structuring ) or with subsequent CLI commands such as beep featurize (see CLI - Featurize ). Structuring help dialog \u00b6 Usage: beep structure [OPTIONS] [FILES]... Structure and/or validate one or more files. Argument is a space-separated list of files or globs. Options: -o, --output-filenames PATH Filenames to write each input filename to. If not specified, auto-names each file by appending`-structured` before the file extension inside the current working dir. -d, --output-dir DIRECTORY Directory to dump auto-named files to. Only works if--output-filenames is not specified. -p, --protocol-parameters-dir DIRECTORY Directory of a protocol parameters files to use for auto-structuring. If not specified, BEEP cannot auto-structure. Use with --automatic. -v, --v-range <FLOAT FLOAT>... Lower, upper bounds for voltage range for structuring. Overridden by auto-structuring if --automatic. -r, --resolution INTEGER Resolution for interpolation for structuring. Overridden by auto-structuring if --automatic. -n, --nominal-capacity FLOAT Nominal capacity to use for structuring. Overridden by auto-structuring if --automatic. -f, --full-fast-charge FLOAT Full fast charge threshold to use for structuring. Overridden by auto-structuring if --automatic. -c, --charge-axis TEXT Axis to use for charge step interpolation. Must be found inside the loaded dataframe. Can be used with --automatic. -x, --discharge-axis TEXT Axis to use for discharge step interpolation. Must be found inside the loaded dataframe. Can be used with-- automatic. -b, --s3-bucket TEXT Expands file paths to include those in the s3 bucket specified. File paths specify s3 keys. Keys can be globbed/wildcarded. Paths matching local files will be prioritized over files with identical paths/globs in s3. Files will be downloaded to CWD. --automatic If --protocol-parameters-path is specified, will automatically determine structuring parameters. Will override all manually set structuring parameters. --validation-only Skips structuring, only validates files. --no-raw Does not save raw cycler data to disk. Saves disk space, but prevents files from being partially restructued. --s3-use-cache Use s3 cache defined with environment variable BEEP_S3_CACHE instead of downloading files directly to the CWD. --help Show this message and exit. Specifying output locations \u00b6 There are three options for specifying output filenames: Specify all output filenames, one for each input file. Should be json . Use --output-filenames ( -o ) to specify files, for example: $: beep structure -o output1.json -o /path/to/output2.json input1.csv input2.csv # Outputs output1.json in the CWD and output2.json at /path/to/output.json. Specify an output directory where auto-named files will be output. Directory should exist. Use --output-dir to specify. $: beep structure -d /path/to/output_dir input1.csv input2.csv # Outputs # - /path/to/output_dir/input1-structured.json # - /path/to/output_dir/input2-structured.json Automatically named files output in CWD. No options needed. $: beep structure input1.csv input2.csv # Outputs in the CWD: # - ./input1-structured.json # - ./input2-structured.json Select files (including from S3) \u00b6 Input files can be named individually or globbed. Input files should be supported by BEEP; see Cycler Data Requirements for more details. Example 1: $: beep structure file1.csv file2.070 Input files do not need to belong to the same cycler type to work together in one operation. Example 2: $: beep structure /path/to/some_files/* /other/path/file.csv If you pass the --s3-bucket argument, you can select files or globs based on keys in this bucket. Note you must have boto3 set up in order to use the S3 files with BEEP. Example for S3: S: beep structure --s3-bucket XXXXXXXXXXXXX /my/s3/key.071 Customize structuring parameters \u00b6 You can customize the structuring parameters using these individual variables: --v-range --resolution --nominal-capacity --full-fast-charge --charge-axis --discharge-axis Example: $: beep structure * --v-range 0 .5 0 .9 --resolution 200 --nominal-capacity 1 .1 --full-fast-charge 0 .9 Alternatively, you can use automatic structuring by passing the --automatic flag. While this flag will by default use a general-purpose set of files for determining structuring parameters, you can specifcy your own parameters for autostructuring by passing both --automatic and --protocol-parameters-dir . For example $: beep structure * --protocol-parameters-dir /path/to/my/params --automatic Failing or invalid files \u00b6 If any of your files fail or are invalid, you can inspect the full traceback in the status json if you have --output-status-json specified in the base beep command . If this does not provide enough information, you can use the inspect command to examine your file, if it can be loaded.","title":"Structure"},{"location":"Command%20Line%20Interface/2%20-%20structuring/#structure","text":"The beep structure command takes in N raw battery cycler files (mostly text or csv) and produces N standardized, structured data json files. The structured json files can be loaded either with the BEEP python BEEPDatapath interface (see Advanced Structuring ) or with subsequent CLI commands such as beep featurize (see CLI - Featurize ).","title":"Structure"},{"location":"Command%20Line%20Interface/2%20-%20structuring/#structuring-help-dialog","text":"Usage: beep structure [OPTIONS] [FILES]... Structure and/or validate one or more files. Argument is a space-separated list of files or globs. Options: -o, --output-filenames PATH Filenames to write each input filename to. If not specified, auto-names each file by appending`-structured` before the file extension inside the current working dir. -d, --output-dir DIRECTORY Directory to dump auto-named files to. Only works if--output-filenames is not specified. -p, --protocol-parameters-dir DIRECTORY Directory of a protocol parameters files to use for auto-structuring. If not specified, BEEP cannot auto-structure. Use with --automatic. -v, --v-range <FLOAT FLOAT>... Lower, upper bounds for voltage range for structuring. Overridden by auto-structuring if --automatic. -r, --resolution INTEGER Resolution for interpolation for structuring. Overridden by auto-structuring if --automatic. -n, --nominal-capacity FLOAT Nominal capacity to use for structuring. Overridden by auto-structuring if --automatic. -f, --full-fast-charge FLOAT Full fast charge threshold to use for structuring. Overridden by auto-structuring if --automatic. -c, --charge-axis TEXT Axis to use for charge step interpolation. Must be found inside the loaded dataframe. Can be used with --automatic. -x, --discharge-axis TEXT Axis to use for discharge step interpolation. Must be found inside the loaded dataframe. Can be used with-- automatic. -b, --s3-bucket TEXT Expands file paths to include those in the s3 bucket specified. File paths specify s3 keys. Keys can be globbed/wildcarded. Paths matching local files will be prioritized over files with identical paths/globs in s3. Files will be downloaded to CWD. --automatic If --protocol-parameters-path is specified, will automatically determine structuring parameters. Will override all manually set structuring parameters. --validation-only Skips structuring, only validates files. --no-raw Does not save raw cycler data to disk. Saves disk space, but prevents files from being partially restructued. --s3-use-cache Use s3 cache defined with environment variable BEEP_S3_CACHE instead of downloading files directly to the CWD. --help Show this message and exit.","title":"Structuring help dialog"},{"location":"Command%20Line%20Interface/2%20-%20structuring/#specifying-output-locations","text":"There are three options for specifying output filenames: Specify all output filenames, one for each input file. Should be json . Use --output-filenames ( -o ) to specify files, for example: $: beep structure -o output1.json -o /path/to/output2.json input1.csv input2.csv # Outputs output1.json in the CWD and output2.json at /path/to/output.json. Specify an output directory where auto-named files will be output. Directory should exist. Use --output-dir to specify. $: beep structure -d /path/to/output_dir input1.csv input2.csv # Outputs # - /path/to/output_dir/input1-structured.json # - /path/to/output_dir/input2-structured.json Automatically named files output in CWD. No options needed. $: beep structure input1.csv input2.csv # Outputs in the CWD: # - ./input1-structured.json # - ./input2-structured.json","title":"Specifying output locations"},{"location":"Command%20Line%20Interface/2%20-%20structuring/#select-files-including-from-s3","text":"Input files can be named individually or globbed. Input files should be supported by BEEP; see Cycler Data Requirements for more details. Example 1: $: beep structure file1.csv file2.070 Input files do not need to belong to the same cycler type to work together in one operation. Example 2: $: beep structure /path/to/some_files/* /other/path/file.csv If you pass the --s3-bucket argument, you can select files or globs based on keys in this bucket. Note you must have boto3 set up in order to use the S3 files with BEEP. Example for S3: S: beep structure --s3-bucket XXXXXXXXXXXXX /my/s3/key.071","title":"Select files (including from S3)"},{"location":"Command%20Line%20Interface/2%20-%20structuring/#customize-structuring-parameters","text":"You can customize the structuring parameters using these individual variables: --v-range --resolution --nominal-capacity --full-fast-charge --charge-axis --discharge-axis Example: $: beep structure * --v-range 0 .5 0 .9 --resolution 200 --nominal-capacity 1 .1 --full-fast-charge 0 .9 Alternatively, you can use automatic structuring by passing the --automatic flag. While this flag will by default use a general-purpose set of files for determining structuring parameters, you can specifcy your own parameters for autostructuring by passing both --automatic and --protocol-parameters-dir . For example $: beep structure * --protocol-parameters-dir /path/to/my/params --automatic","title":"Customize structuring parameters"},{"location":"Command%20Line%20Interface/2%20-%20structuring/#failing-or-invalid-files","text":"If any of your files fail or are invalid, you can inspect the full traceback in the status json if you have --output-status-json specified in the base beep command . If this does not provide enough information, you can use the inspect command to examine your file, if it can be loaded.","title":"Failing or invalid files"},{"location":"Command%20Line%20Interface/3%20-%20featurize/","text":"Featurize \u00b6 Featurize ( beep featurize ) is a way to robustly apply many feature generation routines (featurizers) with different hyperparameters to large sets of files (e.g., a thousand structured cycler files). The input to beep featurize is N structured/processed json files from beep structure . The output of beep featurize is 1 feature matrix file (no matter how many featurizers are applied). Also, optionally N x M featurizer intermediate files for M featurizers (one for each featurizer applied to each file.) Each row of the output feature matrix corresponds to a single cycler file: target_matrix capacity_0.83::TrajectoryFastCharge ... rpt_1Cdischarge_energy0.8_real_regular_throughput::DiagnosticProperties filename ... file1 284 ... NaN file2 58 ... 1266 .108637 file3 85 ... NaN file4 101 ... NaN beep featurize is used for both generating learning features (e.g., voltage under some condition) and targets such as degradation metrics (e.g., cycles to reach a specific capacity). Featurization help dialog \u00b6 $: beep featurize --help Usage: beep featurize [ OPTIONS ] [ FILES ] ... Featurize one or more files. Argument is a space-separated list of files or globs. The same features are applied to each file. Naming of output files is done automatically, but the output directory can be specified. Options: -o, --output-filename FILE Filename to save entre feature matrix to. If not specified, output filewill be named with FeatureMatrix- [ timestamp ] .json.gz. If specified, overrides the output dir for saving the feature matrix to file. -d, --output-dir DIRECTORY Directory to dump auto-named files to. -f, --featurize-with TEXT Specify a featurizer to apply by class name, e.g. HPPCResistanceVoltageFeatures. To apply more than one featurizer, use multiple -f <FEATURIZER> commands. To apply sets ofcore BEEP featurizers, pass either 'all_features' for all features or 'all_targets' for all targets ( features which can be used as targets ) . Note if 'all_features' or 'all_targets' is passed, other -f featurizers will be ignored. All feautrizers are attempted to apply with default hyperparameters ; to specify your own hyperparameters, use --featurize-with- hyperparams.Classes from installed modules not in core BEEP can be specified with the class name in absolute import format, e.g., my_package.my_module.MyClass. -h, --featurize-with-hyperparams TEXT Specify a featurizer to apply by class name with your own hyperparameters. ( such as parameter directories or specific values for hyperparametersfor this featurizer ) , pass a dictionary in the format: '{\"FEATURIZER_NAME\": {\"HYPERPARAM1\": \"VALUE1\"...}}' including the single quotes around the outside and double quotes for internal strings.Custom hyperparameters will be merged with default hyperparameters if the hyperparameter dictionary is underspecified. --save-intermediates Save the intermediate BEEPFeaturizers as json files. Filenames are autogenerated and saved in output-dir if specified ; otherwise, intermediates are written to current working directory. --help Show this message and exit. Specifying input \u00b6 The inputs for beep featurize are structured json output files from beep structure ; Alternatively, structured data serialized with BEEPDatapath in python will also work. Files can be globbed. Specifying outputs \u00b6 The beep featurize command outputs a feature matrix as its required sole output. This file will be auto-named if --output-filename is not specified. To include saving of intermediate featurizer files, use the --save-intermediates flag. These files will be auto-named and put into the CWD if --output-dir is not set. Specifying --output-dir overrides --output-filename and will save all files (including intermediates) into this directory with automatic naming. Selecting featurizers to apply \u00b6 Featurizers in BEEP \u00b6 beep featurize works with \"core\" features in BEEP. To use one with default hyperparameters, use the --featurize-with or -f option with the class name of the featurizer you'd like to use. For example, to apply the HPPCResistanceVoltageFeatures and CycleSummaryStats featurizers, $: beep featurize -f HPPCResistanceVoltageFeatures -f CycleSummaryStats my_structured_file.json You can apply the full set of featurizers for generating learning features by passing --featurize-with all_features : $: beep featurize -f all_features my_structured_file.json Similarly, for features from which degradation targets can be derived, pass --featurize-with all_targets $: beep featurize -f all_targets my_structured_file.json Note passing all_features or all_targets will override any other --featurize-with classes. Featurizers with custom hyperparameters \u00b6 To use custom hyperparameters in beep featurize , pass each featurizer + hyperparameter set with --featurize-with-hyperparams or -h . Each featurizer should be passed in dictionary format with one or more valid hyperparameters defined, like this: { \"HPPCResistanceVoltageFeatures\" : { \"diag_pos\" : 1 , \"soc_window\" : 8 , } } $: beep featurize -h '{\"HPPCResistanceVoltageFeatures\":{\"diag_pos\": 1, \"soc_window\": 8}}' my_structured_file.json Hyperparameters not specified will be merged with the default hyperparameter dictionary defined for each featurizer. Consult the source code for full specifications of each hyperparameter dictionary for any featurizer. To apply multiple featurizers with custom hyperparameters (even the same featurizer class with different hyperparameters), simply use multiple separate --featurize-with-hyperparams options: $: beep featurize -h '{\"HPPCResistanceVoltageFeatures\":{\"diag_pos\": 1, \"soc_window\": 8}}' \\ -h '{\"HPPCResistanceVoltageFeatures\":{\"diag_pos\": 47, \"soc_window\": 10}}' \\ -h '{\"DiagnosticSummaryStats\": {\"test_time_filter_sec\": 1e4}}' \\ my_structured_file.json Your own featurizers \u00b6 beep featurize also works with external featurizers than inherit the BEEPFeaturizer class. Instead of using the class name to identify the featurizer, use --featurize-with* options with the full module and class name of your custom featurizer. For example, if your featurizer inheriting BEEPFeaturizer is installed in your environment in a module my_pkg.my_module.my_submodule.MyClass , do: $: beep featurize -f my_pkg.my_module.my_submodule.MyClass my_structured_file.json Similar to the core featurizers, calling external featurizers with --featurize-with will call them with the default hyperparameters. Using custom hyperparameters should use the same format as --featurize-with-hyperparams , a dictionary with the only key being the fully specified class name and the value being a dictionary of hyperparameters to override: $: beep featurize -h '{\"my_pkg.my_module.my_submodule.MyClass\": {\"my_hp1\": 12}}' \\ my_structured_file.json Any number of external featurizers can be used alongside any number of builtin featurizers in the same command by passing multiple --featurize-with options: $: beep featurize -f HPPCResistanceVoltageFeatures \\ -h '{\"my_pkg.my_module.my_submodule.MyClass\": {\"my_hp1\": 12}}' \\ my_structured_file.json","title":"Featurize"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#featurize","text":"Featurize ( beep featurize ) is a way to robustly apply many feature generation routines (featurizers) with different hyperparameters to large sets of files (e.g., a thousand structured cycler files). The input to beep featurize is N structured/processed json files from beep structure . The output of beep featurize is 1 feature matrix file (no matter how many featurizers are applied). Also, optionally N x M featurizer intermediate files for M featurizers (one for each featurizer applied to each file.) Each row of the output feature matrix corresponds to a single cycler file: target_matrix capacity_0.83::TrajectoryFastCharge ... rpt_1Cdischarge_energy0.8_real_regular_throughput::DiagnosticProperties filename ... file1 284 ... NaN file2 58 ... 1266 .108637 file3 85 ... NaN file4 101 ... NaN beep featurize is used for both generating learning features (e.g., voltage under some condition) and targets such as degradation metrics (e.g., cycles to reach a specific capacity).","title":"Featurize"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#featurization-help-dialog","text":"$: beep featurize --help Usage: beep featurize [ OPTIONS ] [ FILES ] ... Featurize one or more files. Argument is a space-separated list of files or globs. The same features are applied to each file. Naming of output files is done automatically, but the output directory can be specified. Options: -o, --output-filename FILE Filename to save entre feature matrix to. If not specified, output filewill be named with FeatureMatrix- [ timestamp ] .json.gz. If specified, overrides the output dir for saving the feature matrix to file. -d, --output-dir DIRECTORY Directory to dump auto-named files to. -f, --featurize-with TEXT Specify a featurizer to apply by class name, e.g. HPPCResistanceVoltageFeatures. To apply more than one featurizer, use multiple -f <FEATURIZER> commands. To apply sets ofcore BEEP featurizers, pass either 'all_features' for all features or 'all_targets' for all targets ( features which can be used as targets ) . Note if 'all_features' or 'all_targets' is passed, other -f featurizers will be ignored. All feautrizers are attempted to apply with default hyperparameters ; to specify your own hyperparameters, use --featurize-with- hyperparams.Classes from installed modules not in core BEEP can be specified with the class name in absolute import format, e.g., my_package.my_module.MyClass. -h, --featurize-with-hyperparams TEXT Specify a featurizer to apply by class name with your own hyperparameters. ( such as parameter directories or specific values for hyperparametersfor this featurizer ) , pass a dictionary in the format: '{\"FEATURIZER_NAME\": {\"HYPERPARAM1\": \"VALUE1\"...}}' including the single quotes around the outside and double quotes for internal strings.Custom hyperparameters will be merged with default hyperparameters if the hyperparameter dictionary is underspecified. --save-intermediates Save the intermediate BEEPFeaturizers as json files. Filenames are autogenerated and saved in output-dir if specified ; otherwise, intermediates are written to current working directory. --help Show this message and exit.","title":"Featurization help dialog"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#specifying-input","text":"The inputs for beep featurize are structured json output files from beep structure ; Alternatively, structured data serialized with BEEPDatapath in python will also work. Files can be globbed.","title":"Specifying input"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#specifying-outputs","text":"The beep featurize command outputs a feature matrix as its required sole output. This file will be auto-named if --output-filename is not specified. To include saving of intermediate featurizer files, use the --save-intermediates flag. These files will be auto-named and put into the CWD if --output-dir is not set. Specifying --output-dir overrides --output-filename and will save all files (including intermediates) into this directory with automatic naming.","title":"Specifying outputs"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#selecting-featurizers-to-apply","text":"","title":"Selecting featurizers to apply"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#featurizers-in-beep","text":"beep featurize works with \"core\" features in BEEP. To use one with default hyperparameters, use the --featurize-with or -f option with the class name of the featurizer you'd like to use. For example, to apply the HPPCResistanceVoltageFeatures and CycleSummaryStats featurizers, $: beep featurize -f HPPCResistanceVoltageFeatures -f CycleSummaryStats my_structured_file.json You can apply the full set of featurizers for generating learning features by passing --featurize-with all_features : $: beep featurize -f all_features my_structured_file.json Similarly, for features from which degradation targets can be derived, pass --featurize-with all_targets $: beep featurize -f all_targets my_structured_file.json Note passing all_features or all_targets will override any other --featurize-with classes.","title":"Featurizers in BEEP"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#featurizers-with-custom-hyperparameters","text":"To use custom hyperparameters in beep featurize , pass each featurizer + hyperparameter set with --featurize-with-hyperparams or -h . Each featurizer should be passed in dictionary format with one or more valid hyperparameters defined, like this: { \"HPPCResistanceVoltageFeatures\" : { \"diag_pos\" : 1 , \"soc_window\" : 8 , } } $: beep featurize -h '{\"HPPCResistanceVoltageFeatures\":{\"diag_pos\": 1, \"soc_window\": 8}}' my_structured_file.json Hyperparameters not specified will be merged with the default hyperparameter dictionary defined for each featurizer. Consult the source code for full specifications of each hyperparameter dictionary for any featurizer. To apply multiple featurizers with custom hyperparameters (even the same featurizer class with different hyperparameters), simply use multiple separate --featurize-with-hyperparams options: $: beep featurize -h '{\"HPPCResistanceVoltageFeatures\":{\"diag_pos\": 1, \"soc_window\": 8}}' \\ -h '{\"HPPCResistanceVoltageFeatures\":{\"diag_pos\": 47, \"soc_window\": 10}}' \\ -h '{\"DiagnosticSummaryStats\": {\"test_time_filter_sec\": 1e4}}' \\ my_structured_file.json","title":"Featurizers with custom hyperparameters"},{"location":"Command%20Line%20Interface/3%20-%20featurize/#your-own-featurizers","text":"beep featurize also works with external featurizers than inherit the BEEPFeaturizer class. Instead of using the class name to identify the featurizer, use --featurize-with* options with the full module and class name of your custom featurizer. For example, if your featurizer inheriting BEEPFeaturizer is installed in your environment in a module my_pkg.my_module.my_submodule.MyClass , do: $: beep featurize -f my_pkg.my_module.my_submodule.MyClass my_structured_file.json Similar to the core featurizers, calling external featurizers with --featurize-with will call them with the default hyperparameters. Using custom hyperparameters should use the same format as --featurize-with-hyperparams , a dictionary with the only key being the fully specified class name and the value being a dictionary of hyperparameters to override: $: beep featurize -h '{\"my_pkg.my_module.my_submodule.MyClass\": {\"my_hp1\": 12}}' \\ my_structured_file.json Any number of external featurizers can be used alongside any number of builtin featurizers in the same command by passing multiple --featurize-with options: $: beep featurize -f HPPCResistanceVoltageFeatures \\ -h '{\"my_pkg.my_module.my_submodule.MyClass\": {\"my_hp1\": 12}}' \\ my_structured_file.json","title":"Your own featurizers"},{"location":"Command%20Line%20Interface/4%20-%20train/","text":"Train \u00b6 beep train is a one line command to perform hyperparameter tuning and model fitting on previously generated feature matrices. As input, beep train takes: the feature matrix file containing the features for learning the feature matrix file containing the targets (e.g., degradation-related metrics) to fit on As output, beep train produces a single json file of the serialized model. Train help dialog \u00b6 $: beep train --help Usage: beep train [ OPTIONS ] Train a machine learning model using all available data and save it to file. Options: -o, --output-filename FILE Filename ( json ) to write the BEEP linear model object to when training is finished. -fm, --feature-matrix-file FILE Featurization matrix serialized to file, containing features ( X ) for learning. Featurization matrices can be generated by the beep featurize command. [ required ] -tm, --target-matrix-file FILE Featurization matrix serialized to file, containing targets ( one y or more ) for learning. Featurization matrices can be generated by the beep featurize command. [ required ] -t, --targets TEXT Target columns to as from target matrix file. Must all be present in the target matrix file. If more than 1 is specified ( e.g., -t 'col1' -t 'col2' ) , multitask regression will be performed. Column names will be '<Feature Name>::<Featurizer Class Name>' if --homogenize-features is set. If not, column names include long parameter hashes which must be included in this argument option. [ required ] -m, --model-name TEXT Name of the regularized linear model to use. Current selection includes ( 'elasticnet' , 'ridge' , 'lasso' ) . [ required ] -s, --train-on-frac-and-score FLOAT Do hyperparameter tuning on part ( a training fraction ) of the dataset and use that fitted model to predict on a testing fraction of the dataset. Specify the training fraction as a float 0 -1. -al, --alpha-lower FLOAT Lower bound on the grid for the alpha hyperparameter which will be explored during hyperparameter tuning. Must be specified with --alpha-upper and --n-alphas. -au, --alpha-upper FLOAT Upper bound on the grid for the alpha hyperparameter which will be explored during hyperparameter tuning. Must be specified with --alpha-lower and --n-alphas. -an, --n-alphas FLOAT Number of linearly spaced alphas to explore during hyperparameter tuning. If not specified, sklearn defaults are used. Must be specified with --alpha-upper and --alpha- lower. --train-feature-nan-thresh FLOAT Threshold to keep a feature in the training dataset, in fraction of samples which must not be nan from 0 -1. 0 = any feature having any nan is dropped, 1 = no features are dropped. --train-sample-nan-thresh FLOAT Threshold to keep a sample from the training data, in fraction of features which must not be nan from 0 -1. 0 = any sample having any nan feature is dropped, 1 = no samples are dropped. --predict-sample-nan-thresh FLOAT Threshold to keep a sample from any prediction set, including those used internally, in fraction of features which must notbe nan. --drop-nan-training-targets Drop samples containing any nan targets. If False and the targets matrix has nan targets, the command will fail. --impute-strategy TEXT Type of imputation to use, 'median' , 'mean' , or 'none' . --kfold INTEGER Number of folds to use in k-fold hyperparameter tuning. --max-iter INTEGER Number of iterations during training to fit linear parameters. --tol FLOAT Tolerance for optimization. --l1-ratios TEXT Comma separated l1 ratios to try in hyperparameter optimization.For example, '0.1,0.5,0.7,0.9,0.95,1.0' , and all values must be between 0 -1. --homogenize-features BOOLEAN Shorten feature names to only include the featurizer name and ( very short ) feature name. For example, 'capacity_0.8::TrajectoryFastCharge' , where features normally have names including their ( long ) parameter hashes. To use the literal feature names, specify False. --help Show this message and exit. Specifying inputs \u00b6 beep train requires two input files: --feature-matrix-file / -fm \u00b6 The path to a serialized feature matrix file, such as those generated with beep featurize . These will be the learning features for the model. --target-matrix-file / -tm \u00b6 The path to a serialized feature matrix file, such as those generated with beep featurize . These will be the learning targets for the model. Note: The feature matrix file and the target matrix file MUST be generated using the same set of structured json files, otherwise they will not correspond to the same cycler runs and errors will be thrown. Other required args \u00b6 You must also specify one or more --targets / -t , which are column names in the target matrix file. These will be the actual learning targets selected from the input files. Finally, you must specify a --model-name / -m for the liner model. See the Train help dialog for specifics. Specifying outputs \u00b6 beep train outputs a single file which by default will be automatically named. To specify your own output filename, pass --output-filename . Model parameters and options \u00b6 Model parameters and hyperparameters \u00b6 You can pass many model parameters and options for hyperparameter tuning (such as defining the alpha parameter space to search) with command line options: --model : The name of the model to use --alpha-lower : The lower bound on alpha during hyperparameter search --alpha-upper : The higher bound on alpha during hyperparameter search --n-alphas : The number of linearly spaces alphas between alpha lower and alpha upper to include in the grid. --kfold : The number of folds k to use for cross validation in hyperparameter tuning. --max-iter : The max number of iterations to search for optimal hyperparameters during training/tuning. --tol : The tolerate for hyperparameter optimization. --l1-ratios : A comma-separated list of L1 ratios to search when using ElasticNet. Data cleaning options \u00b6 beep train automatically cleans and prepares data for input into an ML experiment. Several options for specifying data cleaning procedures are outlined below: --train-feature-nan-thresh : Threshold for keeping training features with some samples containing NaNs. --train-sample-nan-thresh : Threshold for keeping training samples with some features containing NaNs. --predict-sample-nan-thresh : Threshold for keeping prediction samples with some features containing NaNs. --drop-nan-training-targets : Flag to drop any samples without a valid training target. --impute-strategy : The strategy for imputing unknown values such as NaNs which are left over after dropping NaNs according to thresholds. Running a train/test experiment \u00b6 By default, beep train will train the final model on all available data after determining optimal hyperparameters. However, to run a training and test experiment with the CLI, pass the --train-on-frac-and-score parameter, which will train and tune on the specified fraction of data and test on the remainder. The results of training and testing errors will be reported in the status json if --output-status-json is passed to the base beep command .","title":"Train"},{"location":"Command%20Line%20Interface/4%20-%20train/#train","text":"beep train is a one line command to perform hyperparameter tuning and model fitting on previously generated feature matrices. As input, beep train takes: the feature matrix file containing the features for learning the feature matrix file containing the targets (e.g., degradation-related metrics) to fit on As output, beep train produces a single json file of the serialized model.","title":"Train"},{"location":"Command%20Line%20Interface/4%20-%20train/#train-help-dialog","text":"$: beep train --help Usage: beep train [ OPTIONS ] Train a machine learning model using all available data and save it to file. Options: -o, --output-filename FILE Filename ( json ) to write the BEEP linear model object to when training is finished. -fm, --feature-matrix-file FILE Featurization matrix serialized to file, containing features ( X ) for learning. Featurization matrices can be generated by the beep featurize command. [ required ] -tm, --target-matrix-file FILE Featurization matrix serialized to file, containing targets ( one y or more ) for learning. Featurization matrices can be generated by the beep featurize command. [ required ] -t, --targets TEXT Target columns to as from target matrix file. Must all be present in the target matrix file. If more than 1 is specified ( e.g., -t 'col1' -t 'col2' ) , multitask regression will be performed. Column names will be '<Feature Name>::<Featurizer Class Name>' if --homogenize-features is set. If not, column names include long parameter hashes which must be included in this argument option. [ required ] -m, --model-name TEXT Name of the regularized linear model to use. Current selection includes ( 'elasticnet' , 'ridge' , 'lasso' ) . [ required ] -s, --train-on-frac-and-score FLOAT Do hyperparameter tuning on part ( a training fraction ) of the dataset and use that fitted model to predict on a testing fraction of the dataset. Specify the training fraction as a float 0 -1. -al, --alpha-lower FLOAT Lower bound on the grid for the alpha hyperparameter which will be explored during hyperparameter tuning. Must be specified with --alpha-upper and --n-alphas. -au, --alpha-upper FLOAT Upper bound on the grid for the alpha hyperparameter which will be explored during hyperparameter tuning. Must be specified with --alpha-lower and --n-alphas. -an, --n-alphas FLOAT Number of linearly spaced alphas to explore during hyperparameter tuning. If not specified, sklearn defaults are used. Must be specified with --alpha-upper and --alpha- lower. --train-feature-nan-thresh FLOAT Threshold to keep a feature in the training dataset, in fraction of samples which must not be nan from 0 -1. 0 = any feature having any nan is dropped, 1 = no features are dropped. --train-sample-nan-thresh FLOAT Threshold to keep a sample from the training data, in fraction of features which must not be nan from 0 -1. 0 = any sample having any nan feature is dropped, 1 = no samples are dropped. --predict-sample-nan-thresh FLOAT Threshold to keep a sample from any prediction set, including those used internally, in fraction of features which must notbe nan. --drop-nan-training-targets Drop samples containing any nan targets. If False and the targets matrix has nan targets, the command will fail. --impute-strategy TEXT Type of imputation to use, 'median' , 'mean' , or 'none' . --kfold INTEGER Number of folds to use in k-fold hyperparameter tuning. --max-iter INTEGER Number of iterations during training to fit linear parameters. --tol FLOAT Tolerance for optimization. --l1-ratios TEXT Comma separated l1 ratios to try in hyperparameter optimization.For example, '0.1,0.5,0.7,0.9,0.95,1.0' , and all values must be between 0 -1. --homogenize-features BOOLEAN Shorten feature names to only include the featurizer name and ( very short ) feature name. For example, 'capacity_0.8::TrajectoryFastCharge' , where features normally have names including their ( long ) parameter hashes. To use the literal feature names, specify False. --help Show this message and exit.","title":"Train help dialog"},{"location":"Command%20Line%20Interface/4%20-%20train/#specifying-inputs","text":"beep train requires two input files:","title":"Specifying inputs"},{"location":"Command%20Line%20Interface/4%20-%20train/#-feature-matrix-file-fm","text":"The path to a serialized feature matrix file, such as those generated with beep featurize . These will be the learning features for the model.","title":"--feature-matrix-file/-fm"},{"location":"Command%20Line%20Interface/4%20-%20train/#-target-matrix-file-tm","text":"The path to a serialized feature matrix file, such as those generated with beep featurize . These will be the learning targets for the model. Note: The feature matrix file and the target matrix file MUST be generated using the same set of structured json files, otherwise they will not correspond to the same cycler runs and errors will be thrown.","title":"--target-matrix-file/-tm"},{"location":"Command%20Line%20Interface/4%20-%20train/#other-required-args","text":"You must also specify one or more --targets / -t , which are column names in the target matrix file. These will be the actual learning targets selected from the input files. Finally, you must specify a --model-name / -m for the liner model. See the Train help dialog for specifics.","title":"Other required args"},{"location":"Command%20Line%20Interface/4%20-%20train/#specifying-outputs","text":"beep train outputs a single file which by default will be automatically named. To specify your own output filename, pass --output-filename .","title":"Specifying outputs"},{"location":"Command%20Line%20Interface/4%20-%20train/#model-parameters-and-options","text":"","title":"Model parameters and options"},{"location":"Command%20Line%20Interface/4%20-%20train/#model-parameters-and-hyperparameters","text":"You can pass many model parameters and options for hyperparameter tuning (such as defining the alpha parameter space to search) with command line options: --model : The name of the model to use --alpha-lower : The lower bound on alpha during hyperparameter search --alpha-upper : The higher bound on alpha during hyperparameter search --n-alphas : The number of linearly spaces alphas between alpha lower and alpha upper to include in the grid. --kfold : The number of folds k to use for cross validation in hyperparameter tuning. --max-iter : The max number of iterations to search for optimal hyperparameters during training/tuning. --tol : The tolerate for hyperparameter optimization. --l1-ratios : A comma-separated list of L1 ratios to search when using ElasticNet.","title":"Model parameters and hyperparameters"},{"location":"Command%20Line%20Interface/4%20-%20train/#data-cleaning-options","text":"beep train automatically cleans and prepares data for input into an ML experiment. Several options for specifying data cleaning procedures are outlined below: --train-feature-nan-thresh : Threshold for keeping training features with some samples containing NaNs. --train-sample-nan-thresh : Threshold for keeping training samples with some features containing NaNs. --predict-sample-nan-thresh : Threshold for keeping prediction samples with some features containing NaNs. --drop-nan-training-targets : Flag to drop any samples without a valid training target. --impute-strategy : The strategy for imputing unknown values such as NaNs which are left over after dropping NaNs according to thresholds.","title":"Data cleaning options"},{"location":"Command%20Line%20Interface/4%20-%20train/#running-a-traintest-experiment","text":"By default, beep train will train the final model on all available data after determining optimal hyperparameters. However, to run a training and test experiment with the CLI, pass the --train-on-frac-and-score parameter, which will train and tune on the specified fraction of data and test on the remainder. The results of training and testing errors will be reported in the status json if --output-status-json is passed to the base beep command .","title":"Running a train/test experiment"},{"location":"Command%20Line%20Interface/5%20-%20predict/","text":"Predict \u00b6 beep predict runs previously trained models to predict degradation characteristics based on a new input feature matrix. beep predict takes in a previously trained model json file (e.g., trained with beep train and a previously generated feature matrix (e.g., generated with beep featurize ) which you want ML predictions for. Each row in this input dataframe corresponds to a single cycler file. The output is a dataframe of predictions of degradation characteristics for each file, serialized to disk as json. For example: target_matrix predicted capacity_0.92::TrajectoryFastCharge filename file1_to_predict 287 file2_to_predict 59 file3_to_predict 82 file4_to_predict 103 Predict help dialog \u00b6 $: beep predict --help Usage: beep predict [ OPTIONS ] MODEL_FILE Run a previously trained model to predict degradation targets.The MODEL_FILE passed should be an output of 'beep train' or aserialized BEEPLinearModelExperiment object. Options: -fm, --feature-matrix-file TEXT Feature matrix to use as input to the model. Predictions are basedon these features. [ required ] -o, --output-filename FILE Filename ( json ) to write the final predicted dataframe to. --predict-sample-nan-thresh FLOAT Threshold to keep a sample from any prediction set. --help Show this message and exit. Specifying inputs \u00b6 beep predict requires two files as input: A previously trained model file, which can be generated with beep train or in python via BEEPLinearModelExperiment . A feature matrix file of features for new files for which you want degradation predictions The feature matrix file must have at least the features required by the trained model. Extra features will be automatically dropped. The single model file is specified with the required argument MODEL_FILE (no globs) and the feature matrix is specified with --feature-matrix-file / -fm . For example: $: beep predict -fm /path/to/my/featurematix.json.gz /path/to/my/previously_trained_model.json.gz Specifying output \u00b6 The output is a single serialized dataframe, which is by default auto-named but can be overridden by --output-filename / -o . $: beep predict -fm /path/to/my/featurematix.json.gz \\ -o my_output_predictions.json /path/to/my/previously_trained_model.json.gz","title":"Predict"},{"location":"Command%20Line%20Interface/5%20-%20predict/#predict","text":"beep predict runs previously trained models to predict degradation characteristics based on a new input feature matrix. beep predict takes in a previously trained model json file (e.g., trained with beep train and a previously generated feature matrix (e.g., generated with beep featurize ) which you want ML predictions for. Each row in this input dataframe corresponds to a single cycler file. The output is a dataframe of predictions of degradation characteristics for each file, serialized to disk as json. For example: target_matrix predicted capacity_0.92::TrajectoryFastCharge filename file1_to_predict 287 file2_to_predict 59 file3_to_predict 82 file4_to_predict 103","title":"Predict"},{"location":"Command%20Line%20Interface/5%20-%20predict/#predict-help-dialog","text":"$: beep predict --help Usage: beep predict [ OPTIONS ] MODEL_FILE Run a previously trained model to predict degradation targets.The MODEL_FILE passed should be an output of 'beep train' or aserialized BEEPLinearModelExperiment object. Options: -fm, --feature-matrix-file TEXT Feature matrix to use as input to the model. Predictions are basedon these features. [ required ] -o, --output-filename FILE Filename ( json ) to write the final predicted dataframe to. --predict-sample-nan-thresh FLOAT Threshold to keep a sample from any prediction set. --help Show this message and exit.","title":"Predict help dialog"},{"location":"Command%20Line%20Interface/5%20-%20predict/#specifying-inputs","text":"beep predict requires two files as input: A previously trained model file, which can be generated with beep train or in python via BEEPLinearModelExperiment . A feature matrix file of features for new files for which you want degradation predictions The feature matrix file must have at least the features required by the trained model. Extra features will be automatically dropped. The single model file is specified with the required argument MODEL_FILE (no globs) and the feature matrix is specified with --feature-matrix-file / -fm . For example: $: beep predict -fm /path/to/my/featurematix.json.gz /path/to/my/previously_trained_model.json.gz","title":"Specifying inputs"},{"location":"Command%20Line%20Interface/5%20-%20predict/#specifying-output","text":"The output is a single serialized dataframe, which is by default auto-named but can be overridden by --output-filename / -o . $: beep predict -fm /path/to/my/featurematix.json.gz \\ -o my_output_predictions.json /path/to/my/previously_trained_model.json.gz","title":"Specifying output"},{"location":"Command%20Line%20Interface/6%20-%20protocol/","text":"Protocol \u00b6 Warning: beep protocol is still being migrated from a previous codebase; may be unstable. beep protocol protocol programmatically generates files for running battery experiments. The input to beep protocol is a singe csv file with various parameters specified, for example: project_name,seq_num,template,charge_constant_current_1,charge_percent_limit_1,charge_constant_current_2,charge_cutoff_voltage,charge_constant_voltage_time,charge_rest_time,discharge_profile,profile_charge_limit,max_profile_power,n_repeats,discharge_cutoff_voltage,power_scaling,discharge_rest_time,cell_temperature_nominal,cell_type,capacity_nominal,diagnostic_type,diagnostic_parameter_set,diagnostic_start_cycle,diagnostic_interval Drive,100,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,4,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,101,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,4,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,102,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,4,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,103,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,4,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,104,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,4,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,105,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,4,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,106,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,8,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,107,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,8,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,108,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,8,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,109,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,8,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,110,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,8,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,111,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,8,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,112,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,12,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,113,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,12,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,114,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,12,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,115,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,12,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,116,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,12,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,117,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,12,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,118,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,4,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,119,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,4,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,120,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,4,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,121,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,4,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,122,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,4,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,123,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,4,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,124,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,8,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,125,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,8,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,126,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,8,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,127,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,8,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,128,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,8,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,129,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,8,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,130,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,12,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,131,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,12,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,132,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,12,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,133,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,12,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,134,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,12,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,135,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,12,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 The output of beep protocol is a set of ready-to-use battery cycler protocols. More documentation for beep protocol coming soon. Protocol help dialog \u00b6 $: beep protocol --help Usage: beep protocol [ OPTIONS ] CSV_FILE Generate protocol for battery cyclers from a csv file input. Options: -d, --output-dir TEXT Directory to output files to. At least three subdirs will be created in this directoryin order to organize the generated protocol files. --help Show this message and exit. More documentation coming soon! \u00b6","title":"Protocol"},{"location":"Command%20Line%20Interface/6%20-%20protocol/#protocol","text":"Warning: beep protocol is still being migrated from a previous codebase; may be unstable. beep protocol protocol programmatically generates files for running battery experiments. The input to beep protocol is a singe csv file with various parameters specified, for example: project_name,seq_num,template,charge_constant_current_1,charge_percent_limit_1,charge_constant_current_2,charge_cutoff_voltage,charge_constant_voltage_time,charge_rest_time,discharge_profile,profile_charge_limit,max_profile_power,n_repeats,discharge_cutoff_voltage,power_scaling,discharge_rest_time,cell_temperature_nominal,cell_type,capacity_nominal,diagnostic_type,diagnostic_parameter_set,diagnostic_start_cycle,diagnostic_interval Drive,100,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,4,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,101,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,4,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,102,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,4,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,103,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,4,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,104,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,4,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,105,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,4,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,106,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,8,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,107,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,8,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,108,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,8,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,109,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,8,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,110,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,8,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,111,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,8,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,112,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,12,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,113,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,12,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,114,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,12,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,115,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,12,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,116,diagnosticV5.000,1,30,1,4.1,30,5,US06,4.2,40,12,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,117,diagnosticV5.000,1,30,1,4.1,30,5,LA4,4.2,40,12,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,118,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,4,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,119,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,4,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,120,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,4,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,121,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,4,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,122,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,4,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,123,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,4,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,124,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,8,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,125,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,8,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,126,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,8,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,127,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,8,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,128,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,8,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,129,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,8,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,130,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,12,2.7,0.60,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,131,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,12,2.7,0.27,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,132,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,12,2.7,0.80,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,133,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,12,2.7,0.36,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,134,diagnosticV5.000,1,30,1,3.9,30,5,US06,4.2,40,12,2.7,1.00,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 Drive,135,diagnosticV5.000,1,30,1,3.9,30,5,LA4,4.2,40,12,2.7,0.45,15,25,Tesla_Model3_21700,4.84,HPPC+RPT,Tesla21700,30,200 The output of beep protocol is a set of ready-to-use battery cycler protocols. More documentation for beep protocol coming soon.","title":"Protocol"},{"location":"Command%20Line%20Interface/6%20-%20protocol/#protocol-help-dialog","text":"$: beep protocol --help Usage: beep protocol [ OPTIONS ] CSV_FILE Generate protocol for battery cyclers from a csv file input. Options: -d, --output-dir TEXT Directory to output files to. At least three subdirs will be created in this directoryin order to organize the generated protocol files. --help Show this message and exit.","title":"Protocol help dialog"},{"location":"Command%20Line%20Interface/6%20-%20protocol/#more-documentation-coming-soon","text":"","title":"More documentation coming soon!"},{"location":"Command%20Line%20Interface/7%20-%20inspect/","text":"Inspect \u00b6 BEEP inspect is a debugging and analysis command which can be used to examine any serialized beep object directly from the command line. The objects that can be inspected are: Raw cycler files compatible with BEEP, which will be ingested and represented as a BEEPDatapath . Example: Inspect Raw Files Structured cycler files serialized by BEEP to disk as json, represented as a BEEPDatapath . Example: Inspect Structured Files Feature matrices serialized to disk as json. Example: Inspect Feature Matrices Individual BEEPFeaturizer s serialized to disk as json. Example: Inspect Featurizers Linear BEEPLinearModelExperiment s serialized to disk as json. Example: Inspect Models Inspect help dialog \u00b6 $: beep inspect --help Usage: beep inspect [ OPTIONS ] FILE View BEEP files for debugging and analysis. Options: --help Show this message and exit. Inspect Raw Files \u00b6 Example: S: beep inspect PreDiag_000287_000128.092 2021 -09-22 16 :01:33 DEBUG Loaded potential raw file beep/tests/test_files/PreDiag_000287_000128.092 as Datapath. 2021 -09-22 16 :01:34 INFO Loaded beep/tests/test_files/PreDiag_000287_000128.092 as type <class 'beep.structure.maccor.MaccorDatapath' >. BEEP Datapath: beep/tests/test_files/PreDiag_000287_000128.092 Semiunique id: 'barcode:000128-channel:92-protocol:PreDiag_000287.000-schema:beep/validation_schemas/schema-maccor-2170.yaml-structured:False-legacy:False-raw_path:beep/tests/test_files/PreDiag_000287_000128.092-structured_path:None' File paths { 'metadata' : 'beep/tests/test_files/PreDiag_000287_000128.092' , 'raw' : 'beep/tests/test_files/PreDiag_000287_000128.092' } File metadata: { '_today_datetime' : '12/17/2019' , 'barcode' : '000128' , 'channel_id' : 92 , 'filename' : 'C:\\\\Users\\\\Maccor Tester User\\\\Documents\\\\Backup\\\\STANFORD ' 'LOANER #1\\\\STANFORD LOANER #1\\\\PreDiag_000287_000128.092' , 'protocol' : 'PreDiag_000287.000' , 'start_datetime' : '12/17/2019' } Validation schema: beep/validation_schemas/schema-maccor-2170.yaml Structuring parameters: {} Structured attributes: structured_summary: No object. structured_data: No object. diagnostic_data: No object. diagnostic_summary: No object. raw_data: data_point cycle_index step_index test_time step_time _capacity _energy current voltage _state _ending_status date_time loop1 loop2 loop3 loop4 ac_impedence internal_resistance _wf_chg_cap _wf_dis_cap ... _var2 _var3 _var4 _var5 _var6 _var7 _var8 _var9 _var10 _var11 _var12 _var13 _var14 _var15 charge_capacity discharge_capacity charge_energy discharge_energy date_time_iso temperature 0 1 0 1 0 .00 0 .000000 0 .000000 0 .000000 0 .000000 3 .458076 R 0 12 /17/2019 09 :51:51 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:51:51+00:00 NaN 1 2 0 1 30 .00 30 .000000 0 .000000 0 .000000 0 .000000 3 .457999 R 1 12 /17/2019 09 :52:20 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:52:20+00:00 NaN 2 3 0 1 60 .00 60 .000000 0 .000000 0 .000000 0 .000000 3 .457999 R 1 12 /17/2019 09 :52:50 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:52:50+00:00 NaN 3 4 0 1 89 .42 89 .419998 0 .000000 0 .000000 0 .000000 3 .458152 S 192 12 /17/2019 09 :53:20 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:53:20+00:00 NaN 4 5 0 1 89 .42 89 .419998 0 .000000 0 .000000 0 .000000 3 .458228 R 192 12 /17/2019 11 :15:57 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T19:15:57+00:00 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 546943 546944 246 39 1958303 .97 23211 .070312 4 .459139 16 .402617 -0.691691 2 .700771 D 5 01 /09/2020 03 :18:48 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011044 4 .459139 8 .126739 16 .402617 2020 -01-09T11:18:48+00:00 NaN 546944 546945 246 39 1958305 .13 23212 .230469 4 .459362 16 .403219 -0.691691 2 .700008 D 133 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011044 4 .459362 8 .126739 16 .403219 2020 -01-09T11:18:49+00:00 NaN 546945 546946 247 41 1958305 .16 0 .030000 0 .000006 0 .000016 1 .618448 2 .760967 C 0 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011050 4 .459362 8 .126755 16 .403219 2020 -01-09T11:18:49+00:00 NaN 546946 546947 247 41 1958305 .32 0 .190000 0 .000078 0 .000215 1 .612268 2 .777752 C 5 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011122 4 .459362 8 .126954 16 .403219 2020 -01-09T11:18:49+00:00 NaN 546947 546948 247 41 1958305 .42 0 .290000 0 .000122 0 .000340 1 .612039 2 .784771 C 5 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011167 4 .459362 8 .127079 16 .403219 2020 -01-09T11:18:49+00:00 NaN [ 546948 rows x 44 columns ] <class 'pandas.core.frame.DataFrame' > RangeIndex: 546948 entries, 0 to 546947 Data columns ( total 44 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 data_point 546948 non-null int32 1 cycle_index 546948 non-null int32 2 step_index 546948 non-null int16 3 test_time 546948 non-null float64 4 step_time 546948 non-null float32 5 _capacity 546948 non-null float64 6 _energy 546948 non-null float64 7 current 546948 non-null float32 8 voltage 546948 non-null float32 9 _state 546948 non-null object 10 _ending_status 546948 non-null category 11 date_time 546948 non-null object 12 loop1 546948 non-null int64 13 loop2 546948 non-null int64 14 loop3 546948 non-null int64 15 loop4 546948 non-null int64 16 ac_impedence 546948 non-null float32 17 internal_resistance 546948 non-null float32 18 _wf_chg_cap 0 non-null float32 19 _wf_dis_cap 0 non-null float32 20 _wf_chg_e 0 non-null float32 21 _wf_dis_e 0 non-null float32 22 _range 546948 non-null uint8 23 _var1 546948 non-null float16 24 _var2 546948 non-null float16 25 _var3 546948 non-null float16 26 _var4 546948 non-null float16 27 _var5 546948 non-null float16 28 _var6 546948 non-null float16 29 _var7 546948 non-null float16 30 _var8 546948 non-null float16 31 _var9 546948 non-null float16 32 _var10 546948 non-null float16 33 _var11 546948 non-null float16 34 _var12 546948 non-null float16 35 _var13 546948 non-null float16 36 _var14 546948 non-null float16 37 _var15 546948 non-null float16 38 charge_capacity 546948 non-null float64 39 discharge_capacity 546948 non-null float64 40 charge_energy 546948 non-null float64 41 discharge_energy 546948 non-null float64 42 date_time_iso 546948 non-null object 43 temperature 0 non-null float64 dtypes: category ( 1 ) , float16 ( 15 ) , float32 ( 9 ) , float64 ( 8 ) , int16 ( 1 ) , int32 ( 2 ) , int64 ( 4 ) , object ( 3 ) , uint8 ( 1 ) memory usage: 103 .3+ MB Inspect Structured Files \u00b6 Example: $: beep inspect 2017 -12-04_4_65C-69per_6C_CH29_structured_new.json.gz 2021 -09-22 16 :04:01 INFO Loaded beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29_structured_new.json.gz as type <class 'beep.structure.arbin.ArbinDatapath' >. BEEP Datapath: beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29_structured_new.json.gz Semiunique id: 'barcode:EL151000429559-channel:28-protocol:2017-12-04_tests\\20170630-4_65C_69per_6C.sdu-schema:beep/validation_schemas/schema-arbin-lfp.yaml-structured:True-legacy:True-raw_path:beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv-structured_path:None' File paths { 'metadata' : 'beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29_Metadata.csv' , 'raw' : 'beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv' } File metadata: { 'barcode' : 'EL151000429559' , 'channel_id' : 28 , 'protocol' : '2017-12-04_tests\\\\20170630-4_65C_69per_6C.sdu' } Validation schema: beep/validation_schemas/schema-arbin-lfp.yaml Structuring parameters: { 'charge_axis' : 'charge_capacity' , 'diagnostic_available' : False, 'diagnostic_resolution' : 500 , 'discharge_axis' : 'voltage' , 'full_fast_charge' : 0 .8, 'nominal_capacity' : 1 .1, 'resolution' : 1000 , 'v_range' : None } Structured attributes: structured_summary: cycle_index discharge_capacity charge_capacity discharge_energy charge_energy dc_internal_resistance temperature_maximum temperature_average temperature_minimum date_time_iso energy_efficiency charge_throughput energy_throughput charge_duration time_temperature_integrated paused CV_time CV_current 0 0 1 .940235 1 .432850 6 .142979 4 .725729 0 .029954 34 .222515 32 .666893 20 .699526 2017 -12-05T03:37:36+00:00 1 .299901 1 .432850 4 .725729 32768 .0 48977 .078333 13312 50158 .164062 0 .000029 1 1 1 .060343 1 .061786 3 .219735 3 .703581 0 .017906 35 .375809 32 .387295 30 .235437 2017 -12-06T04:33:04+00:00 0 .869357 2 .494636 8 .429310 640 .0 1927 .509119 0 1577 .987427 0 .062837 2 2 1 .065412 1 .065450 3 .235807 3 .708392 0 .017649 35 .384602 32 .472481 30 .254265 2017 -12-06T05:32:48+00:00 0 .872563 3 .560086 12 .137702 640 .0 1931 .514632 0 1570 .970459 0 .046215 3 3 1 .066605 1 .066726 3 .238866 3 .711425 0 .017506 35 .265358 32 .420013 30 .159765 2017 -12-06T06:32:32+00:00 0 .872675 4 .626812 15 .849127 640 .0 1995 .445402 0 1552 .032471 0 .045087 4 4 1 .066988 1 .067148 3 .239955 3 .712645 0 .017409 35 .280449 32 .407478 30 .157305 2017 -12-06T07:34:24+00:00 0 .872681 5 .693960 19 .561773 512 .0 1926 .752726 0 1548 .414551 0 .052290 .. ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 183 183 1 .033595 1 .033812 3 .046869 3 .615792 0 .016889 37 .566158 32 .988796 30 .226278 2017 -12-13T19:12:00+00:00 0 .842656 194 .065491 676 .183533 640 .0 2026 .858687 0 1590 .061523 0 .034429 184 184 1 .033454 1 .033584 3 .042845 3 .613951 0 .016827 37 .129795 32 .981796 30 .181578 2017 -12-13T20:13:52+00:00 0 .841972 195 .099075 679 .797485 640 .0 1955 .320325 0 1589 .661377 0 .031118 185 185 1 .032677 1 .032898 3 .040163 3 .612450 0 .016875 37 .126766 32 .851368 30 .145836 2017 -12-13T21:13:36+00:00 0 .841579 196 .131973 683 .409912 640 .0 1950 .674312 0 1530 .225342 0 .021825 186 186 1 .032823 1 .033198 3 .041561 3 .613732 0 .016875 37 .236954 32 .925690 30 .300278 2017 -12-13T22:13:20+00:00 0 .841668 197 .165176 687 .023682 640 .0 1954 .338322 0 1590 .264771 0 .026628 187 187 1 .032616 1 .032862 3 .039321 3 .612212 0 .016840 37 .159687 32 .952461 30 .114653 2017 -12-13T23:13:04+00:00 0 .841402 198 .198029 690 .635864 640 .0 1955 .141357 0 1590 .173706 0 .025024 [ 188 rows x 18 columns ] <class 'pandas.core.frame.DataFrame' > RangeIndex: 188 entries, 0 to 187 Data columns ( total 18 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 cycle_index 188 non-null int32 1 discharge_capacity 188 non-null float64 2 charge_capacity 188 non-null float64 3 discharge_energy 188 non-null float64 4 charge_energy 188 non-null float64 5 dc_internal_resistance 188 non-null float32 6 temperature_maximum 188 non-null float32 7 temperature_average 188 non-null float32 8 temperature_minimum 188 non-null float32 9 date_time_iso 188 non-null object 10 energy_efficiency 188 non-null float32 11 charge_throughput 188 non-null float32 12 energy_throughput 188 non-null float32 13 charge_duration 188 non-null float32 14 time_temperature_integrated 188 non-null float64 15 paused 188 non-null int32 16 CV_time 188 non-null float32 17 CV_current 188 non-null float32 dtypes: float32 ( 10 ) , float64 ( 5 ) , int32 ( 2 ) , object ( 1 ) memory usage: 17 .8+ KB None structured_data: voltage test_time current charge_capacity discharge_capacity charge_energy discharge_energy internal_resistance temperature cycle_index step_type 0 2 .800000 88438 .740972 -3.070090 1 .319212 1 .788713 4 .354456 5 .709161 0 .028598 31 .529890 0 discharge 1 2 .800701 85441 .894275 -4.256237 1 .370451 1 .831461 4 .519928 5 .826991 0 .029763 32 .309685 0 discharge 2 2 .801401 58527 .144191 -3.221379 0 .921136 1 .386086 3 .038029 4 .406347 0 .028391 32 .847729 0 discharge 3 2 .802102 31612 .394108 -2.186522 0 .471821 0 .940710 1 .556129 2 .985704 0 .027020 33 .385773 0 discharge 4 2 .802803 4697 .644024 -1.151665 0 .022506 0 .495335 0 .074230 1 .565060 0 .025648 33 .923817 0 discharge ... ... ... ... ... ... ... ... ... ... ... ... 375995 NaN NaN NaN 1 .427113 NaN NaN NaN NaN NaN 187 charge 375996 NaN NaN NaN 1 .428547 NaN NaN NaN NaN NaN 187 charge 375997 NaN NaN NaN 1 .429981 NaN NaN NaN NaN NaN 187 charge 375998 NaN NaN NaN 1 .431416 NaN NaN NaN NaN NaN 187 charge 375999 NaN NaN NaN 1 .432850 NaN NaN NaN NaN NaN 187 charge [ 376000 rows x 11 columns ] <class 'pandas.core.frame.DataFrame' > RangeIndex: 376000 entries, 0 to 375999 Data columns ( total 11 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 voltage 325974 non-null float32 1 test_time 325974 non-null float64 2 current 325974 non-null float32 3 charge_capacity 376000 non-null float32 4 discharge_capacity 325974 non-null float32 5 charge_energy 325974 non-null float32 6 discharge_energy 325974 non-null float32 7 internal_resistance 325974 non-null float32 8 temperature 325974 non-null float32 9 cycle_index 376000 non-null int32 10 step_type 376000 non-null category dtypes: category ( 1 ) , float32 ( 8 ) , float64 ( 1 ) , int32 ( 1 ) memory usage: 16 .1 MB None diagnostic_data: No object. diagnostic_summary: No object. raw_data: No object. Inspect Feature Matrices \u00b6 Example: S: beep inspect FeatureMatrix-2021-21-09_20.50.32.550211.json.gz 2021 -09-22 15 :54:23 INFO Loaded FeatureMatrix-2021-21-09_20.50.32.550211.json.gz as type <class 'beep.features.base.BEEPFeatureMatrix' >. BEEP Feature Matrix: FeatureMatrix-2021-21-09_20.50.32.550211.json.gz Featurizers: Featurizer beep.features.core HPPCResistanceVoltageFeatures { '@class' : 'HPPCResistanceVoltageFeatures' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_index_filter' : 6 , 'diag_pos' : 1 , 'parameters_path' : 'beep/protocol_parameters' , 'soc_window' : 8 , 'test_time_filter_sec' : 1000000 } , 'linked_datapath_semiunique_id' : 'barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PreDiag_000440_0000FB_structure.json' , 'metadata' : { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PreDiag_000440_0000FB_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 10 , 100 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PreDiag_000440_0000FB_structure.json' , 'metadata' : { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PreDiag_000440_0000FB_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 11 , 101 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PreDiag_000440_0000FB_structure.json' , 'metadata' : { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PreDiag_000440_0000FB_structure.json' }} Featurizer beep.features.core HPPCResistanceVoltageFeatures { '@class' : 'HPPCResistanceVoltageFeatures' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_index_filter' : 6 , 'diag_pos' : 1 , 'parameters_path' : 'beep/protocol_parameters' , 'soc_window' : 8 , 'test_time_filter_sec' : 1000000 } , 'linked_datapath_semiunique_id' : 'barcode:00004C-channel:33-protocol:PredictionDiagnostics_000132.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' , 'metadata' : { 'barcode' : '00004C' , 'channel_id' : 33 , 'protocol' : 'PredictionDiagnostics_000132.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 10 , 100 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:00004C-channel:33-protocol:PredictionDiagnostics_000132.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' , 'metadata' : { 'barcode' : '00004C' , 'channel_id' : 33 , 'protocol' : 'PredictionDiagnostics_000132.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 11 , 101 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:00004C-channel:33-protocol:PredictionDiagnostics_000132.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' , 'metadata' : { 'barcode' : '00004C' , 'channel_id' : 33 , 'protocol' : 'PredictionDiagnostics_000132.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' }} Matrix: D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 ... var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 filename ... beep/tests/tes... -0.075467 ... 0 .000186 beep/tests/tes... -0.090097 ... 0 .002462 [ 2 rows x 132 columns ] <class 'pandas.core.frame.DataFrame' > Index: 2 entries, beep/tests/test_files/PreDiag_000440_0000FB_structure.json to beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json Columns: 132 entries, D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 to var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 dtypes: float64 ( 132 ) memory usage: 2 .1+ KB Inspect Featurizers \u00b6 Example: $: beep inspect HPPCFeaturizer.json.gz 2021 -09-22 16 :06:42 INFO Loaded beep/tests/test_files/modelling_test_files/HPPCFeaturizer.json.gz as type <class 'beep.features.core.HPPCResistanceVoltageFeatures' >. BEEP Featurizer: beep/tests/test_files/modelling_test_files/HPPCFeaturizer.json.gz File paths: { 'structured' : 'beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json' } Linked datapath semiunique id: barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json Hyperparameters: { 'cycle_index_filter' : 6 , 'diag_pos' : 1 , 'parameters_path' : 'beep/protocol_parameters' , 'soc_window' : 8 , 'test_time_filter_sec' : 1000000 } Metadata: { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } Features: r_c_0s_00 r_c_0s_10 r_c_0s_20 r_c_0s_30 r_c_0s_40 r_c_0s_50 r_c_0s_60 r_c_0s_70 r_c_0s_80 r_c_3s_00 r_c_3s_10 r_c_3s_20 r_c_3s_30 r_c_3s_40 r_c_3s_50 r_c_3s_60 r_c_3s_70 r_c_3s_80 r_c_end_00 ... skew_ocv kurtosis_ocv sum_ocv sum_square_ocv var_v_diff min_v_diff mean_v_diff skew_v_diff kurtosis_v_diff sum_v_diff sum_square_v_diff D_1 D_2 D_3 D_4 D_5 D_6 D_7 D_8 0 -0.056034 -0.063766 -0.07963 -0.105001 -0.091609 -0.095464 -0.073553 -0.06692 -0.064657 -0.037199 -0.071951 -0.077876 -0.128588 -0.103652 -0.106871 -0.096638 -0.066802 -0.074038 -0.053153 ... 1 .674431 7 .472183 0 .045535 0 .000641 0 .000186 -0.00181 0 .012954 0 .887649 2 .940287 14 .16811 0 .373482 -0.075467 -0.097516 -0.230871 -0.163967 -0.158305 -0.137443 0 .070989 0 .098653 [ 1 rows x 76 columns ] Inspect Models \u00b6 Example: $: beep inspect model-src.json.gz 2021 -09-22 16 :06:04 WARNING Number of samples ( 4 ) less than number of features ( 179 ) ; may cause overfitting. 2021 -09-22 16 :06:04 INFO Loaded beep/tests/test_files/modelling_test_files/model-src.json.gz as type <class 'beep.model.BEEPLinearModelExperiment' >. BEEP Linear Model Experiment: beep/tests/test_files/modelling_test_files/model-src.json.gz Targets: [ 'capacity_0.92::TrajectoryFastCharge' ] Model name: lasso Impute strategy: median Homogenize features: True NaN Thresholds: -train_feature_drop_nan_thresh: 0 .95 -train_sample_drop_nan_thresh: 0 .5 -predict_sample_nan_thresh: 0 .75 Model parameters: - coef_: [ 0 .0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, -0.0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, -0.0, -0.0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, 0 .0, -0.0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, -0.0, -0.0 ] - intercept_: 113 .25 - optimal_hyperparameters: { 'alpha' : 98 .35818271439722 } Matrices: feature_matrix D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 ... var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 filename ... beep/CLI_TEST_... -0.075467 ... 0 .000186 beep/CLI_TEST_... -0.090097 ... 0 .002462 beep/CLI_TEST_... -0.145030 ... 0 .002416 beep/CLI_TEST_... -0.052108 ... 0 .000848 [ 4 rows x 179 columns ] <class 'pandas.core.frame.DataFrame' > Index: 4 entries, beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json to beep/CLI_TEST_FILES_FEATURIZATION/PredictionDiagnostics_000136_00002D_structure.json Columns: 179 entries, D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 to var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 dtypes: float64 ( 179 ) memory usage: 5 .6+ KB None target_matrix capacity_0.83::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 ... rpt_1Cdischarge_energy0.8_real_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e filename ... beep/CLI_TEST_... 284 ... NaN beep/CLI_TEST_... 58 ... 1266 .108637 beep/CLI_TEST_... 85 ... NaN beep/CLI_TEST_... 101 ... NaN [ 4 rows x 11 columns ] <class 'pandas.core.frame.DataFrame' > Index: 4 entries, beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json to beep/CLI_TEST_FILES_FEATURIZATION/PredictionDiagnostics_000136_00002D_structure.json Data columns ( total 11 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 capacity_0.83::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 1 capacity_0.86::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 2 capacity_0.89::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 3 capacity_0.8::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 4 capacity_0.92::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 5 capacity_0.95::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 6 capacity_0.98::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 7 initial_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 8 rpt_1Cdischarge_energy0.8_cycle_index::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 9 rpt_1Cdischarge_energy0.8_normalized_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 10 rpt_1Cdischarge_energy0.8_real_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 dtypes: float64 ( 4 ) , int64 ( 7 ) memory usage: 556 .0+ bytes","title":"Inspect"},{"location":"Command%20Line%20Interface/7%20-%20inspect/#inspect","text":"BEEP inspect is a debugging and analysis command which can be used to examine any serialized beep object directly from the command line. The objects that can be inspected are: Raw cycler files compatible with BEEP, which will be ingested and represented as a BEEPDatapath . Example: Inspect Raw Files Structured cycler files serialized by BEEP to disk as json, represented as a BEEPDatapath . Example: Inspect Structured Files Feature matrices serialized to disk as json. Example: Inspect Feature Matrices Individual BEEPFeaturizer s serialized to disk as json. Example: Inspect Featurizers Linear BEEPLinearModelExperiment s serialized to disk as json. Example: Inspect Models","title":"Inspect"},{"location":"Command%20Line%20Interface/7%20-%20inspect/#inspect-help-dialog","text":"$: beep inspect --help Usage: beep inspect [ OPTIONS ] FILE View BEEP files for debugging and analysis. Options: --help Show this message and exit.","title":"Inspect help dialog"},{"location":"Command%20Line%20Interface/7%20-%20inspect/#inspect-raw-files","text":"Example: S: beep inspect PreDiag_000287_000128.092 2021 -09-22 16 :01:33 DEBUG Loaded potential raw file beep/tests/test_files/PreDiag_000287_000128.092 as Datapath. 2021 -09-22 16 :01:34 INFO Loaded beep/tests/test_files/PreDiag_000287_000128.092 as type <class 'beep.structure.maccor.MaccorDatapath' >. BEEP Datapath: beep/tests/test_files/PreDiag_000287_000128.092 Semiunique id: 'barcode:000128-channel:92-protocol:PreDiag_000287.000-schema:beep/validation_schemas/schema-maccor-2170.yaml-structured:False-legacy:False-raw_path:beep/tests/test_files/PreDiag_000287_000128.092-structured_path:None' File paths { 'metadata' : 'beep/tests/test_files/PreDiag_000287_000128.092' , 'raw' : 'beep/tests/test_files/PreDiag_000287_000128.092' } File metadata: { '_today_datetime' : '12/17/2019' , 'barcode' : '000128' , 'channel_id' : 92 , 'filename' : 'C:\\\\Users\\\\Maccor Tester User\\\\Documents\\\\Backup\\\\STANFORD ' 'LOANER #1\\\\STANFORD LOANER #1\\\\PreDiag_000287_000128.092' , 'protocol' : 'PreDiag_000287.000' , 'start_datetime' : '12/17/2019' } Validation schema: beep/validation_schemas/schema-maccor-2170.yaml Structuring parameters: {} Structured attributes: structured_summary: No object. structured_data: No object. diagnostic_data: No object. diagnostic_summary: No object. raw_data: data_point cycle_index step_index test_time step_time _capacity _energy current voltage _state _ending_status date_time loop1 loop2 loop3 loop4 ac_impedence internal_resistance _wf_chg_cap _wf_dis_cap ... _var2 _var3 _var4 _var5 _var6 _var7 _var8 _var9 _var10 _var11 _var12 _var13 _var14 _var15 charge_capacity discharge_capacity charge_energy discharge_energy date_time_iso temperature 0 1 0 1 0 .00 0 .000000 0 .000000 0 .000000 0 .000000 3 .458076 R 0 12 /17/2019 09 :51:51 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:51:51+00:00 NaN 1 2 0 1 30 .00 30 .000000 0 .000000 0 .000000 0 .000000 3 .457999 R 1 12 /17/2019 09 :52:20 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:52:20+00:00 NaN 2 3 0 1 60 .00 60 .000000 0 .000000 0 .000000 0 .000000 3 .457999 R 1 12 /17/2019 09 :52:50 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:52:50+00:00 NaN 3 4 0 1 89 .42 89 .419998 0 .000000 0 .000000 0 .000000 3 .458152 S 192 12 /17/2019 09 :53:20 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T17:53:20+00:00 NaN 4 5 0 1 89 .42 89 .419998 0 .000000 0 .000000 0 .000000 3 .458228 R 192 12 /17/2019 11 :15:57 0 0 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .000000 0 .000000 0 .000000 0 .000000 2019 -12-17T19:15:57+00:00 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 546943 546944 246 39 1958303 .97 23211 .070312 4 .459139 16 .402617 -0.691691 2 .700771 D 5 01 /09/2020 03 :18:48 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011044 4 .459139 8 .126739 16 .402617 2020 -01-09T11:18:48+00:00 NaN 546944 546945 246 39 1958305 .13 23212 .230469 4 .459362 16 .403219 -0.691691 2 .700008 D 133 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011044 4 .459362 8 .126739 16 .403219 2020 -01-09T11:18:49+00:00 NaN 546945 546946 247 41 1958305 .16 0 .030000 0 .000006 0 .000016 1 .618448 2 .760967 C 0 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011050 4 .459362 8 .126755 16 .403219 2020 -01-09T11:18:49+00:00 NaN 546946 546947 247 41 1958305 .32 0 .190000 0 .000078 0 .000215 1 .612268 2 .777752 C 5 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011122 4 .459362 8 .126954 16 .403219 2020 -01-09T11:18:49+00:00 NaN 546947 546948 247 41 1958305 .42 0 .290000 0 .000122 0 .000340 1 .612039 2 .784771 C 5 01 /09/2020 03 :18:49 64541 22 0 0 0 .0 0 .0 NaN NaN ... 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 0 .0 2 .011167 4 .459362 8 .127079 16 .403219 2020 -01-09T11:18:49+00:00 NaN [ 546948 rows x 44 columns ] <class 'pandas.core.frame.DataFrame' > RangeIndex: 546948 entries, 0 to 546947 Data columns ( total 44 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 data_point 546948 non-null int32 1 cycle_index 546948 non-null int32 2 step_index 546948 non-null int16 3 test_time 546948 non-null float64 4 step_time 546948 non-null float32 5 _capacity 546948 non-null float64 6 _energy 546948 non-null float64 7 current 546948 non-null float32 8 voltage 546948 non-null float32 9 _state 546948 non-null object 10 _ending_status 546948 non-null category 11 date_time 546948 non-null object 12 loop1 546948 non-null int64 13 loop2 546948 non-null int64 14 loop3 546948 non-null int64 15 loop4 546948 non-null int64 16 ac_impedence 546948 non-null float32 17 internal_resistance 546948 non-null float32 18 _wf_chg_cap 0 non-null float32 19 _wf_dis_cap 0 non-null float32 20 _wf_chg_e 0 non-null float32 21 _wf_dis_e 0 non-null float32 22 _range 546948 non-null uint8 23 _var1 546948 non-null float16 24 _var2 546948 non-null float16 25 _var3 546948 non-null float16 26 _var4 546948 non-null float16 27 _var5 546948 non-null float16 28 _var6 546948 non-null float16 29 _var7 546948 non-null float16 30 _var8 546948 non-null float16 31 _var9 546948 non-null float16 32 _var10 546948 non-null float16 33 _var11 546948 non-null float16 34 _var12 546948 non-null float16 35 _var13 546948 non-null float16 36 _var14 546948 non-null float16 37 _var15 546948 non-null float16 38 charge_capacity 546948 non-null float64 39 discharge_capacity 546948 non-null float64 40 charge_energy 546948 non-null float64 41 discharge_energy 546948 non-null float64 42 date_time_iso 546948 non-null object 43 temperature 0 non-null float64 dtypes: category ( 1 ) , float16 ( 15 ) , float32 ( 9 ) , float64 ( 8 ) , int16 ( 1 ) , int32 ( 2 ) , int64 ( 4 ) , object ( 3 ) , uint8 ( 1 ) memory usage: 103 .3+ MB","title":"Inspect Raw Files"},{"location":"Command%20Line%20Interface/7%20-%20inspect/#inspect-structured-files","text":"Example: $: beep inspect 2017 -12-04_4_65C-69per_6C_CH29_structured_new.json.gz 2021 -09-22 16 :04:01 INFO Loaded beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29_structured_new.json.gz as type <class 'beep.structure.arbin.ArbinDatapath' >. BEEP Datapath: beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29_structured_new.json.gz Semiunique id: 'barcode:EL151000429559-channel:28-protocol:2017-12-04_tests\\20170630-4_65C_69per_6C.sdu-schema:beep/validation_schemas/schema-arbin-lfp.yaml-structured:True-legacy:True-raw_path:beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv-structured_path:None' File paths { 'metadata' : 'beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29_Metadata.csv' , 'raw' : 'beep/tests/test_files/2017-12-04_4_65C-69per_6C_CH29.csv' } File metadata: { 'barcode' : 'EL151000429559' , 'channel_id' : 28 , 'protocol' : '2017-12-04_tests\\\\20170630-4_65C_69per_6C.sdu' } Validation schema: beep/validation_schemas/schema-arbin-lfp.yaml Structuring parameters: { 'charge_axis' : 'charge_capacity' , 'diagnostic_available' : False, 'diagnostic_resolution' : 500 , 'discharge_axis' : 'voltage' , 'full_fast_charge' : 0 .8, 'nominal_capacity' : 1 .1, 'resolution' : 1000 , 'v_range' : None } Structured attributes: structured_summary: cycle_index discharge_capacity charge_capacity discharge_energy charge_energy dc_internal_resistance temperature_maximum temperature_average temperature_minimum date_time_iso energy_efficiency charge_throughput energy_throughput charge_duration time_temperature_integrated paused CV_time CV_current 0 0 1 .940235 1 .432850 6 .142979 4 .725729 0 .029954 34 .222515 32 .666893 20 .699526 2017 -12-05T03:37:36+00:00 1 .299901 1 .432850 4 .725729 32768 .0 48977 .078333 13312 50158 .164062 0 .000029 1 1 1 .060343 1 .061786 3 .219735 3 .703581 0 .017906 35 .375809 32 .387295 30 .235437 2017 -12-06T04:33:04+00:00 0 .869357 2 .494636 8 .429310 640 .0 1927 .509119 0 1577 .987427 0 .062837 2 2 1 .065412 1 .065450 3 .235807 3 .708392 0 .017649 35 .384602 32 .472481 30 .254265 2017 -12-06T05:32:48+00:00 0 .872563 3 .560086 12 .137702 640 .0 1931 .514632 0 1570 .970459 0 .046215 3 3 1 .066605 1 .066726 3 .238866 3 .711425 0 .017506 35 .265358 32 .420013 30 .159765 2017 -12-06T06:32:32+00:00 0 .872675 4 .626812 15 .849127 640 .0 1995 .445402 0 1552 .032471 0 .045087 4 4 1 .066988 1 .067148 3 .239955 3 .712645 0 .017409 35 .280449 32 .407478 30 .157305 2017 -12-06T07:34:24+00:00 0 .872681 5 .693960 19 .561773 512 .0 1926 .752726 0 1548 .414551 0 .052290 .. ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 183 183 1 .033595 1 .033812 3 .046869 3 .615792 0 .016889 37 .566158 32 .988796 30 .226278 2017 -12-13T19:12:00+00:00 0 .842656 194 .065491 676 .183533 640 .0 2026 .858687 0 1590 .061523 0 .034429 184 184 1 .033454 1 .033584 3 .042845 3 .613951 0 .016827 37 .129795 32 .981796 30 .181578 2017 -12-13T20:13:52+00:00 0 .841972 195 .099075 679 .797485 640 .0 1955 .320325 0 1589 .661377 0 .031118 185 185 1 .032677 1 .032898 3 .040163 3 .612450 0 .016875 37 .126766 32 .851368 30 .145836 2017 -12-13T21:13:36+00:00 0 .841579 196 .131973 683 .409912 640 .0 1950 .674312 0 1530 .225342 0 .021825 186 186 1 .032823 1 .033198 3 .041561 3 .613732 0 .016875 37 .236954 32 .925690 30 .300278 2017 -12-13T22:13:20+00:00 0 .841668 197 .165176 687 .023682 640 .0 1954 .338322 0 1590 .264771 0 .026628 187 187 1 .032616 1 .032862 3 .039321 3 .612212 0 .016840 37 .159687 32 .952461 30 .114653 2017 -12-13T23:13:04+00:00 0 .841402 198 .198029 690 .635864 640 .0 1955 .141357 0 1590 .173706 0 .025024 [ 188 rows x 18 columns ] <class 'pandas.core.frame.DataFrame' > RangeIndex: 188 entries, 0 to 187 Data columns ( total 18 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 cycle_index 188 non-null int32 1 discharge_capacity 188 non-null float64 2 charge_capacity 188 non-null float64 3 discharge_energy 188 non-null float64 4 charge_energy 188 non-null float64 5 dc_internal_resistance 188 non-null float32 6 temperature_maximum 188 non-null float32 7 temperature_average 188 non-null float32 8 temperature_minimum 188 non-null float32 9 date_time_iso 188 non-null object 10 energy_efficiency 188 non-null float32 11 charge_throughput 188 non-null float32 12 energy_throughput 188 non-null float32 13 charge_duration 188 non-null float32 14 time_temperature_integrated 188 non-null float64 15 paused 188 non-null int32 16 CV_time 188 non-null float32 17 CV_current 188 non-null float32 dtypes: float32 ( 10 ) , float64 ( 5 ) , int32 ( 2 ) , object ( 1 ) memory usage: 17 .8+ KB None structured_data: voltage test_time current charge_capacity discharge_capacity charge_energy discharge_energy internal_resistance temperature cycle_index step_type 0 2 .800000 88438 .740972 -3.070090 1 .319212 1 .788713 4 .354456 5 .709161 0 .028598 31 .529890 0 discharge 1 2 .800701 85441 .894275 -4.256237 1 .370451 1 .831461 4 .519928 5 .826991 0 .029763 32 .309685 0 discharge 2 2 .801401 58527 .144191 -3.221379 0 .921136 1 .386086 3 .038029 4 .406347 0 .028391 32 .847729 0 discharge 3 2 .802102 31612 .394108 -2.186522 0 .471821 0 .940710 1 .556129 2 .985704 0 .027020 33 .385773 0 discharge 4 2 .802803 4697 .644024 -1.151665 0 .022506 0 .495335 0 .074230 1 .565060 0 .025648 33 .923817 0 discharge ... ... ... ... ... ... ... ... ... ... ... ... 375995 NaN NaN NaN 1 .427113 NaN NaN NaN NaN NaN 187 charge 375996 NaN NaN NaN 1 .428547 NaN NaN NaN NaN NaN 187 charge 375997 NaN NaN NaN 1 .429981 NaN NaN NaN NaN NaN 187 charge 375998 NaN NaN NaN 1 .431416 NaN NaN NaN NaN NaN 187 charge 375999 NaN NaN NaN 1 .432850 NaN NaN NaN NaN NaN 187 charge [ 376000 rows x 11 columns ] <class 'pandas.core.frame.DataFrame' > RangeIndex: 376000 entries, 0 to 375999 Data columns ( total 11 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 voltage 325974 non-null float32 1 test_time 325974 non-null float64 2 current 325974 non-null float32 3 charge_capacity 376000 non-null float32 4 discharge_capacity 325974 non-null float32 5 charge_energy 325974 non-null float32 6 discharge_energy 325974 non-null float32 7 internal_resistance 325974 non-null float32 8 temperature 325974 non-null float32 9 cycle_index 376000 non-null int32 10 step_type 376000 non-null category dtypes: category ( 1 ) , float32 ( 8 ) , float64 ( 1 ) , int32 ( 1 ) memory usage: 16 .1 MB None diagnostic_data: No object. diagnostic_summary: No object. raw_data: No object.","title":"Inspect Structured Files"},{"location":"Command%20Line%20Interface/7%20-%20inspect/#inspect-feature-matrices","text":"Example: S: beep inspect FeatureMatrix-2021-21-09_20.50.32.550211.json.gz 2021 -09-22 15 :54:23 INFO Loaded FeatureMatrix-2021-21-09_20.50.32.550211.json.gz as type <class 'beep.features.base.BEEPFeatureMatrix' >. BEEP Feature Matrix: FeatureMatrix-2021-21-09_20.50.32.550211.json.gz Featurizers: Featurizer beep.features.core HPPCResistanceVoltageFeatures { '@class' : 'HPPCResistanceVoltageFeatures' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_index_filter' : 6 , 'diag_pos' : 1 , 'parameters_path' : 'beep/protocol_parameters' , 'soc_window' : 8 , 'test_time_filter_sec' : 1000000 } , 'linked_datapath_semiunique_id' : 'barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PreDiag_000440_0000FB_structure.json' , 'metadata' : { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PreDiag_000440_0000FB_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 10 , 100 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PreDiag_000440_0000FB_structure.json' , 'metadata' : { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PreDiag_000440_0000FB_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 11 , 101 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PreDiag_000440_0000FB_structure.json' , 'metadata' : { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PreDiag_000440_0000FB_structure.json' }} Featurizer beep.features.core HPPCResistanceVoltageFeatures { '@class' : 'HPPCResistanceVoltageFeatures' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_index_filter' : 6 , 'diag_pos' : 1 , 'parameters_path' : 'beep/protocol_parameters' , 'soc_window' : 8 , 'test_time_filter_sec' : 1000000 } , 'linked_datapath_semiunique_id' : 'barcode:00004C-channel:33-protocol:PredictionDiagnostics_000132.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' , 'metadata' : { 'barcode' : '00004C' , 'channel_id' : 33 , 'protocol' : 'PredictionDiagnostics_000132.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 10 , 100 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:00004C-channel:33-protocol:PredictionDiagnostics_000132.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' , 'metadata' : { 'barcode' : '00004C' , 'channel_id' : 33 , 'protocol' : 'PredictionDiagnostics_000132.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' }} Featurizer beep.features.core CycleSummaryStats { '@class' : 'CycleSummaryStats' , '@module' : 'beep.features.core' , 'hyperparameters' : { 'cycle_comp_num' : [ 11 , 101 ] , 'statistics' : [ 'var' , 'min' , 'mean' , 'skew' , 'kurtosis' , 'abs' , 'square' ]} , 'linked_datapath_semiunique_id' : 'barcode:00004C-channel:33-protocol:PredictionDiagnostics_000132.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' , 'metadata' : { 'barcode' : '00004C' , 'channel_id' : 33 , 'protocol' : 'PredictionDiagnostics_000132.000' } , 'paths' : { 'structured' : 'beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json' }} Matrix: D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 ... var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 filename ... beep/tests/tes... -0.075467 ... 0 .000186 beep/tests/tes... -0.090097 ... 0 .002462 [ 2 rows x 132 columns ] <class 'pandas.core.frame.DataFrame' > Index: 2 entries, beep/tests/test_files/PreDiag_000440_0000FB_structure.json to beep/tests/test_files/PredictionDiagnostics_000132_00004C_structure.json Columns: 132 entries, D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 to var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 dtypes: float64 ( 132 ) memory usage: 2 .1+ KB","title":"Inspect Feature Matrices"},{"location":"Command%20Line%20Interface/7%20-%20inspect/#inspect-featurizers","text":"Example: $: beep inspect HPPCFeaturizer.json.gz 2021 -09-22 16 :06:42 INFO Loaded beep/tests/test_files/modelling_test_files/HPPCFeaturizer.json.gz as type <class 'beep.features.core.HPPCResistanceVoltageFeatures' >. BEEP Featurizer: beep/tests/test_files/modelling_test_files/HPPCFeaturizer.json.gz File paths: { 'structured' : 'beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json' } Linked datapath semiunique id: barcode:0000FB-channel:50-protocol:PreDiag_000440.000-schema:None-structured:True-legacy:True-raw_path:None-structured_path:beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json Hyperparameters: { 'cycle_index_filter' : 6 , 'diag_pos' : 1 , 'parameters_path' : 'beep/protocol_parameters' , 'soc_window' : 8 , 'test_time_filter_sec' : 1000000 } Metadata: { 'barcode' : '0000FB' , 'channel_id' : 50 , 'protocol' : 'PreDiag_000440.000' } Features: r_c_0s_00 r_c_0s_10 r_c_0s_20 r_c_0s_30 r_c_0s_40 r_c_0s_50 r_c_0s_60 r_c_0s_70 r_c_0s_80 r_c_3s_00 r_c_3s_10 r_c_3s_20 r_c_3s_30 r_c_3s_40 r_c_3s_50 r_c_3s_60 r_c_3s_70 r_c_3s_80 r_c_end_00 ... skew_ocv kurtosis_ocv sum_ocv sum_square_ocv var_v_diff min_v_diff mean_v_diff skew_v_diff kurtosis_v_diff sum_v_diff sum_square_v_diff D_1 D_2 D_3 D_4 D_5 D_6 D_7 D_8 0 -0.056034 -0.063766 -0.07963 -0.105001 -0.091609 -0.095464 -0.073553 -0.06692 -0.064657 -0.037199 -0.071951 -0.077876 -0.128588 -0.103652 -0.106871 -0.096638 -0.066802 -0.074038 -0.053153 ... 1 .674431 7 .472183 0 .045535 0 .000641 0 .000186 -0.00181 0 .012954 0 .887649 2 .940287 14 .16811 0 .373482 -0.075467 -0.097516 -0.230871 -0.163967 -0.158305 -0.137443 0 .070989 0 .098653 [ 1 rows x 76 columns ]","title":"Inspect Featurizers"},{"location":"Command%20Line%20Interface/7%20-%20inspect/#inspect-models","text":"Example: $: beep inspect model-src.json.gz 2021 -09-22 16 :06:04 WARNING Number of samples ( 4 ) less than number of features ( 179 ) ; may cause overfitting. 2021 -09-22 16 :06:04 INFO Loaded beep/tests/test_files/modelling_test_files/model-src.json.gz as type <class 'beep.model.BEEPLinearModelExperiment' >. BEEP Linear Model Experiment: beep/tests/test_files/modelling_test_files/model-src.json.gz Targets: [ 'capacity_0.92::TrajectoryFastCharge' ] Model name: lasso Impute strategy: median Homogenize features: True NaN Thresholds: -train_feature_drop_nan_thresh: 0 .95 -train_sample_drop_nan_thresh: 0 .5 -predict_sample_nan_thresh: 0 .75 Model parameters: - coef_: [ 0 .0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, -0.0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, -0.0, -0.0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, 0 .0, 0 .0, -0.0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, 0 .0, -0.0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, 0 .0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0 .0, -0.0, -0.0, -0.0 ] - intercept_: 113 .25 - optimal_hyperparameters: { 'alpha' : 98 .35818271439722 } Matrices: feature_matrix D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 ... var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 filename ... beep/CLI_TEST_... -0.075467 ... 0 .000186 beep/CLI_TEST_... -0.090097 ... 0 .002462 beep/CLI_TEST_... -0.145030 ... 0 .002416 beep/CLI_TEST_... -0.052108 ... 0 .000848 [ 4 rows x 179 columns ] <class 'pandas.core.frame.DataFrame' > Index: 4 entries, beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json to beep/CLI_TEST_FILES_FEATURIZATION/PredictionDiagnostics_000136_00002D_structure.json Columns: 179 entries, D_1::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 to var_v_diff::HPPCResistanceVoltageFeatures::6262aa8b2c9ce9530d53f73943e5b465a1946f39be2ad2a3ede05f49e6f9f2d2 dtypes: float64 ( 179 ) memory usage: 5 .6+ KB None target_matrix capacity_0.83::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 ... rpt_1Cdischarge_energy0.8_real_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e filename ... beep/CLI_TEST_... 284 ... NaN beep/CLI_TEST_... 58 ... 1266 .108637 beep/CLI_TEST_... 85 ... NaN beep/CLI_TEST_... 101 ... NaN [ 4 rows x 11 columns ] <class 'pandas.core.frame.DataFrame' > Index: 4 entries, beep/CLI_TEST_FILES_FEATURIZATION/PreDiag_000440_0000FB_structure.json to beep/CLI_TEST_FILES_FEATURIZATION/PredictionDiagnostics_000136_00002D_structure.json Data columns ( total 11 columns ) : # Column Non-Null Count Dtype --- ------ -------------- ----- 0 capacity_0.83::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 1 capacity_0.86::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 2 capacity_0.89::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 3 capacity_0.8::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 4 capacity_0.92::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 5 capacity_0.95::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 6 capacity_0.98::TrajectoryFastCharge::319cec55cc030c1911b2530cae3fc2df8d3c24912ae01ee4172ea4ca4caddec8 4 non-null int64 7 initial_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 8 rpt_1Cdischarge_energy0.8_cycle_index::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 9 rpt_1Cdischarge_energy0.8_normalized_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 10 rpt_1Cdischarge_energy0.8_real_regular_throughput::DiagnosticProperties::9fb32356773f0c4f8c27fc9528ca4a986dc928fbadbd859b67a8892e7daac72e 1 non-null float64 dtypes: float64 ( 4 ) , int64 ( 7 ) memory usage: 556 .0+ bytes","title":"Inspect Models"},{"location":"Python%20tutorials/1%20-%20quickstart/","text":"1: Quickstart \u00b6 This notebook is meant to demonstrate basic usage of the beep package with data from \"Data-driven prediction of battery cycle life before capacity degradation\" KA Severson, et al. Nature Energy 4 (5), 383-391 This data is available for download from https://data.matr.io/1/ . For brevity, only one test is included in this notebook but the example can easily be extended to a larger number of files. Step 0: Install beep and set environment \u00b6 If you have not already installed beep, run: pip install beep Step 1: Download example battery cycler data \u00b6 The example data set we are using here comes from a set of A123 LFP cells cycled under fast charge conditions. While this tutorial is configured for downloading a single cell, its also possible to download the entire data set and run all of the processing steps on all of the data. Note that for Arbin files, we recommend having the metadata file in addition to the data file in order to perform the data structuring correctly (though it is not required). import os import requests print ( 'Beginning file download with requests' ) this_dir = os . path . dirname ( os . path . abspath ( __file__ )) data_dir = os . path . join ( this_dir , 'Severson-et-al' ) try : os . makedirs ( data_dir ) except FileExistsError : pass url = 'https://data.matr.io/1/api/v1/file/5c86c0bafa2ede00015ddf70/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36.csv' ), 'wb' ) as f : f . write ( r . content ) url = 'https://data.matr.io/1/api/v1/file/5c86c0b5fa2ede00015ddf6d/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36_Metadata.csv' ), 'wb' ) as f : f . write ( r . content ) # Retrieve HTTP meta-data print ( \"Status code\" , r . status_code ) print ( \"File type recieved\" , r . headers [ 'content-type' ]) print ( \"File encoding\" , r . encoding ) # output Beginning file download with requests Status code 200 File type recieved text/csv File encoding ISO-8859-1 You should now have two files in your data directory: \u251c\u2500\u2500 Severson-et-al \u2502 \u251c\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36.csv \u2502 \u2514\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36_Metadata.csv Step 2: Structure and analyze data \u00b6 Now that we have our data, we can start using BEEP! To structure a file in beep using python, we use the auto_load function to get a BEEPDatapath object; BEEPDatapath holds everything we need to identify cycler type, load, validate, interpolate, standardize, and analyze our file. import os from beep.structure.cli import auto_load this_dir = os . path . dirname ( os . path . abspath ( __file__ )) cycler_file = os . path . join ( this_dir , \"Severson-et-al/2017-05-12_6C-50per_3_6C_CH36.csv\" ) datapath = auto_load ( cycler_file ) We can check our file is valid with validate : is_valid , msg = datapath . validate () print ( \"File is valid: \" , is_valid ) # Output File is valid: True We can easily interpolate and prepare our file for analysis (known as \"structuring\") with the structure method: datapath . structure () Now that our file has been structured, we can examine some interesting properties, such as the charge capacity vs. the voltage. from matplotlib import pyplot as plt reg_charge = datapath . structured_data [ datapath . structured_data . step_type == 'charge' ] print ( \"Mean current for cycle 25: \" , reg_charge . current [ reg_charge . cycle_index == 25 ] . mean ()) print ( \"Number of cycles: \" , reg_charge . cycle_index . max ()) print ( \"Max charge capacity at cycle 25: \" , reg_charge . charge_capacity [ reg_charge . cycle_index == 25 ] . max ()) plt . plot ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ], reg_charge . voltage [ reg_charge . cycle_index == 600 ]) plt . show () # output Mean current for cycle 25: 4.697416 Number of cycles: 876 Max charge capacity at cycle 25: 1.1737735 We can also view some interesting data about the energy efficiency as the cycles progress: plt . plot ( datapath . structured_summary . cycle_index , datapath . structured_summary . energy_efficiency ) plt . show () More info on BEEPDatapath Step 3: Prepare for machine learning and train a model \u00b6 Featurization uses the structured objects to calculate statistically and physically relevant quantities for the purpose of building predictive machine learning models. The objects can be selected and joined for the purposes of training the model, or used for predicting individual outcomes. beep provides classes such as BEEPFeaturizer and BEEPFeatureMatrix for generating and managing sets of features linked to structured files. beep also provides BEEPLinearModelExperiment , a class for training linear machine learning models on battery data and predicting new degradation characteristics. Quickstart sections on featurization and machine learning are coming soon! Congrats! \u00b6 You've made it to the end of the tutorial.","title":"1: Quickstart"},{"location":"Python%20tutorials/1%20-%20quickstart/#1-quickstart","text":"This notebook is meant to demonstrate basic usage of the beep package with data from \"Data-driven prediction of battery cycle life before capacity degradation\" KA Severson, et al. Nature Energy 4 (5), 383-391 This data is available for download from https://data.matr.io/1/ . For brevity, only one test is included in this notebook but the example can easily be extended to a larger number of files.","title":"1: Quickstart"},{"location":"Python%20tutorials/1%20-%20quickstart/#step-0-install-beep-and-set-environment","text":"If you have not already installed beep, run: pip install beep","title":"Step 0: Install beep and set environment"},{"location":"Python%20tutorials/1%20-%20quickstart/#step-1-download-example-battery-cycler-data","text":"The example data set we are using here comes from a set of A123 LFP cells cycled under fast charge conditions. While this tutorial is configured for downloading a single cell, its also possible to download the entire data set and run all of the processing steps on all of the data. Note that for Arbin files, we recommend having the metadata file in addition to the data file in order to perform the data structuring correctly (though it is not required). import os import requests print ( 'Beginning file download with requests' ) this_dir = os . path . dirname ( os . path . abspath ( __file__ )) data_dir = os . path . join ( this_dir , 'Severson-et-al' ) try : os . makedirs ( data_dir ) except FileExistsError : pass url = 'https://data.matr.io/1/api/v1/file/5c86c0bafa2ede00015ddf70/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36.csv' ), 'wb' ) as f : f . write ( r . content ) url = 'https://data.matr.io/1/api/v1/file/5c86c0b5fa2ede00015ddf6d/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36_Metadata.csv' ), 'wb' ) as f : f . write ( r . content ) # Retrieve HTTP meta-data print ( \"Status code\" , r . status_code ) print ( \"File type recieved\" , r . headers [ 'content-type' ]) print ( \"File encoding\" , r . encoding ) # output Beginning file download with requests Status code 200 File type recieved text/csv File encoding ISO-8859-1 You should now have two files in your data directory: \u251c\u2500\u2500 Severson-et-al \u2502 \u251c\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36.csv \u2502 \u2514\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36_Metadata.csv","title":"Step 1: Download example battery cycler data"},{"location":"Python%20tutorials/1%20-%20quickstart/#step-2-structure-and-analyze-data","text":"Now that we have our data, we can start using BEEP! To structure a file in beep using python, we use the auto_load function to get a BEEPDatapath object; BEEPDatapath holds everything we need to identify cycler type, load, validate, interpolate, standardize, and analyze our file. import os from beep.structure.cli import auto_load this_dir = os . path . dirname ( os . path . abspath ( __file__ )) cycler_file = os . path . join ( this_dir , \"Severson-et-al/2017-05-12_6C-50per_3_6C_CH36.csv\" ) datapath = auto_load ( cycler_file ) We can check our file is valid with validate : is_valid , msg = datapath . validate () print ( \"File is valid: \" , is_valid ) # Output File is valid: True We can easily interpolate and prepare our file for analysis (known as \"structuring\") with the structure method: datapath . structure () Now that our file has been structured, we can examine some interesting properties, such as the charge capacity vs. the voltage. from matplotlib import pyplot as plt reg_charge = datapath . structured_data [ datapath . structured_data . step_type == 'charge' ] print ( \"Mean current for cycle 25: \" , reg_charge . current [ reg_charge . cycle_index == 25 ] . mean ()) print ( \"Number of cycles: \" , reg_charge . cycle_index . max ()) print ( \"Max charge capacity at cycle 25: \" , reg_charge . charge_capacity [ reg_charge . cycle_index == 25 ] . max ()) plt . plot ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ], reg_charge . voltage [ reg_charge . cycle_index == 600 ]) plt . show () # output Mean current for cycle 25: 4.697416 Number of cycles: 876 Max charge capacity at cycle 25: 1.1737735 We can also view some interesting data about the energy efficiency as the cycles progress: plt . plot ( datapath . structured_summary . cycle_index , datapath . structured_summary . energy_efficiency ) plt . show () More info on BEEPDatapath","title":"Step 2: Structure and analyze data"},{"location":"Python%20tutorials/1%20-%20quickstart/#step-3-prepare-for-machine-learning-and-train-a-model","text":"Featurization uses the structured objects to calculate statistically and physically relevant quantities for the purpose of building predictive machine learning models. The objects can be selected and joined for the purposes of training the model, or used for predicting individual outcomes. beep provides classes such as BEEPFeaturizer and BEEPFeatureMatrix for generating and managing sets of features linked to structured files. beep also provides BEEPLinearModelExperiment , a class for training linear machine learning models on battery data and predicting new degradation characteristics. Quickstart sections on featurization and machine learning are coming soon!","title":"Step 3: Prepare for machine learning and train a model"},{"location":"Python%20tutorials/1%20-%20quickstart/#congrats","text":"You've made it to the end of the tutorial.","title":"Congrats!"},{"location":"Python%20tutorials/2%20-%20structuring/","text":"2: Structuring \u00b6 Here you'll find more info about creating and using beep to do your own custom cycler analyses. BEEPDatapath - One object for ingestion, structuring, and validation Batch functions for structuring Featurization Running and analyzing models Structuring with BEEPDatapath \u00b6 One class for ingestion, structuring, and validation \u00b6 BEEPDatapath is an abstract base class that can handle ingestion, structuring, and validation for many types of cyclers. A datapath object represents a complete processing pipeline for battery cycler data. Each cycler has it's own BEEPDatapath class: ArbinDatapath MaccorDatapath NewareDatapath IndigoDatapath BiologicDatapath All these datapaths implement the same core methods, properties, and attributes, listed below: Methods for loading and serializing battery cycler data \u00b6 *Datapath.from_file(filename) \u00b6 Classmethod to load a raw cycler output file (e.g., a csv) into a datapath object. Once loaded, you can validate or structure the file. # Here we use ArbinDatapath as an example from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" ) *Datapath.to_json_file(filename) \u00b6 Dump the current state of a datapath to a file. Can be later loaded with from_json_file . from beep.structure import NewareDatapath datapath = NewareDatapath . from_file ( \"/path/to/my_raw_neware_file\" ) # do some operations ... # Write the processed file to disk, which can then be loaded. datapath . to_json_file ( \"my_processed_neware_data.json\" ) *Datapath.from_json_file(filename) \u00b6 Classmethod to load a processed cycler file (e.g., a previously structured Datapath) into a datapath object. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_json_file ( \"my_previously_serialized_datapath.json\" ) *Datapath(data, metadata, paths=None, **kwargs) \u00b6 Initialize any cycler from the raw data (given as a pandas dataframe) and metadata (given as a dictionary). Paths can be included to keep track of where various cycler files are located. Note: This is not the recommended way to create a BEEPDatapath , as data and metadata must have specific formats to load and structure correctly. Validation and structuring with BEEPDatapath s \u00b6 *Datapath.validate() \u00b6 Validate your raw data. Will return true if the raw data is valid for your cycler (i.e., can be structured successfully). from beep.structure import IndigoDatapath datapath = IndigoDatapath . from_file ( \"/path/to/my_indigo_file\" ) is_valid = datapath . validate () print ( is_valid ) # Out: # True or False *Datapath.structure(*args) \u00b6 Interpolate and structure your data using specified arguments. Once structured, your BEEPDatapath is able to access things like the diagnostic summary, interpolated cycles, cycle summary, diagnostic summary, cycle life, and more (see Analysis and attributes of core attributes of BEEPDatapath ) from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" ) # Structure your data by manually specifying parameters. datapath . structure ( v_range = [ 1.2 , 3.5 ], nominal_capacity = 1.2 , full_fast_charge = 0.85 ) *Datapath.autostructure() \u00b6 Run structuring using automatically determined parameters. BEEP can automatically detect the structuring parameters based on your raw data. Note: The BEEP environment variable BEEP_PROCESSING_DIR must be set before autostructuring, and this directory must contain a parameters file which can be used for determine_structuring_parameters . from beep.structure import BiologicDatapath datapath = BiologicDatapath . from_file ( \"path/to/my/biologic_data_file\" ) # Automatically determines structuring parameters and structures data datapath . autostructure () Analysis and core attributes of BEEPDatapath \u00b6 *Datapath.paths \u00b6 Access all paths of files related to this datapath. paths is a simple mapping of {file_description: file_path} which holds the paths of all files related to this datapath, including raw data, metadata, EIS files, and structured outputs. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . paths ) # Out: { \"raw\" : \"/path/to/my_arbin_file.csv\" , \"metadata\" : \"/path/to/my_arbin_file_Metadata.csv\" } *Datapath.structuring_parameters \u00b6 Parameters used to structure BEEPDatapaths : from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) datapath . autostructure () print ( datapath . structuring_parameters ) # Out: { 'v_range' : None , 'resolution' : 1000 , 'diagnostic_resolution' : 500 , 'nominal_capacity' : 1.1 , 'full_fast_charge' : 0.8 , 'diagnostic_available' : False , 'charge_axis' : 'charge_capacity' , 'discharge_axis' : 'voltage' } *Datapath.raw_data \u00b6 The raw data, loaded into a standardized dataframe format, of this datapath's battery cycler data. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . raw_data ) # Out: data_point test_time ... temperature date_time_iso 0 0 0.0021 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 1 1 1.0014 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 2 2 1.1165 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 3 3 2.1174 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 4 4 12.1782 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 ... ... ... ... ... ... 251258 251258 30545.2000 ... 32.595604 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251259 251259 30545.2000 ... 32.555054 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251260 251260 30550.1970 ... 32.555054 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251261 251261 30550.1970 ... 32.545870 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251262 251262 30555.1970 ... 32.445827 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 *Datapath.metadata \u00b6 An object holding all metadata for this datapath's cycler run. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . metadata . barcode ) print ( datapath . metadata . channel_id ) print ( datapath . metadata . protocol ) print ( datapath . metadata . raw ) # Out: \"EL151000429559\" 28 '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' { 'test_id' : 296 , 'device_id' : 60369369 , 'channel_id' : 28 , 'start_datetime' : 1512445026 , '_resumed_times' : 0 , 'last_resume_datetime' : 0 , '_last_end_datetime' : 1512514129 , 'protocol' : '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' , '_databases' : 'ArbinResult_43,ArbinResult_44,ArbinResult_45,' , 'barcode' : 'EL151000429559' , '_grade_id' : 0 , '_has_aux' : 3 , '_has_special' : 0 , '_schedule_version' : 'Schedule Version 7.00.08' , '_log_aux_data_flag' : 1 , '_log_special_data_flag' : 0 , '_rowstate' : 0 , '_canconfig_filename' : nan , '_m_ncanconfigmd5' : nan , '_value' : 0.0 , '_value2' : 0.0 } *Datapath.structured_data \u00b6 The structured (interpolated) data, as a dataframe. The format is similar to that of .raw_data . The datapath must be structured before this attribute is available. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) datapath . autostructure () print ( datapath . structured_data ) # Out: voltage test_time current ... temperature cycle_index step_type 0 2.500000 NaN NaN ... NaN 0 discharge 1 2.501702 NaN NaN ... NaN 0 discharge 2 2.503403 NaN NaN ... NaN 0 discharge 3 2.505105 NaN NaN ... NaN 0 discharge 4 2.506807 NaN NaN ... NaN 0 discharge ... ... ... ... ... ... ... 461995 NaN NaN NaN ... NaN 245 charge 461996 NaN NaN NaN ... NaN 245 charge 461997 NaN NaN NaN ... NaN 245 charge 461998 NaN NaN NaN ... NaN 245 charge 461999 NaN NaN NaN ... NaN 245 charge *Datapath.structured_summary \u00b6 A summary of the structured cycler data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . structured_summary ) # Out: cycle_index discharge_capacity charge_capacity discharge_energy charge_energy dc_internal_resistance temperature_maximum temperature_average temperature_minimum date_time_iso energy_efficiency charge_throughput energy_throughput charge_duration time_temperature_integrated paused cycle_index 0 0 4.719281 3.827053 17.273731 14.901985 0.0 NaN NaN NaN 2019 - 12 - 17 T17 : 51 : 51 + 00 : 00 1.159156 3.827053 14.901985 NaN NaN 4957 6 6 2.074518 4.406801 7.677041 16.997186 0.0 NaN NaN NaN 2019 - 12 - 20 T13 : 14 : 40 + 00 : 00 0.451665 8.233854 31.899172 5791.0 NaN 0 7 7 2.097911 2.108322 7.775166 8.597635 0.0 NaN NaN NaN 2019 - 12 - 20 T15 : 51 : 34 + 00 : 00 0.904338 10.342176 40.496807 NaN NaN 0 8 8 2.074545 2.098428 7.684986 8.557546 0.0 NaN NaN NaN 2019 - 12 - 20 T17 : 32 : 21 + 00 : 00 0.898036 12.440605 49.054352 NaN NaN 0 9 9 2.074061 2.082069 7.685348 8.494265 0.0 NaN NaN NaN 2019 - 12 - 20 T19 : 12 : 46 + 00 : 00 0.904769 14.522674 57.548618 NaN NaN 0 10 10 2.065671 2.069061 7.655246 8.441246 0.0 NaN NaN NaN 2019 - 12 - 20 T20 : 52 : 53 + 00 : 00 0.906886 16.591734 65.989861 NaN NaN 0 11 11 2.064542 2.068921 7.651949 8.439011 0.0 NaN NaN NaN 2019 - 12 - 20 T22 : 32 : 38 + 00 : 00 0.906735 18.660656 74.428871 NaN NaN 0 12 12 2.068333 2.061454 7.666199 8.409441 0.0 NaN NaN NaN 2019 - 12 - 21 T00 : 12 : 35 + 00 : 00 0.911618 20.722109 82.838318 NaN NaN 0 13 13 2.054566 2.067370 7.616584 8.431127 0.0 NaN NaN NaN 2019 - 12 - 21 T01 : 52 : 14 + 00 : 00 0.903389 22.789478 91.269440 NaN NaN 0 14 14 2.061369 2.057715 7.647454 8.394535 0.0 NaN NaN NaN 2019 - 12 - 21 T03 : 31 : 54 + 00 : 00 0.911004 24.847195 99.663979 NaN NaN 0 15 15 2.050721 2.059819 7.602874 8.401562 0.0 NaN NaN NaN 2019 - 12 - 21 T05 : 11 : 24 + 00 : 00 0.904936 26.907013 108.065536 NaN NaN 0 16 16 2.055427 2.057405 7.622452 8.393292 0.0 NaN NaN NaN 2019 - 12 - 21 T06 : 50 : 57 + 00 : 00 0.908160 28.964418 116.458832 NaN NaN 0 17 17 2.045344 2.049606 7.583858 8.360918 0.0 NaN NaN NaN 2019 - 12 - 21 T08 : 30 : 36 + 00 : 00 0.907060 31.014025 124.819748 NaN NaN 0 18 18 2.047280 2.046608 7.591624 8.347446 0.0 NaN NaN NaN 2019 - 12 - 21 T10 : 09 : 56 + 00 : 00 0.909455 33.060631 133.167191 NaN NaN 0 19 19 2.055454 2.046478 7.623849 8.347916 0.0 NaN NaN NaN 2019 - 12 - 21 T11 : 49 : 18 + 00 : 00 0.913264 35.107109 141.515106 NaN NaN 0 20 20 2.043676 2.055780 7.579766 8.383341 0.0 NaN NaN NaN 2019 - 12 - 21 T13 : 28 : 39 + 00 : 00 0.904146 37.162891 149.898453 NaN NaN 0 21 21 2.049323 2.046085 7.605977 8.346517 0.0 NaN NaN NaN 2019 - 12 - 21 T15 : 08 : 10 + 00 : 00 0.911276 39.208977 158.244965 NaN NaN 0 22 22 2.038514 2.047097 7.560916 8.349430 0.0 NaN NaN NaN 2019 - 12 - 21 T16 : 47 : 22 + 00 : 00 0.905561 41.256073 166.594406 NaN NaN 0 23 23 2.044779 2.045038 7.585164 8.342201 0.0 NaN NaN NaN 2019 - 12 - 21 T18 : 26 : 38 + 00 : 00 0.909252 43.301109 174.936600 NaN NaN 0 24 24 2.039805 2.039563 7.567169 8.319416 0.0 NaN NaN NaN 2019 - 12 - 21 T20 : 06 : 10 + 00 : 00 0.909579 45.340672 183.256012 NaN NaN 0 25 25 2.039563 2.040318 7.566332 8.320876 0.0 NaN NaN NaN 2019 - 12 - 21 T21 : 45 : 20 + 00 : 00 0.909319 47.380993 191.576889 NaN NaN 0 26 26 2.052362 2.038989 7.616830 8.316606 0.0 NaN NaN NaN 2019 - 12 - 21 T23 : 24 : 33 + 00 : 00 0.915858 49.419979 199.893494 NaN NaN 0 27 27 2.035744 2.051446 7.552814 8.364671 0.0 NaN NaN NaN 2019 - 12 - 22 T01 : 03 : 48 + 00 : 00 0.902942 51.471428 208.258163 NaN NaN 0 28 28 2.039347 2.041048 7.568011 8.325755 0.0 NaN NaN NaN 2019 - 12 - 22 T02 : 43 : 14 + 00 : 00 0.908988 53.512474 216.583923 NaN NaN 0 *Datapath.diagnostic_data \u00b6 The structured (interpolated) data for diagnostic cycles, as a dataframe. The format is similar to that of .structured_data . The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_data ) # Out: voltage test_time current ... step_type discharge_dQdV charge_dQdV 0 2.700000 NaN NaN ... 0 NaN NaN 1 2.703006 NaN NaN ... 0 NaN NaN 2 2.706012 NaN NaN ... 0 NaN NaN 3 2.709018 NaN NaN ... 0 NaN NaN 4 2.712024 NaN NaN ... 0 NaN NaN ... ... ... ... ... ... ... 44434 2.782701 1958305.375 1.612107 ... 0 0.0 0.006379 44435 2.783219 1958305.375 1.612090 ... 0 0.0 0.006379 44436 2.783736 1958305.375 1.612073 ... 0 0.0 0.006379 44437 2.784254 1958305.375 1.612056 ... 0 0.0 0.006379 44438 2.784771 1958305.375 1.612039 ... 0 0.0 0.006379 [ 44439 rows x 16 columns ] *Datapath.diagnostic_summary \u00b6 A summary of the structured diagnostic cycle data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_summary ) # Out: cycle_index discharge_capacity ... paused cycle_type 0 1 4.711819 ... 0 reset 1 2 4.807243 ... 0 hppc 2 3 4.648884 ... 0 rpt_0 .2 C 3 4 4.525516 ... 0 rpt_1C 4 5 4.482939 ... 0 rpt_2C 5 36 4.624467 ... 0 reset 6 37 4.722887 ... 0 hppc 7 38 4.584861 ... 0 rpt_0 .2 C 8 39 4.476485 ... 0 rpt_1C 9 40 4.426849 ... 0 rpt_2C 10 141 4.529535 ... 0 reset 11 142 4.621750 ... 0 hppc 12 143 4.486644 ... 0 rpt_0 .2 C 13 144 4.391235 ... 0 rpt_1C 14 145 4.336987 ... 0 rpt_2C 15 246 4.459362 ... 0 reset 16 247 4.459362 ... 0 hppc *Datapath.get_cycle_life(n_cycles, threshold) \u00b6 Calculate the cycle life for capacity loss below a certain threshold. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . get_cycle_life ()) # Out: 231 *Datapath.cycles_to_capacities(cycle_min, cycle_max, cycle_interval) \u00b6 Get the capacities for an array of cycles in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . cycles_to_capacities ( cycle_min = 50 , cycle_max = 200 , cycle_interval = 50 )) # Out: cycle_50 cycle_100 cycle_150 0 2.020498 1.981053 1.965753 *Datapath.capacities_to_cycles(thresh_max_cap, thresh_min_cap, interval_cap) \u00b6 Get the number of cycles to reach an array of threshold capacities in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . capacities_to_cycles ()) # Out: capacity_0 .98 capacity_0 .95 capacity_0 .92 capacity_0 .89 capacity_0 .86 capacity_0 .83 capacity_0 .8 0 76 185 231 231 231 231 231 *Datapath.is_structured \u00b6 Tells whether the datapath has been structured or not. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) print ( datapath . is_structured ) # Out: False datapath . structure () print ( datapath . is_structured ) # Out: True Making your own BEEPDatapath \u00b6 If your cycler is not already supported by BEEP, you can write a class for structuring its data with BEEP by inheriting BEEPDatapath and implementing one method: from_file . from beep.structure import BEEPDatapath class MyCustomCyclerDatapath ( BEEPDatapath ): \"\"\"An example of implementing a custom BEEPDatapath for your own cycler. \"\"\" @classmethod def from_file ( cls , filename ): # Load your file from the raw file filename data = pd . read_csv ( filename ) # Parse the raw data # The raw data must adhere to BEEP standards. See the beep/conversion_schemas for the list of canonical data columns the raw data dataframe must posess. # Your own code for converting the raw data to contain BEEP columns data = convert_my_custom_cycler_data_to_BEEP_dataframe ( data ) # Parse the metadata using your own code # Metadata must return a dictionary # Should preferably contain \"barcode\", \"protocol\", and \"channel_id\" keys at a minimum. metadata_filename = filename + \"_metadata\" metadata = my_metadata_parsing_function ( metadata_filename ) # Store the paths in a dictionary paths = { \"raw\" : filename , \"metadata\" : filename + \"_Metadata\" } return cls ( data , metadata , paths ) Your custom datapath class can create new methods or override existing BEEPDatapath methods if needed. Once you have written your custom class's from_file method, all the existing behavior of BEEPDatapath should be available, including structure() validate() autostructure() paths raw_data structured_summary structured_data diagnostic_data etc. Electrochemical Impedance Spectra \u00b6 More documentation for EIS coming soon! Structuring compatibility with processed legacy BEEP files \u00b6 Both legacy and *Datapath processed (structured) files saved as json should load with *Datapath.from_json_file , but the capabilities between files serialized with legacy and files serialized with newer BEEPDatapath files will differ. The main discrepancy is that legacy files cannot be restructured once loaded. All of BEEPDatapath 's other structured attributes and properties should function for legacy files identically to those serialized with newer BEEPDatapath . See the auto_load_processed documentation for more info on loading legacy processed BEEPDatapath s. Top-level functions for structuring \u00b6 Aside from the CLI (shown in the command line interface guide , BEEP also contains lower-level python functions for helping loading and structuring many cycler output files from different cyclers. auto_load \u00b6 Auto load will look at the file signature of a raw cycler run output file and automatically load the correct datapath (provided the cycler is supported by BEEP). from beep.structure import auto_load arbin_datapath = auto_load ( \"/path/to/my_arbin_file.csv\" ) print ( arbin_datapath ) # Out: < ArbinDatapath object > maccor_datapath = auto_load ( \"/path/to/my_maccor_file\" ) print ( maccor_datapath ) # Out: < MaccorDatapath object > auto_load_processed \u00b6 Automatically loads the correct datapath for any previously serialized processed (structured) BEEP file. While processed run .json files serialized with *Datapath classes can be loaded with monty.serialization.loadfn , processed files serialized with older BEEP versions may not work with loadfn . auto_load_processed will automatically load the correct datapath, even for legacy BEEP processed .json files, though the functionality of these datapaths is restricted. For example, legacy datapaths cannot be restructured. from beep.structure import auto_load_processed arbin_datapath_processed = auto_load_processed ( \"/path/to/my_processed_arbin_file.json\" ) print ( arbin_datapath_processed ) # Out: < ArbinDatapath object > processed_datapath_legacy = auto_load_processed ( \"/path/to/my_legacy_neware_file\" ) print ( processed_datapath_legacy ) # Out: < NewareDatapath object >","title":"2: Structuring"},{"location":"Python%20tutorials/2%20-%20structuring/#2-structuring","text":"Here you'll find more info about creating and using beep to do your own custom cycler analyses. BEEPDatapath - One object for ingestion, structuring, and validation Batch functions for structuring Featurization Running and analyzing models","title":"2: Structuring"},{"location":"Python%20tutorials/2%20-%20structuring/#structuring-with-beepdatapath","text":"","title":"Structuring with BEEPDatapath"},{"location":"Python%20tutorials/2%20-%20structuring/#one-class-for-ingestion-structuring-and-validation","text":"BEEPDatapath is an abstract base class that can handle ingestion, structuring, and validation for many types of cyclers. A datapath object represents a complete processing pipeline for battery cycler data. Each cycler has it's own BEEPDatapath class: ArbinDatapath MaccorDatapath NewareDatapath IndigoDatapath BiologicDatapath All these datapaths implement the same core methods, properties, and attributes, listed below:","title":"One class for ingestion, structuring, and validation"},{"location":"Python%20tutorials/2%20-%20structuring/#methods-for-loading-and-serializing-battery-cycler-data","text":"","title":"Methods for loading and serializing battery cycler data"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathfrom_filefilename","text":"Classmethod to load a raw cycler output file (e.g., a csv) into a datapath object. Once loaded, you can validate or structure the file. # Here we use ArbinDatapath as an example from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" )","title":"*Datapath.from_file(filename)"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathto_json_filefilename","text":"Dump the current state of a datapath to a file. Can be later loaded with from_json_file . from beep.structure import NewareDatapath datapath = NewareDatapath . from_file ( \"/path/to/my_raw_neware_file\" ) # do some operations ... # Write the processed file to disk, which can then be loaded. datapath . to_json_file ( \"my_processed_neware_data.json\" )","title":"*Datapath.to_json_file(filename)"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathfrom_json_filefilename","text":"Classmethod to load a processed cycler file (e.g., a previously structured Datapath) into a datapath object. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_json_file ( \"my_previously_serialized_datapath.json\" )","title":"*Datapath.from_json_file(filename)"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathdata-metadata-pathsnone-kwargs","text":"Initialize any cycler from the raw data (given as a pandas dataframe) and metadata (given as a dictionary). Paths can be included to keep track of where various cycler files are located. Note: This is not the recommended way to create a BEEPDatapath , as data and metadata must have specific formats to load and structure correctly.","title":"*Datapath(data, metadata, paths=None, **kwargs)"},{"location":"Python%20tutorials/2%20-%20structuring/#validation-and-structuring-with-beepdatapaths","text":"","title":"Validation and structuring with BEEPDatapaths"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathvalidate","text":"Validate your raw data. Will return true if the raw data is valid for your cycler (i.e., can be structured successfully). from beep.structure import IndigoDatapath datapath = IndigoDatapath . from_file ( \"/path/to/my_indigo_file\" ) is_valid = datapath . validate () print ( is_valid ) # Out: # True or False","title":"*Datapath.validate()"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathstructureargs","text":"Interpolate and structure your data using specified arguments. Once structured, your BEEPDatapath is able to access things like the diagnostic summary, interpolated cycles, cycle summary, diagnostic summary, cycle life, and more (see Analysis and attributes of core attributes of BEEPDatapath ) from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" ) # Structure your data by manually specifying parameters. datapath . structure ( v_range = [ 1.2 , 3.5 ], nominal_capacity = 1.2 , full_fast_charge = 0.85 )","title":"*Datapath.structure(*args)"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathautostructure","text":"Run structuring using automatically determined parameters. BEEP can automatically detect the structuring parameters based on your raw data. Note: The BEEP environment variable BEEP_PROCESSING_DIR must be set before autostructuring, and this directory must contain a parameters file which can be used for determine_structuring_parameters . from beep.structure import BiologicDatapath datapath = BiologicDatapath . from_file ( \"path/to/my/biologic_data_file\" ) # Automatically determines structuring parameters and structures data datapath . autostructure ()","title":"*Datapath.autostructure()"},{"location":"Python%20tutorials/2%20-%20structuring/#analysis-and-core-attributes-of-beepdatapath","text":"","title":"Analysis and core attributes of BEEPDatapath"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathpaths","text":"Access all paths of files related to this datapath. paths is a simple mapping of {file_description: file_path} which holds the paths of all files related to this datapath, including raw data, metadata, EIS files, and structured outputs. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . paths ) # Out: { \"raw\" : \"/path/to/my_arbin_file.csv\" , \"metadata\" : \"/path/to/my_arbin_file_Metadata.csv\" }","title":"*Datapath.paths"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathstructuring_parameters","text":"Parameters used to structure BEEPDatapaths : from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) datapath . autostructure () print ( datapath . structuring_parameters ) # Out: { 'v_range' : None , 'resolution' : 1000 , 'diagnostic_resolution' : 500 , 'nominal_capacity' : 1.1 , 'full_fast_charge' : 0.8 , 'diagnostic_available' : False , 'charge_axis' : 'charge_capacity' , 'discharge_axis' : 'voltage' }","title":"*Datapath.structuring_parameters"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathraw_data","text":"The raw data, loaded into a standardized dataframe format, of this datapath's battery cycler data. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . raw_data ) # Out: data_point test_time ... temperature date_time_iso 0 0 0.0021 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 1 1 1.0014 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 2 2 1.1165 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 3 3 2.1174 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 4 4 12.1782 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 ... ... ... ... ... ... 251258 251258 30545.2000 ... 32.595604 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251259 251259 30545.2000 ... 32.555054 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251260 251260 30550.1970 ... 32.555054 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251261 251261 30550.1970 ... 32.545870 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251262 251262 30555.1970 ... 32.445827 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00","title":"*Datapath.raw_data"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathmetadata","text":"An object holding all metadata for this datapath's cycler run. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . metadata . barcode ) print ( datapath . metadata . channel_id ) print ( datapath . metadata . protocol ) print ( datapath . metadata . raw ) # Out: \"EL151000429559\" 28 '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' { 'test_id' : 296 , 'device_id' : 60369369 , 'channel_id' : 28 , 'start_datetime' : 1512445026 , '_resumed_times' : 0 , 'last_resume_datetime' : 0 , '_last_end_datetime' : 1512514129 , 'protocol' : '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' , '_databases' : 'ArbinResult_43,ArbinResult_44,ArbinResult_45,' , 'barcode' : 'EL151000429559' , '_grade_id' : 0 , '_has_aux' : 3 , '_has_special' : 0 , '_schedule_version' : 'Schedule Version 7.00.08' , '_log_aux_data_flag' : 1 , '_log_special_data_flag' : 0 , '_rowstate' : 0 , '_canconfig_filename' : nan , '_m_ncanconfigmd5' : nan , '_value' : 0.0 , '_value2' : 0.0 }","title":"*Datapath.metadata"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathstructured_data","text":"The structured (interpolated) data, as a dataframe. The format is similar to that of .raw_data . The datapath must be structured before this attribute is available. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) datapath . autostructure () print ( datapath . structured_data ) # Out: voltage test_time current ... temperature cycle_index step_type 0 2.500000 NaN NaN ... NaN 0 discharge 1 2.501702 NaN NaN ... NaN 0 discharge 2 2.503403 NaN NaN ... NaN 0 discharge 3 2.505105 NaN NaN ... NaN 0 discharge 4 2.506807 NaN NaN ... NaN 0 discharge ... ... ... ... ... ... ... 461995 NaN NaN NaN ... NaN 245 charge 461996 NaN NaN NaN ... NaN 245 charge 461997 NaN NaN NaN ... NaN 245 charge 461998 NaN NaN NaN ... NaN 245 charge 461999 NaN NaN NaN ... NaN 245 charge","title":"*Datapath.structured_data"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathstructured_summary","text":"A summary of the structured cycler data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . structured_summary ) # Out: cycle_index discharge_capacity charge_capacity discharge_energy charge_energy dc_internal_resistance temperature_maximum temperature_average temperature_minimum date_time_iso energy_efficiency charge_throughput energy_throughput charge_duration time_temperature_integrated paused cycle_index 0 0 4.719281 3.827053 17.273731 14.901985 0.0 NaN NaN NaN 2019 - 12 - 17 T17 : 51 : 51 + 00 : 00 1.159156 3.827053 14.901985 NaN NaN 4957 6 6 2.074518 4.406801 7.677041 16.997186 0.0 NaN NaN NaN 2019 - 12 - 20 T13 : 14 : 40 + 00 : 00 0.451665 8.233854 31.899172 5791.0 NaN 0 7 7 2.097911 2.108322 7.775166 8.597635 0.0 NaN NaN NaN 2019 - 12 - 20 T15 : 51 : 34 + 00 : 00 0.904338 10.342176 40.496807 NaN NaN 0 8 8 2.074545 2.098428 7.684986 8.557546 0.0 NaN NaN NaN 2019 - 12 - 20 T17 : 32 : 21 + 00 : 00 0.898036 12.440605 49.054352 NaN NaN 0 9 9 2.074061 2.082069 7.685348 8.494265 0.0 NaN NaN NaN 2019 - 12 - 20 T19 : 12 : 46 + 00 : 00 0.904769 14.522674 57.548618 NaN NaN 0 10 10 2.065671 2.069061 7.655246 8.441246 0.0 NaN NaN NaN 2019 - 12 - 20 T20 : 52 : 53 + 00 : 00 0.906886 16.591734 65.989861 NaN NaN 0 11 11 2.064542 2.068921 7.651949 8.439011 0.0 NaN NaN NaN 2019 - 12 - 20 T22 : 32 : 38 + 00 : 00 0.906735 18.660656 74.428871 NaN NaN 0 12 12 2.068333 2.061454 7.666199 8.409441 0.0 NaN NaN NaN 2019 - 12 - 21 T00 : 12 : 35 + 00 : 00 0.911618 20.722109 82.838318 NaN NaN 0 13 13 2.054566 2.067370 7.616584 8.431127 0.0 NaN NaN NaN 2019 - 12 - 21 T01 : 52 : 14 + 00 : 00 0.903389 22.789478 91.269440 NaN NaN 0 14 14 2.061369 2.057715 7.647454 8.394535 0.0 NaN NaN NaN 2019 - 12 - 21 T03 : 31 : 54 + 00 : 00 0.911004 24.847195 99.663979 NaN NaN 0 15 15 2.050721 2.059819 7.602874 8.401562 0.0 NaN NaN NaN 2019 - 12 - 21 T05 : 11 : 24 + 00 : 00 0.904936 26.907013 108.065536 NaN NaN 0 16 16 2.055427 2.057405 7.622452 8.393292 0.0 NaN NaN NaN 2019 - 12 - 21 T06 : 50 : 57 + 00 : 00 0.908160 28.964418 116.458832 NaN NaN 0 17 17 2.045344 2.049606 7.583858 8.360918 0.0 NaN NaN NaN 2019 - 12 - 21 T08 : 30 : 36 + 00 : 00 0.907060 31.014025 124.819748 NaN NaN 0 18 18 2.047280 2.046608 7.591624 8.347446 0.0 NaN NaN NaN 2019 - 12 - 21 T10 : 09 : 56 + 00 : 00 0.909455 33.060631 133.167191 NaN NaN 0 19 19 2.055454 2.046478 7.623849 8.347916 0.0 NaN NaN NaN 2019 - 12 - 21 T11 : 49 : 18 + 00 : 00 0.913264 35.107109 141.515106 NaN NaN 0 20 20 2.043676 2.055780 7.579766 8.383341 0.0 NaN NaN NaN 2019 - 12 - 21 T13 : 28 : 39 + 00 : 00 0.904146 37.162891 149.898453 NaN NaN 0 21 21 2.049323 2.046085 7.605977 8.346517 0.0 NaN NaN NaN 2019 - 12 - 21 T15 : 08 : 10 + 00 : 00 0.911276 39.208977 158.244965 NaN NaN 0 22 22 2.038514 2.047097 7.560916 8.349430 0.0 NaN NaN NaN 2019 - 12 - 21 T16 : 47 : 22 + 00 : 00 0.905561 41.256073 166.594406 NaN NaN 0 23 23 2.044779 2.045038 7.585164 8.342201 0.0 NaN NaN NaN 2019 - 12 - 21 T18 : 26 : 38 + 00 : 00 0.909252 43.301109 174.936600 NaN NaN 0 24 24 2.039805 2.039563 7.567169 8.319416 0.0 NaN NaN NaN 2019 - 12 - 21 T20 : 06 : 10 + 00 : 00 0.909579 45.340672 183.256012 NaN NaN 0 25 25 2.039563 2.040318 7.566332 8.320876 0.0 NaN NaN NaN 2019 - 12 - 21 T21 : 45 : 20 + 00 : 00 0.909319 47.380993 191.576889 NaN NaN 0 26 26 2.052362 2.038989 7.616830 8.316606 0.0 NaN NaN NaN 2019 - 12 - 21 T23 : 24 : 33 + 00 : 00 0.915858 49.419979 199.893494 NaN NaN 0 27 27 2.035744 2.051446 7.552814 8.364671 0.0 NaN NaN NaN 2019 - 12 - 22 T01 : 03 : 48 + 00 : 00 0.902942 51.471428 208.258163 NaN NaN 0 28 28 2.039347 2.041048 7.568011 8.325755 0.0 NaN NaN NaN 2019 - 12 - 22 T02 : 43 : 14 + 00 : 00 0.908988 53.512474 216.583923 NaN NaN 0","title":"*Datapath.structured_summary"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathdiagnostic_data","text":"The structured (interpolated) data for diagnostic cycles, as a dataframe. The format is similar to that of .structured_data . The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_data ) # Out: voltage test_time current ... step_type discharge_dQdV charge_dQdV 0 2.700000 NaN NaN ... 0 NaN NaN 1 2.703006 NaN NaN ... 0 NaN NaN 2 2.706012 NaN NaN ... 0 NaN NaN 3 2.709018 NaN NaN ... 0 NaN NaN 4 2.712024 NaN NaN ... 0 NaN NaN ... ... ... ... ... ... ... 44434 2.782701 1958305.375 1.612107 ... 0 0.0 0.006379 44435 2.783219 1958305.375 1.612090 ... 0 0.0 0.006379 44436 2.783736 1958305.375 1.612073 ... 0 0.0 0.006379 44437 2.784254 1958305.375 1.612056 ... 0 0.0 0.006379 44438 2.784771 1958305.375 1.612039 ... 0 0.0 0.006379 [ 44439 rows x 16 columns ]","title":"*Datapath.diagnostic_data"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathdiagnostic_summary","text":"A summary of the structured diagnostic cycle data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_summary ) # Out: cycle_index discharge_capacity ... paused cycle_type 0 1 4.711819 ... 0 reset 1 2 4.807243 ... 0 hppc 2 3 4.648884 ... 0 rpt_0 .2 C 3 4 4.525516 ... 0 rpt_1C 4 5 4.482939 ... 0 rpt_2C 5 36 4.624467 ... 0 reset 6 37 4.722887 ... 0 hppc 7 38 4.584861 ... 0 rpt_0 .2 C 8 39 4.476485 ... 0 rpt_1C 9 40 4.426849 ... 0 rpt_2C 10 141 4.529535 ... 0 reset 11 142 4.621750 ... 0 hppc 12 143 4.486644 ... 0 rpt_0 .2 C 13 144 4.391235 ... 0 rpt_1C 14 145 4.336987 ... 0 rpt_2C 15 246 4.459362 ... 0 reset 16 247 4.459362 ... 0 hppc","title":"*Datapath.diagnostic_summary"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathget_cycle_lifen_cycles-threshold","text":"Calculate the cycle life for capacity loss below a certain threshold. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . get_cycle_life ()) # Out: 231","title":"*Datapath.get_cycle_life(n_cycles, threshold)"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathcycles_to_capacitiescycle_min-cycle_max-cycle_interval","text":"Get the capacities for an array of cycles in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . cycles_to_capacities ( cycle_min = 50 , cycle_max = 200 , cycle_interval = 50 )) # Out: cycle_50 cycle_100 cycle_150 0 2.020498 1.981053 1.965753","title":"*Datapath.cycles_to_capacities(cycle_min, cycle_max, cycle_interval)"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathcapacities_to_cyclesthresh_max_cap-thresh_min_cap-interval_cap","text":"Get the number of cycles to reach an array of threshold capacities in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . capacities_to_cycles ()) # Out: capacity_0 .98 capacity_0 .95 capacity_0 .92 capacity_0 .89 capacity_0 .86 capacity_0 .83 capacity_0 .8 0 76 185 231 231 231 231 231","title":"*Datapath.capacities_to_cycles(thresh_max_cap, thresh_min_cap, interval_cap)"},{"location":"Python%20tutorials/2%20-%20structuring/#datapathis_structured","text":"Tells whether the datapath has been structured or not. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) print ( datapath . is_structured ) # Out: False datapath . structure () print ( datapath . is_structured ) # Out: True","title":"*Datapath.is_structured"},{"location":"Python%20tutorials/2%20-%20structuring/#making-your-own-beepdatapath","text":"If your cycler is not already supported by BEEP, you can write a class for structuring its data with BEEP by inheriting BEEPDatapath and implementing one method: from_file . from beep.structure import BEEPDatapath class MyCustomCyclerDatapath ( BEEPDatapath ): \"\"\"An example of implementing a custom BEEPDatapath for your own cycler. \"\"\" @classmethod def from_file ( cls , filename ): # Load your file from the raw file filename data = pd . read_csv ( filename ) # Parse the raw data # The raw data must adhere to BEEP standards. See the beep/conversion_schemas for the list of canonical data columns the raw data dataframe must posess. # Your own code for converting the raw data to contain BEEP columns data = convert_my_custom_cycler_data_to_BEEP_dataframe ( data ) # Parse the metadata using your own code # Metadata must return a dictionary # Should preferably contain \"barcode\", \"protocol\", and \"channel_id\" keys at a minimum. metadata_filename = filename + \"_metadata\" metadata = my_metadata_parsing_function ( metadata_filename ) # Store the paths in a dictionary paths = { \"raw\" : filename , \"metadata\" : filename + \"_Metadata\" } return cls ( data , metadata , paths ) Your custom datapath class can create new methods or override existing BEEPDatapath methods if needed. Once you have written your custom class's from_file method, all the existing behavior of BEEPDatapath should be available, including structure() validate() autostructure() paths raw_data structured_summary structured_data diagnostic_data etc.","title":"Making your own BEEPDatapath"},{"location":"Python%20tutorials/2%20-%20structuring/#electrochemical-impedance-spectra","text":"More documentation for EIS coming soon!","title":"Electrochemical Impedance Spectra"},{"location":"Python%20tutorials/2%20-%20structuring/#structuring-compatibility-with-processed-legacy-beep-files","text":"Both legacy and *Datapath processed (structured) files saved as json should load with *Datapath.from_json_file , but the capabilities between files serialized with legacy and files serialized with newer BEEPDatapath files will differ. The main discrepancy is that legacy files cannot be restructured once loaded. All of BEEPDatapath 's other structured attributes and properties should function for legacy files identically to those serialized with newer BEEPDatapath . See the auto_load_processed documentation for more info on loading legacy processed BEEPDatapath s.","title":"Structuring compatibility with processed legacy BEEP files"},{"location":"Python%20tutorials/2%20-%20structuring/#top-level-functions-for-structuring","text":"Aside from the CLI (shown in the command line interface guide , BEEP also contains lower-level python functions for helping loading and structuring many cycler output files from different cyclers.","title":"Top-level functions for structuring"},{"location":"Python%20tutorials/2%20-%20structuring/#auto_load","text":"Auto load will look at the file signature of a raw cycler run output file and automatically load the correct datapath (provided the cycler is supported by BEEP). from beep.structure import auto_load arbin_datapath = auto_load ( \"/path/to/my_arbin_file.csv\" ) print ( arbin_datapath ) # Out: < ArbinDatapath object > maccor_datapath = auto_load ( \"/path/to/my_maccor_file\" ) print ( maccor_datapath ) # Out: < MaccorDatapath object >","title":"auto_load"},{"location":"Python%20tutorials/2%20-%20structuring/#auto_load_processed","text":"Automatically loads the correct datapath for any previously serialized processed (structured) BEEP file. While processed run .json files serialized with *Datapath classes can be loaded with monty.serialization.loadfn , processed files serialized with older BEEP versions may not work with loadfn . auto_load_processed will automatically load the correct datapath, even for legacy BEEP processed .json files, though the functionality of these datapaths is restricted. For example, legacy datapaths cannot be restructured. from beep.structure import auto_load_processed arbin_datapath_processed = auto_load_processed ( \"/path/to/my_processed_arbin_file.json\" ) print ( arbin_datapath_processed ) # Out: < ArbinDatapath object > processed_datapath_legacy = auto_load_processed ( \"/path/to/my_legacy_neware_file\" ) print ( processed_datapath_legacy ) # Out: < NewareDatapath object >","title":"auto_load_processed"},{"location":"Python%20tutorials/3%20-%20featurization/","text":"3: Featurization \u00b6 More documentation for featurization coming soon!","title":"3: Featurization"},{"location":"Python%20tutorials/3%20-%20featurization/#3-featurization","text":"More documentation for featurization coming soon!","title":"3: Featurization"},{"location":"Python%20tutorials/4%20-%20models/","text":"4: Machine Learning \u00b6 More documentation for running models coming soon!","title":"4: Machine Learning"},{"location":"Python%20tutorials/4%20-%20models/#4-machine-learning","text":"More documentation for running models coming soon!","title":"4: Machine Learning"},{"location":"Python%20tutorials/advanced_structuring/","text":"Advanced Structuring: Unsupported cyclers \u00b6 If you are using a cycler not supported by BEEP, you can still use BEEP to structure, featurize, and run models on your data! To do this, you simply inherit from the BEEPDatapath base class described in the Structuring Tutorial to create your own Datapath. BEEPDatapath handles all structuring of battery cycler files by taking them from raw cycler output files (usually csvs or text) and converting them into consistent interfaces for structuring. Your custom datapath will work with BEEP's capabilities similarly to all existing cyclers/datapaths. The Simplest Case: Using from_file \u00b6 To put your cycler data in a format BEEP can understand, inherit from the BEEPDatapath class and implement the from_file classmethod. Requirements \u00b6 Your from file method will need to produce the following data to work correctly with BEEP. 1. A dataframe of the battery cycler data, in a standard format \u00b6 The dataframe should have at least the following columns, named exactly as described: test_time : Time of the test, in seconds cycle_index : Integer index of the cycle number current : Current drawn to/from battery, in amps voltage : Voltage, in volts charge_capacity : Charge capacity of the battery, in amp-hours discharge_capacity : Discharge capacity of the battery, in amp-hours charge_energy : Charge energy of the battery, in watt-hours discharge_energy : Discharge energy of the battery, in watt-hours step_index : Index integer of the charge-step, e.g., resting = 1, charging = 2, etc. step_time : amount of time spent in this charge-step, in seconds. (Optional): temperature : Temperature of the cell itself date_time : Date time, as timestamp (ms from unix epoch) date_time_iso : Date time in UTC time zone, formatted using .isoformat() internal_resistance : Internal resistance of battery, in ohm The dataframe may contain other data, if available from your cycler output. 2. Metadata dictionary \u00b6 All available metadata from the cycler run should be gathered by from_file . This can include things like: barcode protocol channel_id and other cycler-specific metadata. The metadata should be a dictionary. 3. Paths to raw input files \u00b6 Finally, paths to all raw input files should be collected as a dictionary, mapping file type to the absolute path. For example, if each run of your cycler requires a time series file and a metadata file, the paths dictionary would look like: paths = { \"raw\" : \"/path/to/raw/timeseries.csv\" , \"metadata\" : \"/path/to/metadata.json\" } Note raw and metadata are special keys. While having these two exact paths is recommended, arbitrary other paths to supporting files can be passed in the paths dictionary without any special naming convention. For example: paths = { \"raw\" : \"/path/to/raw/timeseries.csv\" , \"metadata\" : None , \"my_other_required_filetype_path\" : \"/path/to/somefile.hd5\" } Column Mapping \u00b6 To transparently keep consistent data types and column names, we recommend making the following class attributes in your BEEPDatapath child class: COLUMN_MAPPING : Maps raw column names to BEEP canonical names COLUMNS_IGNORE : Raw column names to ignore, if they are not needed (for example, Environmental Temperature (C) ) DATA_TYPES : Mapping of BEEP canoncial column name to data type, in pandas-parsable format. For example, if your cycle index should be 32-pt integer, you can include the key-value \"cycle_index\": \"int32\" in your DATA_TYPES class attribute. Code Example - putting it all together \u00b6 Once your from_file method is able to extract the three requirements in the correct format, you should be able to pass those objects to the cls constructor inside of from_file . For example: import os import json import pytz import pandas as pd from beep.structure.base import BEEPDatapath class MyCyclerDatapath ( BEEPDatapath ): COLUMN_MAPPING = { \"test_time (s)\" : \"test_time\" , \"cycle_index\" : \"cycle_index\" , \"current (a)\" : \"current\" , \"voltage (v)\" : \"voltage\" , \"charge_capacity (ah)\" : \"charge_capacity\" , \"discharge_capacity (ah)\" : \"discharge_capacity\" , \"charge_energy (wh)\" : \"charge_energy\" , \"discharge_energy (wh)\" : \"discharge_energy\" , \"cell_temperature (c)\" : \"temperature\" , \"date_time\" : \"date_time\" , \"steptime\" : \"step_time\" , \"stepix\" : \"step_index\" } # Columns to ignore COLUMNS_IGNORE = [ \"environment_temperature (c)\" ] # Mapping of data types for BEEP columns DATA_TYPES = { \"test_time\" : \"float64\" , \"cycle_index\" : \"int32\" , \"current\" : \"float32\" , \"voltage\" : \"float32\" , \"charge_capacity\" : \"float64\" , \"discharge_capacity\" : \"float64\" , \"charge_energy\" : \"float64\" , \"discharge_energy\" : \"float64\" , \"temperature\" : \"float32\" , \"date_time\" : \"float32\" , \"step_time\" : \"float32\" , \"step_index\" : \"int32\" } @classmethod def from_file ( cls , path , metadata_path = None ): # some code to get the raw data in BEEP format # assuming it does not need to be further augmented df = pd . read_csv ( path ) df = df . drop ( cls . COLUMNS_IGNORE ) df . rename ( columns = cls . COLUMN_MAPPING , inplace = True ) # For example, adding a date_time_iso column if not already present df [ \"date_time_iso\" ] = df [ \"date_time\" ] . apply ( lambda x : x . from_timestamp () . replace ( tzinfo = pytz . UTC ) . isoformat () ) # Cast all data types to those specified as class attrs for column , dtype in cls . DATA_TYPES . items (): if column in df : if not df [ column ] . isnull () . values . any (): df [ column ] = df [ column ] . astype ( dtype ) # Read in metadata from a separate json file, for example if metadata_path : with open ( metadata_path , \"r\" ) as f : metadata = json . load ( f ) else : metadata = {} # specify all paths absolutely paths = { \"raw\" : os . path . abspath ( path ), \"metadata\" : os . path . abspath ( metadata_path ) } # Return the 3 required objects to BEEPDatapath return cls ( df , metadata , paths ) After your BEEPDatapath is working \u00b6 Once your BEEPDatapath is able to load raw files using from_file , all of BEEP's other modules and methods should work with it like they do with any other Datapath/cycler. For example, structuring your BEEPDatapath requires only calling the parent BEEPDatapath 's .structure method. For more info on the capabilities of BEEPDatapath , see the Structuring Tutorial . Advanced usage \u00b6 Your cycler may possess capabilities for data or structuring outside of base BEEPDatapath 's capabilities. In this case, it may be needed to implement additional methods or override BEEPDatapath methods beyond from_file . The specific implementation will depend on your cycler's capabilities; however, it is recommended not to override the following methods in particular: BEEPDatapath.structure BEEPDatapath.autostructure BEEPDatapath.as_dict BEEPDatapath.from_dict If these methods are overridden in an incompatible way, it is likely they will break further downstream BEEP tasks, such as diagnostic structuring or featurization.","title":"Advanced Structuring: Unsupported cyclers"},{"location":"Python%20tutorials/advanced_structuring/#advanced-structuring-unsupported-cyclers","text":"If you are using a cycler not supported by BEEP, you can still use BEEP to structure, featurize, and run models on your data! To do this, you simply inherit from the BEEPDatapath base class described in the Structuring Tutorial to create your own Datapath. BEEPDatapath handles all structuring of battery cycler files by taking them from raw cycler output files (usually csvs or text) and converting them into consistent interfaces for structuring. Your custom datapath will work with BEEP's capabilities similarly to all existing cyclers/datapaths.","title":"Advanced Structuring: Unsupported cyclers"},{"location":"Python%20tutorials/advanced_structuring/#the-simplest-case-using-from_file","text":"To put your cycler data in a format BEEP can understand, inherit from the BEEPDatapath class and implement the from_file classmethod.","title":"The Simplest Case: Using from_file"},{"location":"Python%20tutorials/advanced_structuring/#requirements","text":"Your from file method will need to produce the following data to work correctly with BEEP.","title":"Requirements"},{"location":"Python%20tutorials/advanced_structuring/#1-a-dataframe-of-the-battery-cycler-data-in-a-standard-format","text":"The dataframe should have at least the following columns, named exactly as described: test_time : Time of the test, in seconds cycle_index : Integer index of the cycle number current : Current drawn to/from battery, in amps voltage : Voltage, in volts charge_capacity : Charge capacity of the battery, in amp-hours discharge_capacity : Discharge capacity of the battery, in amp-hours charge_energy : Charge energy of the battery, in watt-hours discharge_energy : Discharge energy of the battery, in watt-hours step_index : Index integer of the charge-step, e.g., resting = 1, charging = 2, etc. step_time : amount of time spent in this charge-step, in seconds. (Optional): temperature : Temperature of the cell itself date_time : Date time, as timestamp (ms from unix epoch) date_time_iso : Date time in UTC time zone, formatted using .isoformat() internal_resistance : Internal resistance of battery, in ohm The dataframe may contain other data, if available from your cycler output.","title":"1. A dataframe of the battery cycler data, in a standard format"},{"location":"Python%20tutorials/advanced_structuring/#2-metadata-dictionary","text":"All available metadata from the cycler run should be gathered by from_file . This can include things like: barcode protocol channel_id and other cycler-specific metadata. The metadata should be a dictionary.","title":"2. Metadata dictionary"},{"location":"Python%20tutorials/advanced_structuring/#3-paths-to-raw-input-files","text":"Finally, paths to all raw input files should be collected as a dictionary, mapping file type to the absolute path. For example, if each run of your cycler requires a time series file and a metadata file, the paths dictionary would look like: paths = { \"raw\" : \"/path/to/raw/timeseries.csv\" , \"metadata\" : \"/path/to/metadata.json\" } Note raw and metadata are special keys. While having these two exact paths is recommended, arbitrary other paths to supporting files can be passed in the paths dictionary without any special naming convention. For example: paths = { \"raw\" : \"/path/to/raw/timeseries.csv\" , \"metadata\" : None , \"my_other_required_filetype_path\" : \"/path/to/somefile.hd5\" }","title":"3. Paths to raw input files"},{"location":"Python%20tutorials/advanced_structuring/#column-mapping","text":"To transparently keep consistent data types and column names, we recommend making the following class attributes in your BEEPDatapath child class: COLUMN_MAPPING : Maps raw column names to BEEP canonical names COLUMNS_IGNORE : Raw column names to ignore, if they are not needed (for example, Environmental Temperature (C) ) DATA_TYPES : Mapping of BEEP canoncial column name to data type, in pandas-parsable format. For example, if your cycle index should be 32-pt integer, you can include the key-value \"cycle_index\": \"int32\" in your DATA_TYPES class attribute.","title":"Column Mapping"},{"location":"Python%20tutorials/advanced_structuring/#code-example-putting-it-all-together","text":"Once your from_file method is able to extract the three requirements in the correct format, you should be able to pass those objects to the cls constructor inside of from_file . For example: import os import json import pytz import pandas as pd from beep.structure.base import BEEPDatapath class MyCyclerDatapath ( BEEPDatapath ): COLUMN_MAPPING = { \"test_time (s)\" : \"test_time\" , \"cycle_index\" : \"cycle_index\" , \"current (a)\" : \"current\" , \"voltage (v)\" : \"voltage\" , \"charge_capacity (ah)\" : \"charge_capacity\" , \"discharge_capacity (ah)\" : \"discharge_capacity\" , \"charge_energy (wh)\" : \"charge_energy\" , \"discharge_energy (wh)\" : \"discharge_energy\" , \"cell_temperature (c)\" : \"temperature\" , \"date_time\" : \"date_time\" , \"steptime\" : \"step_time\" , \"stepix\" : \"step_index\" } # Columns to ignore COLUMNS_IGNORE = [ \"environment_temperature (c)\" ] # Mapping of data types for BEEP columns DATA_TYPES = { \"test_time\" : \"float64\" , \"cycle_index\" : \"int32\" , \"current\" : \"float32\" , \"voltage\" : \"float32\" , \"charge_capacity\" : \"float64\" , \"discharge_capacity\" : \"float64\" , \"charge_energy\" : \"float64\" , \"discharge_energy\" : \"float64\" , \"temperature\" : \"float32\" , \"date_time\" : \"float32\" , \"step_time\" : \"float32\" , \"step_index\" : \"int32\" } @classmethod def from_file ( cls , path , metadata_path = None ): # some code to get the raw data in BEEP format # assuming it does not need to be further augmented df = pd . read_csv ( path ) df = df . drop ( cls . COLUMNS_IGNORE ) df . rename ( columns = cls . COLUMN_MAPPING , inplace = True ) # For example, adding a date_time_iso column if not already present df [ \"date_time_iso\" ] = df [ \"date_time\" ] . apply ( lambda x : x . from_timestamp () . replace ( tzinfo = pytz . UTC ) . isoformat () ) # Cast all data types to those specified as class attrs for column , dtype in cls . DATA_TYPES . items (): if column in df : if not df [ column ] . isnull () . values . any (): df [ column ] = df [ column ] . astype ( dtype ) # Read in metadata from a separate json file, for example if metadata_path : with open ( metadata_path , \"r\" ) as f : metadata = json . load ( f ) else : metadata = {} # specify all paths absolutely paths = { \"raw\" : os . path . abspath ( path ), \"metadata\" : os . path . abspath ( metadata_path ) } # Return the 3 required objects to BEEPDatapath return cls ( df , metadata , paths )","title":"Code Example - putting it all together"},{"location":"Python%20tutorials/advanced_structuring/#after-your-beepdatapath-is-working","text":"Once your BEEPDatapath is able to load raw files using from_file , all of BEEP's other modules and methods should work with it like they do with any other Datapath/cycler. For example, structuring your BEEPDatapath requires only calling the parent BEEPDatapath 's .structure method. For more info on the capabilities of BEEPDatapath , see the Structuring Tutorial .","title":"After your BEEPDatapath is working"},{"location":"Python%20tutorials/advanced_structuring/#advanced-usage","text":"Your cycler may possess capabilities for data or structuring outside of base BEEPDatapath 's capabilities. In this case, it may be needed to implement additional methods or override BEEPDatapath methods beyond from_file . The specific implementation will depend on your cycler's capabilities; however, it is recommended not to override the following methods in particular: BEEPDatapath.structure BEEPDatapath.autostructure BEEPDatapath.as_dict BEEPDatapath.from_dict If these methods are overridden in an incompatible way, it is likely they will break further downstream BEEP tasks, such as diagnostic structuring or featurization.","title":"Advanced usage"},{"location":"Python%20tutorials/advanced_structuring2/","text":"Advanced Structuring: Diagnostic and Custom Cyles \u00b6 It is often necessary in cycling experiments to run cycles with more than standard aging charging or discharging steps. These may include reference performance testing (RPT), hybrid pulse power characterization (HPPC), or other custom series of steps. We refer to these as \"diagnostic cycles\". BEEP's core BEEPDatapath object contains logic for interpolating these cycles in a reproducible way, but you must specify where in the cycler file the diagnostic cycles are. If the locations of the diagnostic cycles are not specified, BEEPDatapath will treat these cycles as regular aging cycles. How to structure diagnostic cycles in BEEP \u00b6 The series of steps for structuring diagnostic cycles is: Define a DiagnosticConfig ; this is an object specifying where diagnostic cycles are located. Set the DiagnosticConfig object as the diagnostic attribute of a BEEPDatapath object. Structure using either BEEPDatapath.stucture(...) or BEEPDatapath.interpolate_diagnostic_cycles(...) (for more granularity.) 1. (a) Defining a DiagnosticConfig from cycle indices \u00b6 The most direct way of specifying a DiagnosticConfig is by simply passing in the locations of the cycle indices for each type of diagnostic cycle in your file. This is done with a dictionary where the keys are user-defined names of cycles and values are sets of cycle indices. In this example, we'll say there are only HPPC cycles and they're located at cycle indices 1, 12, and 14. from beep.structure.diagnostic import DiagnosticConfig dc = DiagnosticConfig ( { \"hppc\" : { 12 , 14 , 1 } } ) For a more complex example, let's say there are several kinds of cycles at various intervals: from beep.structure.diagnostic import DiagnosticConfig rpt1_ix = set ( range ( 1 , 1002 , 200 )) rpt2_ix = set ( range ( 2 , 1003 , 200 )) hppc1_ix = { 12 , 512 } hppc2_ix = { 115 , 718 , 910 } reset_ix = { 0 , 1000 } abnormal_ix = set ( range ( 5 , 520 , 50 )) dc = DiagnosticConfig ( { \"rpt1\" : rpt1_ix , \"rpt2\" : rpt2_ix , \"hppc1\" : hppc1_ix , \"hppc2\" : hppc2_ix , \"reset_\" : reset_ix , \"abnormal\" : abnormal_ix }, ) Note the names of the cycles are user defined , but BEEP will determine a strategy of interpolation if the cycle names contain: \"rpt\" : If found in the cycle name, these cycles will be treated as RPT. E.g., \"rpt_0.2C\" would be interpolated as an RPT cycle. \"hppc\" : If found in the cycle name, these cycles will be treated as HPPC. \"reset\" : If found in the cycle name, these cycles will be treated as RESET cycles. Any other cycle name will be interpolated on a step-by-step basis on the voltage axis. 1. (b) Defining a DiagnosticConfig automatically using step numbers \u00b6 Specifying individual step numbers can be difficult, especially if you are working with someone else's file. However, DiagnosticConfig can also be instantiated with a set of heuristics for recognizing step numbers present in certain cycles but missing in others. For example, if HPPC cycles always contain the step indices 14 and 16 and other cycles never do, we can automatically determine the cycle indices of the HPPC cycles. We use the DiagnosticConfig.from_step_numbers method to instantiate the object automatically. The matching_critera argument determines a set of \"contains\" or \"exact\" matching rules for each diagnostic cycle type. We will also need the dataframe of raw data. For example, let's say: Our HPPC cycles always at least contain step numbers 1,2,4,6,8. Our low-rate RPT cycles are EXACTLY (only) step numbers 12 and 13. Our high-rate RPT cycles are EXACTLY (only) step numbers 15 and 16. We can recognize the cycles automatically: from beep.structure.maccor import MaccorDatapath from beep.structure.diagnostic import DiagnosticConfig datapath = MaccorDatapath . from_file ( \"MyMaccorFile.rar\" ) dc = DiagnosticConfig . from_step_numbers ( datapath . raw_data , matching_criteria = { \"hppc\" : ( \"contains\" , [( 1 , 2 , 4 , 6 , 8 )]), \"rpt_lowrate\" : ( \"exact\" , [( 12 , 13 )]), \"rpt_highrate\" : ( \"exact\" , [( 15 , 16 )]) } ) 1. (c) Working with DiagnosticConfig \u00b6 Once instantiated, DiagnosticConfig objects have some attributes for working with the cycle indices of each diagnostic cycle type. DiagnosticConfig.all_ix gives the set of all diagnostic cycles, regardless of their type (as long as they are not regular aging cycles) DiagnosticConfig.rpt_ix gives the set of all RPT cycles, even those specified at different C-rates. For more info on how RPT cycles are recognized, see Step 1(a) above. DiagnosticConfig.hppc_ix gives the set of all HPPC cycles, even those with different parameters. DiagnosticConfig.cycles gives a mapping from a cycle type string (e.g., \"rpt_lowrate\" ) to the set of it's cycle indices (e.g., {1, 101, 201, ...} ) DiagnosticConfig.type_by_ix gives a mapping from cycle index (e.g., 101 ) to the cycle type string (e.g., \"rpt_lowrate\" ) Here is an example: from beep.structure.diagnostic import DiagnosticConfig rpt1_ix = set ( range ( 1 , 1002 , 200 )) rpt2_ix = set ( range ( 2 , 1003 , 200 )) hppc1_ix = { 12 , 512 } hppc2_ix = { 115 , 718 , 910 } reset_ix = { 0 , 1000 } abnormal_ix = set ( range ( 5 , 520 , 50 )) dc = DiagnosticConfig ( { \"rpt1\" : rpt1_ix , \"rpt2\" : rpt2_ix , \"hppc1\" : hppc1_ix , \"hppc2\" : hppc2_ix , \"reset_\" : reset_ix , \"abnormal\" : abnormal_ix }, ) print ( \"All diagnostic indices:\" , dc . all_ix ) print ( \"All RPT indices:\" , dc . rpt_ix ) print ( \"All HPPC indices:\" , dc . hppc_ix ) print ( \"RPT1 indices:\" , dc . cycles [ \"rpt_lowrate\" ]) print ( \"Cycle type of cycle 12:\" , dc . type_by_ix [ 12 ]) All diagnostic indices: {0, 1, 2, 5, 12, 55...} All RPT indices: {1, 2, 201, 202, 401, 402...} All HPPC indices: {12, 115, 512, 718, 910} RPT lowrate indices: {1, 201, 401, 601,...} Cycle type of cycle 12: hppc1 2. Set the DiagnosticConfig object to BEEPDatapath.diagnostic \u00b6 Once DiagnosticConfig is instantiated alongside a datapath, set the diagnostic attribute of a BEEPDatapath to that object. datapath.diagnostic = diagnostic_config_object 3. Interpolate! \u00b6 You can now structure files normally using BEEPDatapath.structure(...) (for a full structuring of both diagnostic and normal cycles) or BEEPDatapath.interpolate_diagnostic_cycles(...) (for diagnostic cycles only). Here is a full example: from beep.structure.novonix import NovonixDatapath from beep.structure.diagnostic import DiagnosticConfig nd = NovonixDatapath . from_file ( \"MyNovonixFile.091\" ) dc = DiagnosticConfig ( { \"rpt\" : set ( range ( 1 , 1002 , 200 )), \"hppc\" : { 12 , 512 }, \"reset\" : { 0 , 1000 }, }, ) nd . diagnostic = dc nd . structure ()","title":"Advanced Structuring: Diagnostic and Custom Cyles"},{"location":"Python%20tutorials/advanced_structuring2/#advanced-structuring-diagnostic-and-custom-cyles","text":"It is often necessary in cycling experiments to run cycles with more than standard aging charging or discharging steps. These may include reference performance testing (RPT), hybrid pulse power characterization (HPPC), or other custom series of steps. We refer to these as \"diagnostic cycles\". BEEP's core BEEPDatapath object contains logic for interpolating these cycles in a reproducible way, but you must specify where in the cycler file the diagnostic cycles are. If the locations of the diagnostic cycles are not specified, BEEPDatapath will treat these cycles as regular aging cycles.","title":"Advanced Structuring: Diagnostic and Custom Cyles"},{"location":"Python%20tutorials/advanced_structuring2/#how-to-structure-diagnostic-cycles-in-beep","text":"The series of steps for structuring diagnostic cycles is: Define a DiagnosticConfig ; this is an object specifying where diagnostic cycles are located. Set the DiagnosticConfig object as the diagnostic attribute of a BEEPDatapath object. Structure using either BEEPDatapath.stucture(...) or BEEPDatapath.interpolate_diagnostic_cycles(...) (for more granularity.)","title":"How to structure diagnostic cycles in BEEP"},{"location":"Python%20tutorials/advanced_structuring2/#1-a-defining-a-diagnosticconfig-from-cycle-indices","text":"The most direct way of specifying a DiagnosticConfig is by simply passing in the locations of the cycle indices for each type of diagnostic cycle in your file. This is done with a dictionary where the keys are user-defined names of cycles and values are sets of cycle indices. In this example, we'll say there are only HPPC cycles and they're located at cycle indices 1, 12, and 14. from beep.structure.diagnostic import DiagnosticConfig dc = DiagnosticConfig ( { \"hppc\" : { 12 , 14 , 1 } } ) For a more complex example, let's say there are several kinds of cycles at various intervals: from beep.structure.diagnostic import DiagnosticConfig rpt1_ix = set ( range ( 1 , 1002 , 200 )) rpt2_ix = set ( range ( 2 , 1003 , 200 )) hppc1_ix = { 12 , 512 } hppc2_ix = { 115 , 718 , 910 } reset_ix = { 0 , 1000 } abnormal_ix = set ( range ( 5 , 520 , 50 )) dc = DiagnosticConfig ( { \"rpt1\" : rpt1_ix , \"rpt2\" : rpt2_ix , \"hppc1\" : hppc1_ix , \"hppc2\" : hppc2_ix , \"reset_\" : reset_ix , \"abnormal\" : abnormal_ix }, ) Note the names of the cycles are user defined , but BEEP will determine a strategy of interpolation if the cycle names contain: \"rpt\" : If found in the cycle name, these cycles will be treated as RPT. E.g., \"rpt_0.2C\" would be interpolated as an RPT cycle. \"hppc\" : If found in the cycle name, these cycles will be treated as HPPC. \"reset\" : If found in the cycle name, these cycles will be treated as RESET cycles. Any other cycle name will be interpolated on a step-by-step basis on the voltage axis.","title":"1. (a) Defining a DiagnosticConfig from cycle indices"},{"location":"Python%20tutorials/advanced_structuring2/#1-b-defining-a-diagnosticconfig-automatically-using-step-numbers","text":"Specifying individual step numbers can be difficult, especially if you are working with someone else's file. However, DiagnosticConfig can also be instantiated with a set of heuristics for recognizing step numbers present in certain cycles but missing in others. For example, if HPPC cycles always contain the step indices 14 and 16 and other cycles never do, we can automatically determine the cycle indices of the HPPC cycles. We use the DiagnosticConfig.from_step_numbers method to instantiate the object automatically. The matching_critera argument determines a set of \"contains\" or \"exact\" matching rules for each diagnostic cycle type. We will also need the dataframe of raw data. For example, let's say: Our HPPC cycles always at least contain step numbers 1,2,4,6,8. Our low-rate RPT cycles are EXACTLY (only) step numbers 12 and 13. Our high-rate RPT cycles are EXACTLY (only) step numbers 15 and 16. We can recognize the cycles automatically: from beep.structure.maccor import MaccorDatapath from beep.structure.diagnostic import DiagnosticConfig datapath = MaccorDatapath . from_file ( \"MyMaccorFile.rar\" ) dc = DiagnosticConfig . from_step_numbers ( datapath . raw_data , matching_criteria = { \"hppc\" : ( \"contains\" , [( 1 , 2 , 4 , 6 , 8 )]), \"rpt_lowrate\" : ( \"exact\" , [( 12 , 13 )]), \"rpt_highrate\" : ( \"exact\" , [( 15 , 16 )]) } )","title":"1. (b) Defining a DiagnosticConfig automatically using step numbers"},{"location":"Python%20tutorials/advanced_structuring2/#1-c-working-with-diagnosticconfig","text":"Once instantiated, DiagnosticConfig objects have some attributes for working with the cycle indices of each diagnostic cycle type. DiagnosticConfig.all_ix gives the set of all diagnostic cycles, regardless of their type (as long as they are not regular aging cycles) DiagnosticConfig.rpt_ix gives the set of all RPT cycles, even those specified at different C-rates. For more info on how RPT cycles are recognized, see Step 1(a) above. DiagnosticConfig.hppc_ix gives the set of all HPPC cycles, even those with different parameters. DiagnosticConfig.cycles gives a mapping from a cycle type string (e.g., \"rpt_lowrate\" ) to the set of it's cycle indices (e.g., {1, 101, 201, ...} ) DiagnosticConfig.type_by_ix gives a mapping from cycle index (e.g., 101 ) to the cycle type string (e.g., \"rpt_lowrate\" ) Here is an example: from beep.structure.diagnostic import DiagnosticConfig rpt1_ix = set ( range ( 1 , 1002 , 200 )) rpt2_ix = set ( range ( 2 , 1003 , 200 )) hppc1_ix = { 12 , 512 } hppc2_ix = { 115 , 718 , 910 } reset_ix = { 0 , 1000 } abnormal_ix = set ( range ( 5 , 520 , 50 )) dc = DiagnosticConfig ( { \"rpt1\" : rpt1_ix , \"rpt2\" : rpt2_ix , \"hppc1\" : hppc1_ix , \"hppc2\" : hppc2_ix , \"reset_\" : reset_ix , \"abnormal\" : abnormal_ix }, ) print ( \"All diagnostic indices:\" , dc . all_ix ) print ( \"All RPT indices:\" , dc . rpt_ix ) print ( \"All HPPC indices:\" , dc . hppc_ix ) print ( \"RPT1 indices:\" , dc . cycles [ \"rpt_lowrate\" ]) print ( \"Cycle type of cycle 12:\" , dc . type_by_ix [ 12 ]) All diagnostic indices: {0, 1, 2, 5, 12, 55...} All RPT indices: {1, 2, 201, 202, 401, 402...} All HPPC indices: {12, 115, 512, 718, 910} RPT lowrate indices: {1, 201, 401, 601,...} Cycle type of cycle 12: hppc1","title":"1. (c) Working with DiagnosticConfig"},{"location":"Python%20tutorials/advanced_structuring2/#2-set-the-diagnosticconfig-object-to-beepdatapathdiagnostic","text":"Once DiagnosticConfig is instantiated alongside a datapath, set the diagnostic attribute of a BEEPDatapath to that object. datapath.diagnostic = diagnostic_config_object","title":"2. Set the DiagnosticConfig object to BEEPDatapath.diagnostic"},{"location":"Python%20tutorials/advanced_structuring2/#3-interpolate","text":"You can now structure files normally using BEEPDatapath.structure(...) (for a full structuring of both diagnostic and normal cycles) or BEEPDatapath.interpolate_diagnostic_cycles(...) (for diagnostic cycles only). Here is a full example: from beep.structure.novonix import NovonixDatapath from beep.structure.diagnostic import DiagnosticConfig nd = NovonixDatapath . from_file ( \"MyNovonixFile.091\" ) dc = DiagnosticConfig ( { \"rpt\" : set ( range ( 1 , 1002 , 200 )), \"hppc\" : { 12 , 512 }, \"reset\" : { 0 , 1000 }, }, ) nd . diagnostic = dc nd . structure ()","title":"3. Interpolate!"}]}
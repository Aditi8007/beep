{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 BEEP is a set of tools designed to support Battery Evaluation and Early Prediction of cycle life corresponding to the research of the d3batt program and the Toyota Research Institute . BEEP enables parsing and handing of electrochemical battery cycling data via data objects reflecting cycling run data, experimental protocols, featurization, and modeling of cycle life. Currently beep supports arbin, maccor and biologic cyclers. We are currently looking for experienced python developers to help us improve this package and implement new features. Please contact any of the maintainers for more information. Installation \u00b6 To a base install, do: pip install beep If you want to develop BEEP and run tests, clone the repo via git and use pip (or python setup.py develop ) for an editable install: git clone git@github.com:ToyotaResearchInstitute/BEEP.git cd BEEP pip install -e . [ tests ] Environment \u00b6 To configure the use of AWS resources its necessary to set the environment variable BEEP_ENV . For most users 'dev' is the appropriate choice since it assumes that no AWS resources are available. export BEEP_ENV = 'dev' For processing file locally its necessary to configure the folder structure export BEEP_PROCESSING_DIR = '/path/to/beep/data/' Testing \u00b6 Make sure you have installed the required testing packages (see installation). You can use pytest for running unittests. In order to run tests the environment variable needs to be set (i.e. export BEEP_ENV='dev' ) pytest beep How to cite \u00b6 If you use BEEP, please cite this article: P. Herring, C. Balaji Gopal, M. Aykol, J.H. Montoya, A. Anapolsky, P.M. Attia, W. Gent, J.S. Hummelsh\u00f8j, L. Hung, H.-K. Kwon, P. Moore, D. Schweigert, K.A. Severson, S. Suram, Z. Yang, R.D. Braatz, B.D. Storey, SoftwareX 11 (2020) 100506. https://doi.org/10.1016/j.softx.2020.100506","title":"Introduction"},{"location":"#introduction","text":"BEEP is a set of tools designed to support Battery Evaluation and Early Prediction of cycle life corresponding to the research of the d3batt program and the Toyota Research Institute . BEEP enables parsing and handing of electrochemical battery cycling data via data objects reflecting cycling run data, experimental protocols, featurization, and modeling of cycle life. Currently beep supports arbin, maccor and biologic cyclers. We are currently looking for experienced python developers to help us improve this package and implement new features. Please contact any of the maintainers for more information.","title":"Introduction"},{"location":"#installation","text":"To a base install, do: pip install beep If you want to develop BEEP and run tests, clone the repo via git and use pip (or python setup.py develop ) for an editable install: git clone git@github.com:ToyotaResearchInstitute/BEEP.git cd BEEP pip install -e . [ tests ]","title":"Installation"},{"location":"#environment","text":"To configure the use of AWS resources its necessary to set the environment variable BEEP_ENV . For most users 'dev' is the appropriate choice since it assumes that no AWS resources are available. export BEEP_ENV = 'dev' For processing file locally its necessary to configure the folder structure export BEEP_PROCESSING_DIR = '/path/to/beep/data/'","title":"Environment"},{"location":"#testing","text":"Make sure you have installed the required testing packages (see installation). You can use pytest for running unittests. In order to run tests the environment variable needs to be set (i.e. export BEEP_ENV='dev' ) pytest beep","title":"Testing"},{"location":"#how-to-cite","text":"If you use BEEP, please cite this article: P. Herring, C. Balaji Gopal, M. Aykol, J.H. Montoya, A. Anapolsky, P.M. Attia, W. Gent, J.S. Hummelsh\u00f8j, L. Hung, H.-K. Kwon, P. Moore, D. Schweigert, K.A. Severson, S. Suram, Z. Yang, R.D. Braatz, B.D. Storey, SoftwareX 11 (2020) 100506. https://doi.org/10.1016/j.softx.2020.100506","title":"How to cite"},{"location":"cli/","text":"Command line interface \u00b6 Introduction \u00b6 BEEP provides a command line interface for easier usage of the BEEP pipeline. There are five main steps to the BEEP pipeline: Collation: logically organize your data from various battery cycler machines and experiments Validation: check that BEEP will be able to run on your data Structuring: convert cycler outputs into a minimal, universal format Featurization: adding features for machine learning Run model: run a machine learning model to predict battery lifetimes. Each command accepts a JSON string as input in order to provide flexibility and better automation. collate : standardize filenames among many cyclers/runs \u00b6 The collate script takes no input, and operates by assuming the BEEP_PROCESSING_DIR (default / ) has subdirectories /data-share/raw_cycler_files and data-share/renamed_cycler_files/FastCharge . The script moves files from the /data-share/raw_cycler_files directory, parses the metadata, and renames them according to a combination of protocol, channel number, and date, placing them in /data-share/renamed_cycler_files . The script output is a json string that contains the following fields: fid - The file id used internally for renaming filename - full paths for raw cycler filenames strname - the string name associated with the file (i. e. scrubbed of csv ) file_list - full paths for the new, renamed, cycler files protocol - the cycling protocol corresponding to each file channel_no - the channel number corresponding to each file date - the date corresponding to each file Example: $ collate { \"mode\" : \"events_off\" , \"fid\" : [ 0 , 1 , 2 ], \"strname\" : [ \"2017-05-09_test-TC-contact\" , \"2017-08-14_8C-5per_3_47C\" , \"2017-12-04_4_65C-69per_6C\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], \"protocol\" : [ null , \"8C(5%)-3.47C\" , \"4.65C(69%)-6C\" ], \"date\" : [ \"2017-05-09\" , \"2017-08-14\" , \"2017-12-04\" ], \"channel_no\" : [ \"CH33\" , \"CH44\" , \"CH29\" ], \"filename\" : [ \"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\" , \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\" , \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\" ] } validate : ensure your data is valid \u00b6 The validation script, validate , runs the validation procedure contained in beep.validate on renamed files according to the output of rename above. It also updates a general json validation record in /data-share/validation/validation.json . The input json must contain the following fields file_list - the list of filenames to be validated mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json will have the following fields: validity - a list of validation results, e. g. [\"valid\", \"valid\", \"invalid\"] file_list - a list of full path filenames which have been processed Example: $ validate '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"strname\": [\"2017-05-09_test-TC-contact\", \"2017-08-14_8C-5per_3_47C\", \"2017-12-04_4_65C-69per_6C\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"], \"protocol\": [null, \"8C(5%)-3.47C\", \"4.65C(69%)-6C\"], \"date\": [\"2017-05-09\", \"2017-08-14\", \"2017-12-04\"], \"channel_no\": [\"CH33\", \"CH44\", \"CH29\"], \"filename\": [\"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\", \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\", \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\"] }' { \"validity\" : [ \"invalid\" , \"invalid\" , \"valid\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], } structure : convert cycler data to universal formats \u00b6 The structure script will run the data structuring on specified filenames corresponding to validated raw cycler files. It places the structured datafiles in /data-share/structure . The input json must contain the following fields: * file_list - a list of full path filenames which have been processed * validity - a list of boolean validation results, e. g. [True, True, False] * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json contains the following fields: invalid_file_list - a list of invalid files according to the validity file_list - a list of files which have been structured into processed_cycler_runs Example: $ structure '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"validity\": [\"invalid\", \"invalid\", \"valid\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"]}' { \"invalid_file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" ], \"file_list\" : [ \"/data-share/structure/FastCharge_2_CH29_structure.json\" ], } featurize : add features for machine learning \u00b6 The featurize script will generate features according to the methods contained in beep.generate_features. It places output files corresponding to features in /data-share/features/ . The input json must contain the following fields file_list - a list of processed cycler runs for which to generate features mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json file will contain the following: file_list - a list of filenames corresponding to the locations of the features Example: $ featurize '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"invalid_file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\"], \"file_list\": [\"/data-share/structure/FastCharge_2_CH29_structure.json\"] }' { \"file_list\" : [ \"/data-share/features/FastCharge_2_CH29_full_model_features.json\" ]} run_model : run a machine learning model \u00b6 The run_model script will generate a model and create predictions based on the features previously generated by the generate_features. It stores its outputs in /data-share/predictions/ The input json must contain the following fields * file_list - list of files corresponding to model features * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json will contain the following fields * file_list - list of files corresponding to model predictions Example: $ run_model '{ \"mode\": \"events_off\", \"run_list\": [34], \"file_list\": [\"/data-share/features/FastCharge_2_CH29_full_model_features.json\"] }' { \"file_list\" : [ \"/data-share/predictions/FastCharge_2_CH29_full_model_predictions.json\" ], }","title":"Command line interface"},{"location":"cli/#command-line-interface","text":"","title":"Command line interface"},{"location":"cli/#introduction","text":"BEEP provides a command line interface for easier usage of the BEEP pipeline. There are five main steps to the BEEP pipeline: Collation: logically organize your data from various battery cycler machines and experiments Validation: check that BEEP will be able to run on your data Structuring: convert cycler outputs into a minimal, universal format Featurization: adding features for machine learning Run model: run a machine learning model to predict battery lifetimes. Each command accepts a JSON string as input in order to provide flexibility and better automation.","title":"Introduction"},{"location":"cli/#collate-standardize-filenames-among-many-cyclersruns","text":"The collate script takes no input, and operates by assuming the BEEP_PROCESSING_DIR (default / ) has subdirectories /data-share/raw_cycler_files and data-share/renamed_cycler_files/FastCharge . The script moves files from the /data-share/raw_cycler_files directory, parses the metadata, and renames them according to a combination of protocol, channel number, and date, placing them in /data-share/renamed_cycler_files . The script output is a json string that contains the following fields: fid - The file id used internally for renaming filename - full paths for raw cycler filenames strname - the string name associated with the file (i. e. scrubbed of csv ) file_list - full paths for the new, renamed, cycler files protocol - the cycling protocol corresponding to each file channel_no - the channel number corresponding to each file date - the date corresponding to each file Example: $ collate { \"mode\" : \"events_off\" , \"fid\" : [ 0 , 1 , 2 ], \"strname\" : [ \"2017-05-09_test-TC-contact\" , \"2017-08-14_8C-5per_3_47C\" , \"2017-12-04_4_65C-69per_6C\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], \"protocol\" : [ null , \"8C(5%)-3.47C\" , \"4.65C(69%)-6C\" ], \"date\" : [ \"2017-05-09\" , \"2017-08-14\" , \"2017-12-04\" ], \"channel_no\" : [ \"CH33\" , \"CH44\" , \"CH29\" ], \"filename\" : [ \"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\" , \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\" , \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\" ] }","title":"collate: standardize filenames among many cyclers/runs"},{"location":"cli/#validate-ensure-your-data-is-valid","text":"The validation script, validate , runs the validation procedure contained in beep.validate on renamed files according to the output of rename above. It also updates a general json validation record in /data-share/validation/validation.json . The input json must contain the following fields file_list - the list of filenames to be validated mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json will have the following fields: validity - a list of validation results, e. g. [\"valid\", \"valid\", \"invalid\"] file_list - a list of full path filenames which have been processed Example: $ validate '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"strname\": [\"2017-05-09_test-TC-contact\", \"2017-08-14_8C-5per_3_47C\", \"2017-12-04_4_65C-69per_6C\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"], \"protocol\": [null, \"8C(5%)-3.47C\", \"4.65C(69%)-6C\"], \"date\": [\"2017-05-09\", \"2017-08-14\", \"2017-12-04\"], \"channel_no\": [\"CH33\", \"CH44\", \"CH29\"], \"filename\": [\"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\", \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\", \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\"] }' { \"validity\" : [ \"invalid\" , \"invalid\" , \"valid\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], }","title":"validate: ensure your data is valid"},{"location":"cli/#structure-convert-cycler-data-to-universal-formats","text":"The structure script will run the data structuring on specified filenames corresponding to validated raw cycler files. It places the structured datafiles in /data-share/structure . The input json must contain the following fields: * file_list - a list of full path filenames which have been processed * validity - a list of boolean validation results, e. g. [True, True, False] * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json contains the following fields: invalid_file_list - a list of invalid files according to the validity file_list - a list of files which have been structured into processed_cycler_runs Example: $ structure '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"validity\": [\"invalid\", \"invalid\", \"valid\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"]}' { \"invalid_file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" ], \"file_list\" : [ \"/data-share/structure/FastCharge_2_CH29_structure.json\" ], }","title":"structure: convert cycler data to universal formats"},{"location":"cli/#featurize-add-features-for-machine-learning","text":"The featurize script will generate features according to the methods contained in beep.generate_features. It places output files corresponding to features in /data-share/features/ . The input json must contain the following fields file_list - a list of processed cycler runs for which to generate features mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json file will contain the following: file_list - a list of filenames corresponding to the locations of the features Example: $ featurize '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"invalid_file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\"], \"file_list\": [\"/data-share/structure/FastCharge_2_CH29_structure.json\"] }' { \"file_list\" : [ \"/data-share/features/FastCharge_2_CH29_full_model_features.json\" ]}","title":"featurize: add features for machine learning"},{"location":"cli/#run_model-run-a-machine-learning-model","text":"The run_model script will generate a model and create predictions based on the features previously generated by the generate_features. It stores its outputs in /data-share/predictions/ The input json must contain the following fields * file_list - list of files corresponding to model features * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json will contain the following fields * file_list - list of files corresponding to model predictions Example: $ run_model '{ \"mode\": \"events_off\", \"run_list\": [34], \"file_list\": [\"/data-share/features/FastCharge_2_CH29_full_model_features.json\"] }' { \"file_list\" : [ \"/data-share/predictions/FastCharge_2_CH29_full_model_predictions.json\" ], }","title":"run_model: run a machine learning model"},{"location":"data/","text":"Cycler data requirements \u00b6 BEEP automatically parses and structures data based on specific outputs from various battery cyclers. The following column headers marked \"required\" are required for downstream processing of each cycler. BEEP currently supports five brands of battery cyclers: Arbin Maccor Indigo BioLogic Neware Arbin \u00b6 Arbin data files are of the form name_of_file_CHXX.csv with an associated metadata file name_of_file_CHXX_Metadata.csv Cycler Data \u00b6 Column name (case insensitive) Required Explanation Unit Data Type data_point index of this data point int32 test_time time of data point relative to start seconds float32 datetime \u2713 time of data point relative to epoch time seconds float32 step_time elapsed time counted from the starting point of present active step seconds float32 step_index \u2713 currently running step number in the active schedule int16 cycle_index \u2713 currently active test cycle number int32 current \u2713 measured value of present channel current Amps float32 voltage \u2713 measured value of present channel voltage Volts float32 charge_capacity \u2713 cumulative value of present channel charge capacity Amp-hr float64 discharge_capacity \u2713 cumulative value of present channel discharge capacity Amp-hr float64 charge_energy \u2713 cumulative value of present channel charge energy Watt-hr float64 discharge_energy \u2713 cumulative value of present channel discharge energy Watt-hr float64 dv/dt the first-order change rate of voltage Volts/seconds float32 internal_resistance calculated internal resistance Ohms float32 temperature cell temperature \u00b0Celsius float32 Metadata \u00b6 Field name Required test_id device_id iv_ch_id first_start_datetime schedule_file_name item_id resumed_times last_end_datetime databases grade_id has_aux has_special schedule_version log_aux_data_flag log_special_data_flag rowstate canconfig_filename m_ncanconfigmd5 value value2 Maccor \u00b6 Maccor files are single tabular text files matching the regex pattern \".*\\\\d{5,6}.*\\\\d{3}\" . Column name (case insensitive) Required Explanation Unit Data Type rec# \u2713 data point number (index) int32 cyc# \u2713 cycle number int32 step \u2713 step number int16 test (sec) \u2713 total time elapsed seconds float32 step (sec) \u2713 time within this step seconds float32 amp-hr \u2713 charge capacity Amp-hr float64 watt-hr \u2713 charge energy Watt-hr float64 amps \u2713 channel current Amps float32 volts \u2713 channel voltage Volts float32 state \u2713 charging/discharging/etc. state of the battery category es \u2713 category dpt time \u2713 date and time of data point Date-Time str acimp/ohms \u2713 AC impedance of circuit Ohm float32 dcir/ohms \u2713 DC internal resistance Ohm float32 wf chg cap \u2713 charge capacity (based on waveform, if available) Amp-hh float32 wf dis cap \u2713 discharge capacity (based on waveform, if available) Amp-hr float32 wf chg e \u2713 charge energy (based on waveform, if available) Watt-hr float32 wf dis e \u2713 discharge energy (based on waveform, if available) Watt-hr float32 range \u2713 uint8 var1 \u2713 float16 var2 \u2713 float16 var3 \u2713 float16 var4 \u2713 float16 var5 \u2713 float16 var6 \u2713 float16 var7 \u2713 float16 var8 \u2713 float16 var9 \u2713 float16 var10 \u2713 float16 var11 \u2713 float16 var12 \u2713 float16 var13 \u2713 float16 var14 \u2713 float16 var15 \u2713 float16 Indigo \u00b6 Indigo files are single hierarchical data files ( *.h5 ) with the mandatory group store field \"time_series_data\" . Column name (case insensitive) Required Explanation Unit Data Type cell_coulomb_count_c \u2713 instantaneous cell charge Coulombs cell_current_a \u2713 A cell_energy_j \u2713 cell energy Joules cell_id \u2713 identifier of the cell cell_power_w instantaneous cell power Watts cell_temperature_c temperature of the cell \u00b0Celsius cell_voltage_v \u2713 voltage of the cell Volts cycle_count \u2713 index of the cycle experiment_count index of the experiment experiment_type half_cycle_count \u2713 system_time_us \u2713 test time of data point relative to epoch microseconds time_s time elapsed since test beginning seconds BioLogic \u00b6 BioLogic files are ASCII text files of the form *.mpt with matching *.mpl log/metadata files. BioLogic cycler data is currently only supported for raw operations (e.g., ingestion via RawCyclerRun analysis) and is not supported for downstream processing. Column name Required Explanation Unit Data Type cycle number \u2713 index of this cycle int half cycle \u2713 int Ecell/V \u2713 cell potential Volts float I/mA \u2713 cell current mAmps float Q discharge/mA.h \u2713 discharge capacity mAmp-hr float Q charge/mA.h \u2713 charge capacty mAmp-hr float Energy charge/W.h \u2713 charge energy Watt-hr float Energy discharge/W.h \u2713 discharge energy Watt-hr float Various other fields in BioLogic data or metadata files are not required. Neware \u00b6 Neware files are singular *.csv files. Note: Neware files use non-standard csv formatting; some fields may require further processing or structuring before input to beep . Column name Required Explanation Unit Data Type Record ID \u2713 index of this data point int32 Realtime \u2713 date-time format for this point Time(h:min:s.ms) \u2713 recorded time for this point seconds float32 Step ID \u2713 index of this step int16 Cycle ID \u2713 index of this cycle int32 Current(mA) \u2713 cell current mAmps float32 Voltage(V) \u2713 cell voltage Volts float32 Capacitance_Chg(mAh) \u2713 charge capacity mAmp-hr float64 Capacitance_DChg(mAh) \u2713 discharge capacity mAmp-hr float64 Engy_Chg(mWh) \u2713 charge energy mWatt-hr float64 Engy_DChg(mWh) \u2713 discharge energy mWatt-hr float64 DCIR(O) \u2713 DC internal resistance float32 Capacity(mAh) \u2713 mAmp-hr Capacity Density(mAh/g) \u2713 mAmp-hr/gram Energy(mWh) \u2713 mWatt-hr CmpEng(mWh/g) \u2713 mWatt-hr/gram Min-T(C) \u2713 mimumum cell temperature \u00b0Celsius Max-T(C) \u2713 max cell temperature \u00b0Celsius Avg-T(C) \u2713 average cell temperature \u00b0Celsius Power(mW) \u2713 instantaneous power mWatt dQ/dV(mAh/V) \u2713 differential capacity mAmp-hr/Volt dQm/dV(mAh/V.g) \u2713 differential capacity density mAmp-hr/Volt-gram Temperature(C) \u2713 temperature (alternate sensor) \u00b0Celsius float32","title":"Cycler data requirements"},{"location":"data/#cycler-data-requirements","text":"BEEP automatically parses and structures data based on specific outputs from various battery cyclers. The following column headers marked \"required\" are required for downstream processing of each cycler. BEEP currently supports five brands of battery cyclers: Arbin Maccor Indigo BioLogic Neware","title":"Cycler data requirements"},{"location":"data/#arbin","text":"Arbin data files are of the form name_of_file_CHXX.csv with an associated metadata file name_of_file_CHXX_Metadata.csv","title":"Arbin"},{"location":"data/#cycler-data","text":"Column name (case insensitive) Required Explanation Unit Data Type data_point index of this data point int32 test_time time of data point relative to start seconds float32 datetime \u2713 time of data point relative to epoch time seconds float32 step_time elapsed time counted from the starting point of present active step seconds float32 step_index \u2713 currently running step number in the active schedule int16 cycle_index \u2713 currently active test cycle number int32 current \u2713 measured value of present channel current Amps float32 voltage \u2713 measured value of present channel voltage Volts float32 charge_capacity \u2713 cumulative value of present channel charge capacity Amp-hr float64 discharge_capacity \u2713 cumulative value of present channel discharge capacity Amp-hr float64 charge_energy \u2713 cumulative value of present channel charge energy Watt-hr float64 discharge_energy \u2713 cumulative value of present channel discharge energy Watt-hr float64 dv/dt the first-order change rate of voltage Volts/seconds float32 internal_resistance calculated internal resistance Ohms float32 temperature cell temperature \u00b0Celsius float32","title":"Cycler Data"},{"location":"data/#metadata","text":"Field name Required test_id device_id iv_ch_id first_start_datetime schedule_file_name item_id resumed_times last_end_datetime databases grade_id has_aux has_special schedule_version log_aux_data_flag log_special_data_flag rowstate canconfig_filename m_ncanconfigmd5 value value2","title":"Metadata"},{"location":"data/#maccor","text":"Maccor files are single tabular text files matching the regex pattern \".*\\\\d{5,6}.*\\\\d{3}\" . Column name (case insensitive) Required Explanation Unit Data Type rec# \u2713 data point number (index) int32 cyc# \u2713 cycle number int32 step \u2713 step number int16 test (sec) \u2713 total time elapsed seconds float32 step (sec) \u2713 time within this step seconds float32 amp-hr \u2713 charge capacity Amp-hr float64 watt-hr \u2713 charge energy Watt-hr float64 amps \u2713 channel current Amps float32 volts \u2713 channel voltage Volts float32 state \u2713 charging/discharging/etc. state of the battery category es \u2713 category dpt time \u2713 date and time of data point Date-Time str acimp/ohms \u2713 AC impedance of circuit Ohm float32 dcir/ohms \u2713 DC internal resistance Ohm float32 wf chg cap \u2713 charge capacity (based on waveform, if available) Amp-hh float32 wf dis cap \u2713 discharge capacity (based on waveform, if available) Amp-hr float32 wf chg e \u2713 charge energy (based on waveform, if available) Watt-hr float32 wf dis e \u2713 discharge energy (based on waveform, if available) Watt-hr float32 range \u2713 uint8 var1 \u2713 float16 var2 \u2713 float16 var3 \u2713 float16 var4 \u2713 float16 var5 \u2713 float16 var6 \u2713 float16 var7 \u2713 float16 var8 \u2713 float16 var9 \u2713 float16 var10 \u2713 float16 var11 \u2713 float16 var12 \u2713 float16 var13 \u2713 float16 var14 \u2713 float16 var15 \u2713 float16","title":"Maccor"},{"location":"data/#indigo","text":"Indigo files are single hierarchical data files ( *.h5 ) with the mandatory group store field \"time_series_data\" . Column name (case insensitive) Required Explanation Unit Data Type cell_coulomb_count_c \u2713 instantaneous cell charge Coulombs cell_current_a \u2713 A cell_energy_j \u2713 cell energy Joules cell_id \u2713 identifier of the cell cell_power_w instantaneous cell power Watts cell_temperature_c temperature of the cell \u00b0Celsius cell_voltage_v \u2713 voltage of the cell Volts cycle_count \u2713 index of the cycle experiment_count index of the experiment experiment_type half_cycle_count \u2713 system_time_us \u2713 test time of data point relative to epoch microseconds time_s time elapsed since test beginning seconds","title":"Indigo"},{"location":"data/#biologic","text":"BioLogic files are ASCII text files of the form *.mpt with matching *.mpl log/metadata files. BioLogic cycler data is currently only supported for raw operations (e.g., ingestion via RawCyclerRun analysis) and is not supported for downstream processing. Column name Required Explanation Unit Data Type cycle number \u2713 index of this cycle int half cycle \u2713 int Ecell/V \u2713 cell potential Volts float I/mA \u2713 cell current mAmps float Q discharge/mA.h \u2713 discharge capacity mAmp-hr float Q charge/mA.h \u2713 charge capacty mAmp-hr float Energy charge/W.h \u2713 charge energy Watt-hr float Energy discharge/W.h \u2713 discharge energy Watt-hr float Various other fields in BioLogic data or metadata files are not required.","title":"BioLogic"},{"location":"data/#neware","text":"Neware files are singular *.csv files. Note: Neware files use non-standard csv formatting; some fields may require further processing or structuring before input to beep . Column name Required Explanation Unit Data Type Record ID \u2713 index of this data point int32 Realtime \u2713 date-time format for this point Time(h:min:s.ms) \u2713 recorded time for this point seconds float32 Step ID \u2713 index of this step int16 Cycle ID \u2713 index of this cycle int32 Current(mA) \u2713 cell current mAmps float32 Voltage(V) \u2713 cell voltage Volts float32 Capacitance_Chg(mAh) \u2713 charge capacity mAmp-hr float64 Capacitance_DChg(mAh) \u2713 discharge capacity mAmp-hr float64 Engy_Chg(mWh) \u2713 charge energy mWatt-hr float64 Engy_DChg(mWh) \u2713 discharge energy mWatt-hr float64 DCIR(O) \u2713 DC internal resistance float32 Capacity(mAh) \u2713 mAmp-hr Capacity Density(mAh/g) \u2713 mAmp-hr/gram Energy(mWh) \u2713 mWatt-hr CmpEng(mWh/g) \u2713 mWatt-hr/gram Min-T(C) \u2713 mimumum cell temperature \u00b0Celsius Max-T(C) \u2713 max cell temperature \u00b0Celsius Avg-T(C) \u2713 average cell temperature \u00b0Celsius Power(mW) \u2713 instantaneous power mWatt dQ/dV(mAh/V) \u2713 differential capacity mAmp-hr/Volt dQm/dV(mAh/V.g) \u2713 differential capacity density mAmp-hr/Volt-gram Temperature(C) \u2713 temperature (alternate sensor) \u00b0Celsius float32","title":"Neware"},{"location":"tutorial1/","text":"Python tutorial 1: Start here \u00b6 This notebook is meant to demonstrate basic usage of the beep package with data from \"Data-driven prediction of battery cycle life before capacity degradation\" KA Severson, et al. Nature Energy 4 (5), 383-391 This data is available for download from https://data.matr.io/1/ . For brevity, only one test is included in this notebook but the example can easily be extended to a larger number of files. Step 0: Install beep and set environment \u00b6 If you have not already installed beep, run: pip install beep We will also need to set two environment variables for beep. BEEP_ENV : Set the compute environment for beep to use (AWS, local, etc.). We will set to dev for working locally. BEEP_PROCESSING_DIR : The central directory BEEP will use to process intermediate files and organize data. export BEEP_ENV = \"dev\" export BEEP_PROCESSING_DIR = \"./tutorial/\" Step 1: Download example battery cycler data \u00b6 The example data set we are using here comes from a set of A123 LFP cells cycled under fast charge conditions. While this tutorial is configured for downloading a single cell, its also possible to download the entire data set and run all of the processing steps on all of the data. Note that for Arbin files, we recommend having the metadata file in addition to the data file in order to perform the data structuring correctly (though it is not required). import os import requests print ( 'Beginning file download with requests' ) this_dir = os . path . dirname ( os . path . abspath ( __file__ )) data_dir = os . path . join ( this_dir , 'Severson-et-al' ) try : os . makedirs ( data_dir ) except FileExistsError : pass url = 'https://data.matr.io/1/api/v1/file/5c86c0bafa2ede00015ddf70/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36.csv' ), 'wb' ) as f : f . write ( r . content ) url = 'https://data.matr.io/1/api/v1/file/5c86c0b5fa2ede00015ddf6d/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36_Metadata.csv' ), 'wb' ) as f : f . write ( r . content ) # Retrieve HTTP meta-data print ( \"Status code\" , r . status_code ) print ( \"File type recieved\" , r . headers [ 'content-type' ]) print ( \"File encoding\" , r . encoding ) # output Beginning file download with requests Status code 200 File type recieved text / csv File encoding ISO - 8859 - 1 You should now have two files in your data directory: \u251c\u2500\u2500 Severson-et-al \u2502 \u251c\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36.csv \u2502 \u2514\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36_Metadata.csv Step 2: Data pipelining - validation, structuring, featurization \u00b6 Now that we have our data, we can start using BEEP! Fist, we can create a list of all of the files in the data directory and then runs the three data pipeline processing steps on each of the files. a. Validation \u00b6 This module determine if the data conforms to expected format with the correct column names and with values inside an expected range. b. Structuring \u00b6 The structuring module turns the time series data from the cycler machine into a json-like structure with DataFrame objects. The DataFrame objects include a summary DataFrame with per cycle statistics, and a DataFrame with interpolated charge and discharge steps of the regular cycles. For files that have diagnostic cycles that were programmatically inserted, separate DataFrame objects are created with summary statistics and interpolated steps for the diagnostic cycles. c. Featurization \u00b6 Featurization uses the structured objects to calculate statistically and physically relevant quantities for the purpose of building predictive machine learning models. The objects can be selected and joined for the purposes of training the model, or used for predicting individual outcomes. import json import glob # Import beep scripts from beep import validate , structure , featurize file_list = glob . glob ( os . path . join ( data_dir , '*[0-9].csv' )) mode = 'events_off' mapped = { \"mode\" : 'events_off' , # mode run|test|events_off \"file_list\" : file_list , # list of file paths ['path/test1.csv', 'path/test2.csv'] 'run_list' : list ( range ( len ( file_list ))) # list of run_ids [0, 1] } mapped = json . dumps ( mapped ) # Validation validated = validate . validate_file_list_from_json ( mapped ) validated_output = json . loads ( validated ) validated_output [ 'mode' ] = mode # mode run|test|events_off validated_output [ 'run_list' ] = list ( range ( len ( validated_output [ 'file_list' ]))) validated = json . dumps ( validated_output ) print ( validated ) # Data structuring structured = structure . process_file_list_from_json ( validated ) structured_output = json . loads ( structured ) structured_output [ 'mode' ] = mode # mode run|test|events_off structured_output [ 'run_list' ] = list ( range ( len ( file_list ))) structured = json . dumps ( structured_output ) print ( structured ) # Featurization featurized = featurize . process_file_list_from_json ( structured ) featurized_output = json . loads ( featurized ) featurized_output [ 'mode' ] = mode # mode run|test|events_off featurized_output [ 'run_list' ] = list ( range ( len ( file_list ))) featurized = json . dumps ( featurized_output ) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00, 1.74s/it] {\"file_list\": [\"./Severson-et-al/2017-05-12_6C-50per_3_6C_CH36.csv\"], \"run_list\": [0], \"validity\": [\"valid\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"mode\": \"events_off\"} 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [03:48<00:00, 3.85it/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [02:07<00:00, 6.89it/s] {\"file_list\": [\"/path/to/your/beep/processing/data-share/structure/2017-05-12_6C-50per_3_6C_CH36_structure.json\"], \"run_list\": [0], \"result_list\": [\"success\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"invalid_file_list\": [], \"mode\": \"events_off\"} Step 3: Examine data in the structure file \u00b6 Interpolation data \u00b6 The code below demonstrates how to access the DataFrame objects in the structure file. Loading the file is substantially faster than analyzing the raw time series data. The interpolated data also provides the ability to calculate differences between cycles. from matplotlib import pyplot as plt from monty.serialization import loadfn processing_dir = os . environ . get ( \"BEEP_PROCESSING_DIR\" , \"tutorial\" ) struct = loadfn ( os . path . join ( processing_dir , 'data-share' , 'structure' , '2017-05-12_6C-50per_3_6C_CH36_structure.json' )) reg_charge = struct . structured_data [ struct . structured_data . step_type == 'charge' ] print ( reg_charge . current [ reg_charge . cycle_index == 25 ] . mean ()) print ( reg_charge . cycle_index . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 25 ] . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ] . max ()) plt . plot ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ], reg_charge . voltage [ reg_charge . cycle_index == 600 ]) plt . show () # output 4.697416 876 1.1737735 1.1737735 Summary data \u00b6 The summary data provides a quick way of determine how the battery cell degrades during the cycling experiment. Quantities such as energy efficiency per cycle and total charge throughput at a given cycle number are calculated. plt . plot ( struct . structured_summary . cycle_index , struct . structured_summary . energy_efficiency ) plt . show () Congrats! \u00b6 You've made it to the end of the tutorial.","title":"Python tutorial 1: Start here"},{"location":"tutorial1/#python-tutorial-1-start-here","text":"This notebook is meant to demonstrate basic usage of the beep package with data from \"Data-driven prediction of battery cycle life before capacity degradation\" KA Severson, et al. Nature Energy 4 (5), 383-391 This data is available for download from https://data.matr.io/1/ . For brevity, only one test is included in this notebook but the example can easily be extended to a larger number of files.","title":"Python tutorial 1: Start here"},{"location":"tutorial1/#step-0-install-beep-and-set-environment","text":"If you have not already installed beep, run: pip install beep We will also need to set two environment variables for beep. BEEP_ENV : Set the compute environment for beep to use (AWS, local, etc.). We will set to dev for working locally. BEEP_PROCESSING_DIR : The central directory BEEP will use to process intermediate files and organize data. export BEEP_ENV = \"dev\" export BEEP_PROCESSING_DIR = \"./tutorial/\"","title":"Step 0: Install beep and set environment"},{"location":"tutorial1/#step-1-download-example-battery-cycler-data","text":"The example data set we are using here comes from a set of A123 LFP cells cycled under fast charge conditions. While this tutorial is configured for downloading a single cell, its also possible to download the entire data set and run all of the processing steps on all of the data. Note that for Arbin files, we recommend having the metadata file in addition to the data file in order to perform the data structuring correctly (though it is not required). import os import requests print ( 'Beginning file download with requests' ) this_dir = os . path . dirname ( os . path . abspath ( __file__ )) data_dir = os . path . join ( this_dir , 'Severson-et-al' ) try : os . makedirs ( data_dir ) except FileExistsError : pass url = 'https://data.matr.io/1/api/v1/file/5c86c0bafa2ede00015ddf70/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36.csv' ), 'wb' ) as f : f . write ( r . content ) url = 'https://data.matr.io/1/api/v1/file/5c86c0b5fa2ede00015ddf6d/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36_Metadata.csv' ), 'wb' ) as f : f . write ( r . content ) # Retrieve HTTP meta-data print ( \"Status code\" , r . status_code ) print ( \"File type recieved\" , r . headers [ 'content-type' ]) print ( \"File encoding\" , r . encoding ) # output Beginning file download with requests Status code 200 File type recieved text / csv File encoding ISO - 8859 - 1 You should now have two files in your data directory: \u251c\u2500\u2500 Severson-et-al \u2502 \u251c\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36.csv \u2502 \u2514\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36_Metadata.csv","title":"Step 1: Download example battery cycler data"},{"location":"tutorial1/#step-2-data-pipelining-validation-structuring-featurization","text":"Now that we have our data, we can start using BEEP! Fist, we can create a list of all of the files in the data directory and then runs the three data pipeline processing steps on each of the files.","title":"Step 2: Data pipelining - validation, structuring, featurization"},{"location":"tutorial1/#a-validation","text":"This module determine if the data conforms to expected format with the correct column names and with values inside an expected range.","title":"a. Validation"},{"location":"tutorial1/#b-structuring","text":"The structuring module turns the time series data from the cycler machine into a json-like structure with DataFrame objects. The DataFrame objects include a summary DataFrame with per cycle statistics, and a DataFrame with interpolated charge and discharge steps of the regular cycles. For files that have diagnostic cycles that were programmatically inserted, separate DataFrame objects are created with summary statistics and interpolated steps for the diagnostic cycles.","title":"b. Structuring"},{"location":"tutorial1/#c-featurization","text":"Featurization uses the structured objects to calculate statistically and physically relevant quantities for the purpose of building predictive machine learning models. The objects can be selected and joined for the purposes of training the model, or used for predicting individual outcomes. import json import glob # Import beep scripts from beep import validate , structure , featurize file_list = glob . glob ( os . path . join ( data_dir , '*[0-9].csv' )) mode = 'events_off' mapped = { \"mode\" : 'events_off' , # mode run|test|events_off \"file_list\" : file_list , # list of file paths ['path/test1.csv', 'path/test2.csv'] 'run_list' : list ( range ( len ( file_list ))) # list of run_ids [0, 1] } mapped = json . dumps ( mapped ) # Validation validated = validate . validate_file_list_from_json ( mapped ) validated_output = json . loads ( validated ) validated_output [ 'mode' ] = mode # mode run|test|events_off validated_output [ 'run_list' ] = list ( range ( len ( validated_output [ 'file_list' ]))) validated = json . dumps ( validated_output ) print ( validated ) # Data structuring structured = structure . process_file_list_from_json ( validated ) structured_output = json . loads ( structured ) structured_output [ 'mode' ] = mode # mode run|test|events_off structured_output [ 'run_list' ] = list ( range ( len ( file_list ))) structured = json . dumps ( structured_output ) print ( structured ) # Featurization featurized = featurize . process_file_list_from_json ( structured ) featurized_output = json . loads ( featurized ) featurized_output [ 'mode' ] = mode # mode run|test|events_off featurized_output [ 'run_list' ] = list ( range ( len ( file_list ))) featurized = json . dumps ( featurized_output ) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00, 1.74s/it] {\"file_list\": [\"./Severson-et-al/2017-05-12_6C-50per_3_6C_CH36.csv\"], \"run_list\": [0], \"validity\": [\"valid\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"mode\": \"events_off\"} 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [03:48<00:00, 3.85it/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [02:07<00:00, 6.89it/s] {\"file_list\": [\"/path/to/your/beep/processing/data-share/structure/2017-05-12_6C-50per_3_6C_CH36_structure.json\"], \"run_list\": [0], \"result_list\": [\"success\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"invalid_file_list\": [], \"mode\": \"events_off\"}","title":"c. Featurization"},{"location":"tutorial1/#step-3-examine-data-in-the-structure-file","text":"","title":"Step 3: Examine data in the structure file"},{"location":"tutorial1/#interpolation-data","text":"The code below demonstrates how to access the DataFrame objects in the structure file. Loading the file is substantially faster than analyzing the raw time series data. The interpolated data also provides the ability to calculate differences between cycles. from matplotlib import pyplot as plt from monty.serialization import loadfn processing_dir = os . environ . get ( \"BEEP_PROCESSING_DIR\" , \"tutorial\" ) struct = loadfn ( os . path . join ( processing_dir , 'data-share' , 'structure' , '2017-05-12_6C-50per_3_6C_CH36_structure.json' )) reg_charge = struct . structured_data [ struct . structured_data . step_type == 'charge' ] print ( reg_charge . current [ reg_charge . cycle_index == 25 ] . mean ()) print ( reg_charge . cycle_index . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 25 ] . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ] . max ()) plt . plot ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ], reg_charge . voltage [ reg_charge . cycle_index == 600 ]) plt . show () # output 4.697416 876 1.1737735 1.1737735","title":"Interpolation data"},{"location":"tutorial1/#summary-data","text":"The summary data provides a quick way of determine how the battery cell degrades during the cycling experiment. Quantities such as energy efficiency per cycle and total charge throughput at a given cycle number are calculated. plt . plot ( struct . structured_summary . cycle_index , struct . structured_summary . energy_efficiency ) plt . show ()","title":"Summary data"},{"location":"tutorial1/#congrats","text":"You've made it to the end of the tutorial.","title":"Congrats!"},{"location":"tutorial2/","text":"Python tutorial 2: Next steps \u00b6 Here you'll find more info about creating and using beep to do your own custom cycler analysie. BEEPDatapath - One object for ingestion, structuring, and validation Batch functions for structuring Featurization Running and analyzing models Structuring with BEEPDatapath \u00b6 One class for ingestion, structuring, and validation \u00b6 BEEPDatapath is an abstract base class that can handle ingestion, structuring, and validation for many types of cyclers. A datapath object represents a complete processing pipeline for battery cycler data. Each cycler has it's own BEEPDatapath class: ArbinDatapath MaccorDatapath NewareDatapath IndigoDatapath BiologicDatapath All these datapaths implement the same core methods, properties, and attributes, listed below: Methods for loading and serializing battery cycler data \u00b6 *Datapath.from_file(filename) \u00b6 Classmethod to load a raw cycler output file (e.g., a csv) into a datapath object. Once loaded, you can validate or structure the file. # Here we use ArbinDatapath as an example from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" ) *Datapath.to_json_file(filename) \u00b6 Dump the current state of a datapath to a file. Can be later loaded with from_json_file . from beep.structure import NewareDatapath datapath = NewareDatapath . from_file ( \"/path/to/my_raw_neware_file\" ) # do some operations ... # Write the processed file to disk, which can then be loaded. datapath . to_json_file ( \"my_processed_neware_data.json\" ) *Datapath.from_json_file(filename) \u00b6 Classmethod to load a processed cycler file (e.g., a previously structured Datapath) into a datapath object. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_json_file ( \"my_previously_serialized_datapath.json\" ) *Datapath(data, metadata, paths=None, **kwargs) \u00b6 Initialize any cycler from the raw data (given as a pandas dataframe) and metadata (given as a dictionary). Paths can be included to keep track of where various cycler files are located. Note: This is not the recommended way to create a BEEPDatapath , as data and metadata must have specific formats to load and structure correctly. Validation and structuring with BEEPDatapath s \u00b6 *Datapath.validate() \u00b6 Validate your raw data. Will return true if the raw data is valid for your cycler (i.e., can be structured successfully). from beep.structure import IndigoDatapath datapath = IndigoDatapath . from_file ( \"/path/to/my_indigo_file\" ) is_valid = datapath . validate () print ( is_valid ) # Out: # True or False *Datapath.structure(*args) \u00b6 Interpolate and structure your data using specified arguments. Once structured, your BEEPDatapath is able to access things like the diagnostic summary, interpolated cycles, cycle summary, diagnostic summary, cycle life, and more (see Analysis and attributes of core attributes of BEEPDatapath ) from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" ) # Structure your data by manually specifying parameters. datapath . structure ( v_range = [ 1.2 , 3.5 ], nominal_capacity = 1.2 , full_fast_charge = 0.85 ) *Datapath.autostructure() \u00b6 Run structuring using automatically determined parameters. BEEP can automatically detect the structuring parameters based on your raw data. Note: The BEEP environment variable BEEP_PROCESSING_DIR must be set before autostructuring, and this directory must contain a parameters file which can be used for determine_structuring_parameters . from beep.structure import BiologicDatapath datapath = BiologicDatapath . from_file ( \"path/to/my/biologic_data_file\" ) # Automatically determines structuring parameters and structures data datapath . autostructure () Analysis and core attributes of BEEPDatapath \u00b6 *Datapath.paths \u00b6 Access all paths of files related to this datapath. paths is a simple mapping of {file_description: file_path} which holds the paths of all files related to this datapath, including raw data, metadata, EIS files, and structured outputs. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . paths ) # Out: { \"raw\" : \"/path/to/my_arbin_file.csv\" , \"metadata\" : \"/path/to/my_arbin_file_Metadata.csv\" } *Datapath.raw_data \u00b6 The raw data, loaded into a standardized dataframe format, of this datapath's battery cycler data. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . raw_data ) # Out: data_point test_time ... temperature date_time_iso 0 0 0.0021 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 1 1 1.0014 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 2 2 1.1165 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 3 3 2.1174 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 4 4 12.1782 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 ... ... ... ... ... ... 251258 251258 30545.2000 ... 32.595604 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251259 251259 30545.2000 ... 32.555054 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251260 251260 30550.1970 ... 32.555054 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251261 251261 30550.1970 ... 32.545870 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251262 251262 30555.1970 ... 32.445827 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 *Datapath.metadata \u00b6 An object holding all metadata for this datapath's cycler run. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . metadata . barcode ) print ( datapath . metadata . channel_id ) print ( datapath . metadata . protocol ) print ( datapath . metadata . raw ) # Out: \"EL151000429559\" 28 '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' { 'test_id' : 296 , 'device_id' : 60369369 , 'channel_id' : 28 , 'start_datetime' : 1512445026 , '_resumed_times' : 0 , 'last_resume_datetime' : 0 , '_last_end_datetime' : 1512514129 , 'protocol' : '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' , '_databases' : 'ArbinResult_43,ArbinResult_44,ArbinResult_45,' , 'barcode' : 'EL151000429559' , '_grade_id' : 0 , '_has_aux' : 3 , '_has_special' : 0 , '_schedule_version' : 'Schedule Version 7.00.08' , '_log_aux_data_flag' : 1 , '_log_special_data_flag' : 0 , '_rowstate' : 0 , '_canconfig_filename' : nan , '_m_ncanconfigmd5' : nan , '_value' : 0.0 , '_value2' : 0.0 } *Datapath.structured_data \u00b6 The structured (interpolated) data, as a dataframe. The format is similar to that of .raw_data . The datapath must be structured before this attribute is available. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) datapath . autostructure () print ( datapath . structured_data ) # Out: voltage test_time current ... temperature cycle_index step_type 0 2.500000 NaN NaN ... NaN 0 discharge 1 2.501702 NaN NaN ... NaN 0 discharge 2 2.503403 NaN NaN ... NaN 0 discharge 3 2.505105 NaN NaN ... NaN 0 discharge 4 2.506807 NaN NaN ... NaN 0 discharge ... ... ... ... ... ... ... 461995 NaN NaN NaN ... NaN 245 charge 461996 NaN NaN NaN ... NaN 245 charge 461997 NaN NaN NaN ... NaN 245 charge 461998 NaN NaN NaN ... NaN 245 charge 461999 NaN NaN NaN ... NaN 245 charge *Datapath.structured_summary \u00b6 A summary of the structured cycler data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . structured_summary ) # Out: cycle_index discharge_capacity charge_capacity discharge_energy charge_energy dc_internal_resistance temperature_maximum temperature_average temperature_minimum date_time_iso energy_efficiency charge_throughput energy_throughput charge_duration time_temperature_integrated paused cycle_index 0 0 4.719281 3.827053 17.273731 14.901985 0.0 NaN NaN NaN 2019 - 12 - 17 T17 : 51 : 51 + 00 : 00 1.159156 3.827053 14.901985 NaN NaN 4957 6 6 2.074518 4.406801 7.677041 16.997186 0.0 NaN NaN NaN 2019 - 12 - 20 T13 : 14 : 40 + 00 : 00 0.451665 8.233854 31.899172 5791.0 NaN 0 7 7 2.097911 2.108322 7.775166 8.597635 0.0 NaN NaN NaN 2019 - 12 - 20 T15 : 51 : 34 + 00 : 00 0.904338 10.342176 40.496807 NaN NaN 0 8 8 2.074545 2.098428 7.684986 8.557546 0.0 NaN NaN NaN 2019 - 12 - 20 T17 : 32 : 21 + 00 : 00 0.898036 12.440605 49.054352 NaN NaN 0 9 9 2.074061 2.082069 7.685348 8.494265 0.0 NaN NaN NaN 2019 - 12 - 20 T19 : 12 : 46 + 00 : 00 0.904769 14.522674 57.548618 NaN NaN 0 10 10 2.065671 2.069061 7.655246 8.441246 0.0 NaN NaN NaN 2019 - 12 - 20 T20 : 52 : 53 + 00 : 00 0.906886 16.591734 65.989861 NaN NaN 0 11 11 2.064542 2.068921 7.651949 8.439011 0.0 NaN NaN NaN 2019 - 12 - 20 T22 : 32 : 38 + 00 : 00 0.906735 18.660656 74.428871 NaN NaN 0 12 12 2.068333 2.061454 7.666199 8.409441 0.0 NaN NaN NaN 2019 - 12 - 21 T00 : 12 : 35 + 00 : 00 0.911618 20.722109 82.838318 NaN NaN 0 13 13 2.054566 2.067370 7.616584 8.431127 0.0 NaN NaN NaN 2019 - 12 - 21 T01 : 52 : 14 + 00 : 00 0.903389 22.789478 91.269440 NaN NaN 0 14 14 2.061369 2.057715 7.647454 8.394535 0.0 NaN NaN NaN 2019 - 12 - 21 T03 : 31 : 54 + 00 : 00 0.911004 24.847195 99.663979 NaN NaN 0 15 15 2.050721 2.059819 7.602874 8.401562 0.0 NaN NaN NaN 2019 - 12 - 21 T05 : 11 : 24 + 00 : 00 0.904936 26.907013 108.065536 NaN NaN 0 16 16 2.055427 2.057405 7.622452 8.393292 0.0 NaN NaN NaN 2019 - 12 - 21 T06 : 50 : 57 + 00 : 00 0.908160 28.964418 116.458832 NaN NaN 0 17 17 2.045344 2.049606 7.583858 8.360918 0.0 NaN NaN NaN 2019 - 12 - 21 T08 : 30 : 36 + 00 : 00 0.907060 31.014025 124.819748 NaN NaN 0 18 18 2.047280 2.046608 7.591624 8.347446 0.0 NaN NaN NaN 2019 - 12 - 21 T10 : 09 : 56 + 00 : 00 0.909455 33.060631 133.167191 NaN NaN 0 19 19 2.055454 2.046478 7.623849 8.347916 0.0 NaN NaN NaN 2019 - 12 - 21 T11 : 49 : 18 + 00 : 00 0.913264 35.107109 141.515106 NaN NaN 0 20 20 2.043676 2.055780 7.579766 8.383341 0.0 NaN NaN NaN 2019 - 12 - 21 T13 : 28 : 39 + 00 : 00 0.904146 37.162891 149.898453 NaN NaN 0 21 21 2.049323 2.046085 7.605977 8.346517 0.0 NaN NaN NaN 2019 - 12 - 21 T15 : 08 : 10 + 00 : 00 0.911276 39.208977 158.244965 NaN NaN 0 22 22 2.038514 2.047097 7.560916 8.349430 0.0 NaN NaN NaN 2019 - 12 - 21 T16 : 47 : 22 + 00 : 00 0.905561 41.256073 166.594406 NaN NaN 0 23 23 2.044779 2.045038 7.585164 8.342201 0.0 NaN NaN NaN 2019 - 12 - 21 T18 : 26 : 38 + 00 : 00 0.909252 43.301109 174.936600 NaN NaN 0 24 24 2.039805 2.039563 7.567169 8.319416 0.0 NaN NaN NaN 2019 - 12 - 21 T20 : 06 : 10 + 00 : 00 0.909579 45.340672 183.256012 NaN NaN 0 25 25 2.039563 2.040318 7.566332 8.320876 0.0 NaN NaN NaN 2019 - 12 - 21 T21 : 45 : 20 + 00 : 00 0.909319 47.380993 191.576889 NaN NaN 0 26 26 2.052362 2.038989 7.616830 8.316606 0.0 NaN NaN NaN 2019 - 12 - 21 T23 : 24 : 33 + 00 : 00 0.915858 49.419979 199.893494 NaN NaN 0 27 27 2.035744 2.051446 7.552814 8.364671 0.0 NaN NaN NaN 2019 - 12 - 22 T01 : 03 : 48 + 00 : 00 0.902942 51.471428 208.258163 NaN NaN 0 28 28 2.039347 2.041048 7.568011 8.325755 0.0 NaN NaN NaN 2019 - 12 - 22 T02 : 43 : 14 + 00 : 00 0.908988 53.512474 216.583923 NaN NaN 0 *Datapath.diagnostic_data \u00b6 The structured (interpolated) data for diagnostic cycles, as a dataframe. The format is similar to that of .structured_data . The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_data ) # Out: voltage test_time current ... step_type discharge_dQdV charge_dQdV 0 2.700000 NaN NaN ... 0 NaN NaN 1 2.703006 NaN NaN ... 0 NaN NaN 2 2.706012 NaN NaN ... 0 NaN NaN 3 2.709018 NaN NaN ... 0 NaN NaN 4 2.712024 NaN NaN ... 0 NaN NaN ... ... ... ... ... ... ... 44434 2.782701 1958305.375 1.612107 ... 0 0.0 0.006379 44435 2.783219 1958305.375 1.612090 ... 0 0.0 0.006379 44436 2.783736 1958305.375 1.612073 ... 0 0.0 0.006379 44437 2.784254 1958305.375 1.612056 ... 0 0.0 0.006379 44438 2.784771 1958305.375 1.612039 ... 0 0.0 0.006379 [ 44439 rows x 16 columns ] *Datapath.diagnostic_summary \u00b6 A summary of the structured diagnostic cycle data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_summary ) # Out: cycle_index discharge_capacity ... paused cycle_type 0 1 4.711819 ... 0 reset 1 2 4.807243 ... 0 hppc 2 3 4.648884 ... 0 rpt_0 . 2 C 3 4 4.525516 ... 0 rpt_1C 4 5 4.482939 ... 0 rpt_2C 5 36 4.624467 ... 0 reset 6 37 4.722887 ... 0 hppc 7 38 4.584861 ... 0 rpt_0 . 2 C 8 39 4.476485 ... 0 rpt_1C 9 40 4.426849 ... 0 rpt_2C 10 141 4.529535 ... 0 reset 11 142 4.621750 ... 0 hppc 12 143 4.486644 ... 0 rpt_0 . 2 C 13 144 4.391235 ... 0 rpt_1C 14 145 4.336987 ... 0 rpt_2C 15 246 4.459362 ... 0 reset 16 247 4.459362 ... 0 hppc *Datapath.get_cycle_life(n_cycles, threshold) \u00b6 Calculate the cycle life for capacity loss below a certain threshold. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . get_cycle_life ()) # Out: 231 *Datapath.cycles_to_capacities(cycle_min, cycle_max, cycle_interval) \u00b6 Get the capacities for an array of cycles in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . cycles_to_capacities ( cycle_min = 50 , cycle_max = 200 , cycle_interval = 50 )) # Out: cycle_50 cycle_100 cycle_150 0 2.020498 1.981053 1.965753 *Datapath.capacities_to_cycles(thresh_max_cap, thresh_min_cap, interval_cap) \u00b6 Get the number of cycles to reach an array of threshold capacities in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . capacities_to_cycles ()) # Out: capacity_0 . 98 capacity_0 . 95 capacity_0 . 92 capacity_0 . 89 capacity_0 . 86 capacity_0 . 83 capacity_0 . 8 0 76 185 231 231 231 231 231 *Datapath.is_structured \u00b6 Tells whether the datapath has been structured or not. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) print ( datapath . is_structured ) # Out: False datapath . structure () print ( datapath . is_structured ) # Out: True Making your own BEEPDatapath \u00b6 If your cycler is not already supported by BEEP, you can write a class for structuring its data with BEEP by inheriting BEEPDatapath and implementing one method: from_file . from beep.structure import BEEPDatapath class MyCustomCyclerDatapath ( BEEPDatapath ): \"\"\"An example of implementing a custom BEEPDatapath for your own cycler. \"\"\" @classmethod def from_file ( cls , filename ): # Load your file from the raw file filename data = pd . read_csv ( filename ) # Parse the raw data # The raw data must adhere to BEEP standards. See the beep/conversion_schemas for the list of canonical data columns the raw data dataframe must posess. # Your own code for converting the raw data to contain BEEP columns data = convert_my_custom_cycler_data_to_BEEP_dataframe ( data ) # Parse the metadata using your own code # Metadata must return a dictionary # Should preferably contain \"barcode\", \"protocol\", and \"channel_id\" keys at a minimum. metadata_filename = filename + \"_metadata\" metadata = my_metadata_parsing_function ( metadata_filename ) # Store the paths in a dictionary paths = { \"raw\" : filename , \"metadata\" : filename + \"_Metadata\" } return cls ( data , metadata , paths ) Your custom datapath class can create new methods or override existing BEEPDatapath methods if needed. Once you have written your custom class's from_file method, all the existing behavior of BEEPDatapath should be available, including structure() validate() autostructure() paths raw_data structured_summary structured_data diagnostic_data etc. Electrochemical Impedance Spectra \u00b6 More documentation for EIS coming soon! Structuring compatibility with processed legacy BEEP files \u00b6 Both legacy and *Datapath processed (structured) files saved as json should load with *Datapath.from_json_file , but the capabilities between files serialized with legacy and files serialized with newer BEEPDatapath files will differ. The main discrepancy is that legacy files cannot be restructured once loaded. All of BEEPDatapath 's other structured attributes and properties should function for legacy files identically to those serialized with newer BEEPDatapath . See the auto_load_processed documentation for more info on loading legacy processed BEEPDatapath s. Batch functions for structuring \u00b6 Aside from the CLI (shown in the command line interface guide , BEEP also contains lower-level python functions for helping loading and structuring many cycler output files in batches. process_file_list_from_json \u00b6 from beep.structure import process_file_list_from_json json_spec = { \"mode\" : 'events_off' , # mode run|test|events_off \"file_list\" : file_list , # list of file paths ['path/test1.csv', 'path/test2.csv'] 'run_list' : list ( range ( len ( file_list ))) # list of run_ids [0, 1] } # The files will automatically be serialized and saved to disk as # individual .json for each cycler run/datapath batch_result = process_file_list_from_json ( json_spec ) # Get a report of the structuring print ( batch_result ) # Out: { \"file_list\" : [ \"/path/to/your/beep/processing/data-share/structure/2017-05-12_6C-50per_3_6C_CH36_structure.json\" ], \"run_list\" : [ 0 ], \"result_list\" : [ \"success\" ], \"message_list\" : [{ \"comment\" : \"\" , \"error\" : \"\" }], \"invalid_file_list\" : [], \"mode\" : \"events_off\" } See the first tutorial for a full usage example of structuring with process_file_list_from_json . auto_load \u00b6 Auto load will look at the file signature of a raw cycler run output file and automatically load the correct datapath (provided the cycler is supported by BEEP). from beep.structure import auto_load arbin_datapath = auto_load ( \"/path/to/my_arbin_file.csv\" ) print ( arbin_datapath ) # Out: < ArbinDatapath object > maccor_datapath = auto_load ( \"/path/to/my_maccor_file\" ) print ( maccor_datapath ) # Out: < MaccorDatapath object > auto_load_processed \u00b6 Automatically loads the correct datapath for any previously serialized processed (structured) BEEP file. While processed run .json files serialized with *Datapath classes can be loaded with monty.serialization.loadfn , processed files serialized with older BEEP versions may not work with loadfn . auto_load_processed will automatically load the correct datapath, even for legacy BEEP processed .json files, though the functionality of these datapaths is restricted. For example, legacy datapaths cannot be restructured. from beep.structure import auto_load_processed arbin_datapath_processed = auto_load_processed ( \"/path/to/my_processed_arbin_file.json\" ) print ( arbin_datapath_processed ) # Out: < ArbinDatapath object > processed_datapath_legacy = auto_load_processed ( \"/path/to/my_legacy_neware_file\" ) print ( processed_datapath_legacy ) # Out: < NewareDatapath object > Featurization \u00b6 More documentation for featurization coming soon! Running and analyzing models \u00b6 More documentation for running models coming soon!","title":"Python tutorial 2: Next steps"},{"location":"tutorial2/#python-tutorial-2-next-steps","text":"Here you'll find more info about creating and using beep to do your own custom cycler analysie. BEEPDatapath - One object for ingestion, structuring, and validation Batch functions for structuring Featurization Running and analyzing models","title":"Python tutorial 2: Next steps"},{"location":"tutorial2/#structuring-with-beepdatapath","text":"","title":"Structuring with BEEPDatapath"},{"location":"tutorial2/#one-class-for-ingestion-structuring-and-validation","text":"BEEPDatapath is an abstract base class that can handle ingestion, structuring, and validation for many types of cyclers. A datapath object represents a complete processing pipeline for battery cycler data. Each cycler has it's own BEEPDatapath class: ArbinDatapath MaccorDatapath NewareDatapath IndigoDatapath BiologicDatapath All these datapaths implement the same core methods, properties, and attributes, listed below:","title":"One class for ingestion, structuring, and validation"},{"location":"tutorial2/#methods-for-loading-and-serializing-battery-cycler-data","text":"","title":"Methods for loading and serializing battery cycler data"},{"location":"tutorial2/#datapathfrom_filefilename","text":"Classmethod to load a raw cycler output file (e.g., a csv) into a datapath object. Once loaded, you can validate or structure the file. # Here we use ArbinDatapath as an example from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" )","title":"*Datapath.from_file(filename)"},{"location":"tutorial2/#datapathto_json_filefilename","text":"Dump the current state of a datapath to a file. Can be later loaded with from_json_file . from beep.structure import NewareDatapath datapath = NewareDatapath . from_file ( \"/path/to/my_raw_neware_file\" ) # do some operations ... # Write the processed file to disk, which can then be loaded. datapath . to_json_file ( \"my_processed_neware_data.json\" )","title":"*Datapath.to_json_file(filename)"},{"location":"tutorial2/#datapathfrom_json_filefilename","text":"Classmethod to load a processed cycler file (e.g., a previously structured Datapath) into a datapath object. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_json_file ( \"my_previously_serialized_datapath.json\" )","title":"*Datapath.from_json_file(filename)"},{"location":"tutorial2/#datapathdata-metadata-pathsnone-kwargs","text":"Initialize any cycler from the raw data (given as a pandas dataframe) and metadata (given as a dictionary). Paths can be included to keep track of where various cycler files are located. Note: This is not the recommended way to create a BEEPDatapath , as data and metadata must have specific formats to load and structure correctly.","title":"*Datapath(data, metadata, paths=None, **kwargs)"},{"location":"tutorial2/#validation-and-structuring-with-beepdatapaths","text":"","title":"Validation and structuring with BEEPDatapaths"},{"location":"tutorial2/#datapathvalidate","text":"Validate your raw data. Will return true if the raw data is valid for your cycler (i.e., can be structured successfully). from beep.structure import IndigoDatapath datapath = IndigoDatapath . from_file ( \"/path/to/my_indigo_file\" ) is_valid = datapath . validate () print ( is_valid ) # Out: # True or False","title":"*Datapath.validate()"},{"location":"tutorial2/#datapathstructureargs","text":"Interpolate and structure your data using specified arguments. Once structured, your BEEPDatapath is able to access things like the diagnostic summary, interpolated cycles, cycle summary, diagnostic summary, cycle life, and more (see Analysis and attributes of core attributes of BEEPDatapath ) from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"my_arbin_file.csv\" ) # Structure your data by manually specifying parameters. datapath . structure ( v_range = [ 1.2 , 3.5 ], nominal_capacity = 1.2 , full_fast_charge = 0.85 )","title":"*Datapath.structure(*args)"},{"location":"tutorial2/#datapathautostructure","text":"Run structuring using automatically determined parameters. BEEP can automatically detect the structuring parameters based on your raw data. Note: The BEEP environment variable BEEP_PROCESSING_DIR must be set before autostructuring, and this directory must contain a parameters file which can be used for determine_structuring_parameters . from beep.structure import BiologicDatapath datapath = BiologicDatapath . from_file ( \"path/to/my/biologic_data_file\" ) # Automatically determines structuring parameters and structures data datapath . autostructure ()","title":"*Datapath.autostructure()"},{"location":"tutorial2/#analysis-and-core-attributes-of-beepdatapath","text":"","title":"Analysis and core attributes of BEEPDatapath"},{"location":"tutorial2/#datapathpaths","text":"Access all paths of files related to this datapath. paths is a simple mapping of {file_description: file_path} which holds the paths of all files related to this datapath, including raw data, metadata, EIS files, and structured outputs. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . paths ) # Out: { \"raw\" : \"/path/to/my_arbin_file.csv\" , \"metadata\" : \"/path/to/my_arbin_file_Metadata.csv\" }","title":"*Datapath.paths"},{"location":"tutorial2/#datapathraw_data","text":"The raw data, loaded into a standardized dataframe format, of this datapath's battery cycler data. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . raw_data ) # Out: data_point test_time ... temperature date_time_iso 0 0 0.0021 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 1 1 1.0014 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 2 2 1.1165 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 3 3 2.1174 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 4 4 12.1782 ... 20.750711 2017 - 12 - 05 T03 : 37 : 36 + 00 : 00 ... ... ... ... ... ... 251258 251258 30545.2000 ... 32.595604 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251259 251259 30545.2000 ... 32.555054 2017 - 12 - 14 T00 : 10 : 40 + 00 : 00 251260 251260 30550.1970 ... 32.555054 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251261 251261 30550.1970 ... 32.545870 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00 251262 251262 30555.1970 ... 32.445827 2017 - 12 - 14 T00 : 12 : 48 + 00 : 00","title":"*Datapath.raw_data"},{"location":"tutorial2/#datapathmetadata","text":"An object holding all metadata for this datapath's cycler run. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) print ( datapath . metadata . barcode ) print ( datapath . metadata . channel_id ) print ( datapath . metadata . protocol ) print ( datapath . metadata . raw ) # Out: \"EL151000429559\" 28 '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' { 'test_id' : 296 , 'device_id' : 60369369 , 'channel_id' : 28 , 'start_datetime' : 1512445026 , '_resumed_times' : 0 , 'last_resume_datetime' : 0 , '_last_end_datetime' : 1512514129 , 'protocol' : '2017-12-04_tests \\\\ 20170630-4_65C_69per_6C.sdu' , '_databases' : 'ArbinResult_43,ArbinResult_44,ArbinResult_45,' , 'barcode' : 'EL151000429559' , '_grade_id' : 0 , '_has_aux' : 3 , '_has_special' : 0 , '_schedule_version' : 'Schedule Version 7.00.08' , '_log_aux_data_flag' : 1 , '_log_special_data_flag' : 0 , '_rowstate' : 0 , '_canconfig_filename' : nan , '_m_ncanconfigmd5' : nan , '_value' : 0.0 , '_value2' : 0.0 }","title":"*Datapath.metadata"},{"location":"tutorial2/#datapathstructured_data","text":"The structured (interpolated) data, as a dataframe. The format is similar to that of .raw_data . The datapath must be structured before this attribute is available. from beep.structure import ArbinDatapath datapath = ArbinDatapath . from_file ( \"/path/to/my_arbin_file.csv\" ) datapath . autostructure () print ( datapath . structured_data ) # Out: voltage test_time current ... temperature cycle_index step_type 0 2.500000 NaN NaN ... NaN 0 discharge 1 2.501702 NaN NaN ... NaN 0 discharge 2 2.503403 NaN NaN ... NaN 0 discharge 3 2.505105 NaN NaN ... NaN 0 discharge 4 2.506807 NaN NaN ... NaN 0 discharge ... ... ... ... ... ... ... 461995 NaN NaN NaN ... NaN 245 charge 461996 NaN NaN NaN ... NaN 245 charge 461997 NaN NaN NaN ... NaN 245 charge 461998 NaN NaN NaN ... NaN 245 charge 461999 NaN NaN NaN ... NaN 245 charge","title":"*Datapath.structured_data"},{"location":"tutorial2/#datapathstructured_summary","text":"A summary of the structured cycler data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . structured_summary ) # Out: cycle_index discharge_capacity charge_capacity discharge_energy charge_energy dc_internal_resistance temperature_maximum temperature_average temperature_minimum date_time_iso energy_efficiency charge_throughput energy_throughput charge_duration time_temperature_integrated paused cycle_index 0 0 4.719281 3.827053 17.273731 14.901985 0.0 NaN NaN NaN 2019 - 12 - 17 T17 : 51 : 51 + 00 : 00 1.159156 3.827053 14.901985 NaN NaN 4957 6 6 2.074518 4.406801 7.677041 16.997186 0.0 NaN NaN NaN 2019 - 12 - 20 T13 : 14 : 40 + 00 : 00 0.451665 8.233854 31.899172 5791.0 NaN 0 7 7 2.097911 2.108322 7.775166 8.597635 0.0 NaN NaN NaN 2019 - 12 - 20 T15 : 51 : 34 + 00 : 00 0.904338 10.342176 40.496807 NaN NaN 0 8 8 2.074545 2.098428 7.684986 8.557546 0.0 NaN NaN NaN 2019 - 12 - 20 T17 : 32 : 21 + 00 : 00 0.898036 12.440605 49.054352 NaN NaN 0 9 9 2.074061 2.082069 7.685348 8.494265 0.0 NaN NaN NaN 2019 - 12 - 20 T19 : 12 : 46 + 00 : 00 0.904769 14.522674 57.548618 NaN NaN 0 10 10 2.065671 2.069061 7.655246 8.441246 0.0 NaN NaN NaN 2019 - 12 - 20 T20 : 52 : 53 + 00 : 00 0.906886 16.591734 65.989861 NaN NaN 0 11 11 2.064542 2.068921 7.651949 8.439011 0.0 NaN NaN NaN 2019 - 12 - 20 T22 : 32 : 38 + 00 : 00 0.906735 18.660656 74.428871 NaN NaN 0 12 12 2.068333 2.061454 7.666199 8.409441 0.0 NaN NaN NaN 2019 - 12 - 21 T00 : 12 : 35 + 00 : 00 0.911618 20.722109 82.838318 NaN NaN 0 13 13 2.054566 2.067370 7.616584 8.431127 0.0 NaN NaN NaN 2019 - 12 - 21 T01 : 52 : 14 + 00 : 00 0.903389 22.789478 91.269440 NaN NaN 0 14 14 2.061369 2.057715 7.647454 8.394535 0.0 NaN NaN NaN 2019 - 12 - 21 T03 : 31 : 54 + 00 : 00 0.911004 24.847195 99.663979 NaN NaN 0 15 15 2.050721 2.059819 7.602874 8.401562 0.0 NaN NaN NaN 2019 - 12 - 21 T05 : 11 : 24 + 00 : 00 0.904936 26.907013 108.065536 NaN NaN 0 16 16 2.055427 2.057405 7.622452 8.393292 0.0 NaN NaN NaN 2019 - 12 - 21 T06 : 50 : 57 + 00 : 00 0.908160 28.964418 116.458832 NaN NaN 0 17 17 2.045344 2.049606 7.583858 8.360918 0.0 NaN NaN NaN 2019 - 12 - 21 T08 : 30 : 36 + 00 : 00 0.907060 31.014025 124.819748 NaN NaN 0 18 18 2.047280 2.046608 7.591624 8.347446 0.0 NaN NaN NaN 2019 - 12 - 21 T10 : 09 : 56 + 00 : 00 0.909455 33.060631 133.167191 NaN NaN 0 19 19 2.055454 2.046478 7.623849 8.347916 0.0 NaN NaN NaN 2019 - 12 - 21 T11 : 49 : 18 + 00 : 00 0.913264 35.107109 141.515106 NaN NaN 0 20 20 2.043676 2.055780 7.579766 8.383341 0.0 NaN NaN NaN 2019 - 12 - 21 T13 : 28 : 39 + 00 : 00 0.904146 37.162891 149.898453 NaN NaN 0 21 21 2.049323 2.046085 7.605977 8.346517 0.0 NaN NaN NaN 2019 - 12 - 21 T15 : 08 : 10 + 00 : 00 0.911276 39.208977 158.244965 NaN NaN 0 22 22 2.038514 2.047097 7.560916 8.349430 0.0 NaN NaN NaN 2019 - 12 - 21 T16 : 47 : 22 + 00 : 00 0.905561 41.256073 166.594406 NaN NaN 0 23 23 2.044779 2.045038 7.585164 8.342201 0.0 NaN NaN NaN 2019 - 12 - 21 T18 : 26 : 38 + 00 : 00 0.909252 43.301109 174.936600 NaN NaN 0 24 24 2.039805 2.039563 7.567169 8.319416 0.0 NaN NaN NaN 2019 - 12 - 21 T20 : 06 : 10 + 00 : 00 0.909579 45.340672 183.256012 NaN NaN 0 25 25 2.039563 2.040318 7.566332 8.320876 0.0 NaN NaN NaN 2019 - 12 - 21 T21 : 45 : 20 + 00 : 00 0.909319 47.380993 191.576889 NaN NaN 0 26 26 2.052362 2.038989 7.616830 8.316606 0.0 NaN NaN NaN 2019 - 12 - 21 T23 : 24 : 33 + 00 : 00 0.915858 49.419979 199.893494 NaN NaN 0 27 27 2.035744 2.051446 7.552814 8.364671 0.0 NaN NaN NaN 2019 - 12 - 22 T01 : 03 : 48 + 00 : 00 0.902942 51.471428 208.258163 NaN NaN 0 28 28 2.039347 2.041048 7.568011 8.325755 0.0 NaN NaN NaN 2019 - 12 - 22 T02 : 43 : 14 + 00 : 00 0.908988 53.512474 216.583923 NaN NaN 0","title":"*Datapath.structured_summary"},{"location":"tutorial2/#datapathdiagnostic_data","text":"The structured (interpolated) data for diagnostic cycles, as a dataframe. The format is similar to that of .structured_data . The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_data ) # Out: voltage test_time current ... step_type discharge_dQdV charge_dQdV 0 2.700000 NaN NaN ... 0 NaN NaN 1 2.703006 NaN NaN ... 0 NaN NaN 2 2.706012 NaN NaN ... 0 NaN NaN 3 2.709018 NaN NaN ... 0 NaN NaN 4 2.712024 NaN NaN ... 0 NaN NaN ... ... ... ... ... ... ... 44434 2.782701 1958305.375 1.612107 ... 0 0.0 0.006379 44435 2.783219 1958305.375 1.612090 ... 0 0.0 0.006379 44436 2.783736 1958305.375 1.612073 ... 0 0.0 0.006379 44437 2.784254 1958305.375 1.612056 ... 0 0.0 0.006379 44438 2.784771 1958305.375 1.612039 ... 0 0.0 0.006379 [ 44439 rows x 16 columns ]","title":"*Datapath.diagnostic_data"},{"location":"tutorial2/#datapathdiagnostic_summary","text":"A summary of the structured diagnostic cycle data, as a dataframe. The datapath must be structured before this attribute is available. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file_with_diagnostic.071\" ) datapath . autostructure () print ( datapath . diagnostic_summary ) # Out: cycle_index discharge_capacity ... paused cycle_type 0 1 4.711819 ... 0 reset 1 2 4.807243 ... 0 hppc 2 3 4.648884 ... 0 rpt_0 . 2 C 3 4 4.525516 ... 0 rpt_1C 4 5 4.482939 ... 0 rpt_2C 5 36 4.624467 ... 0 reset 6 37 4.722887 ... 0 hppc 7 38 4.584861 ... 0 rpt_0 . 2 C 8 39 4.476485 ... 0 rpt_1C 9 40 4.426849 ... 0 rpt_2C 10 141 4.529535 ... 0 reset 11 142 4.621750 ... 0 hppc 12 143 4.486644 ... 0 rpt_0 . 2 C 13 144 4.391235 ... 0 rpt_1C 14 145 4.336987 ... 0 rpt_2C 15 246 4.459362 ... 0 reset 16 247 4.459362 ... 0 hppc","title":"*Datapath.diagnostic_summary"},{"location":"tutorial2/#datapathget_cycle_lifen_cycles-threshold","text":"Calculate the cycle life for capacity loss below a certain threshold. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . get_cycle_life ()) # Out: 231","title":"*Datapath.get_cycle_life(n_cycles, threshold)"},{"location":"tutorial2/#datapathcycles_to_capacitiescycle_min-cycle_max-cycle_interval","text":"Get the capacities for an array of cycles in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . cycles_to_capacities ( cycle_min = 50 , cycle_max = 200 , cycle_interval = 50 )) # Out: cycle_50 cycle_100 cycle_150 0 2.020498 1.981053 1.965753","title":"*Datapath.cycles_to_capacities(cycle_min, cycle_max, cycle_interval)"},{"location":"tutorial2/#datapathcapacities_to_cyclesthresh_max_cap-thresh_min_cap-interval_cap","text":"Get the number of cycles to reach an array of threshold capacities in an interval. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) datapath . autostructure () print ( datapath . capacities_to_cycles ()) # Out: capacity_0 . 98 capacity_0 . 95 capacity_0 . 92 capacity_0 . 89 capacity_0 . 86 capacity_0 . 83 capacity_0 . 8 0 76 185 231 231 231 231 231","title":"*Datapath.capacities_to_cycles(thresh_max_cap, thresh_min_cap, interval_cap)"},{"location":"tutorial2/#datapathis_structured","text":"Tells whether the datapath has been structured or not. from beep.structure import MaccorDatapath datapath = MaccorDatapath . from_file ( \"/path/to/my_maccor_file.071\" ) print ( datapath . is_structured ) # Out: False datapath . structure () print ( datapath . is_structured ) # Out: True","title":"*Datapath.is_structured"},{"location":"tutorial2/#making-your-own-beepdatapath","text":"If your cycler is not already supported by BEEP, you can write a class for structuring its data with BEEP by inheriting BEEPDatapath and implementing one method: from_file . from beep.structure import BEEPDatapath class MyCustomCyclerDatapath ( BEEPDatapath ): \"\"\"An example of implementing a custom BEEPDatapath for your own cycler. \"\"\" @classmethod def from_file ( cls , filename ): # Load your file from the raw file filename data = pd . read_csv ( filename ) # Parse the raw data # The raw data must adhere to BEEP standards. See the beep/conversion_schemas for the list of canonical data columns the raw data dataframe must posess. # Your own code for converting the raw data to contain BEEP columns data = convert_my_custom_cycler_data_to_BEEP_dataframe ( data ) # Parse the metadata using your own code # Metadata must return a dictionary # Should preferably contain \"barcode\", \"protocol\", and \"channel_id\" keys at a minimum. metadata_filename = filename + \"_metadata\" metadata = my_metadata_parsing_function ( metadata_filename ) # Store the paths in a dictionary paths = { \"raw\" : filename , \"metadata\" : filename + \"_Metadata\" } return cls ( data , metadata , paths ) Your custom datapath class can create new methods or override existing BEEPDatapath methods if needed. Once you have written your custom class's from_file method, all the existing behavior of BEEPDatapath should be available, including structure() validate() autostructure() paths raw_data structured_summary structured_data diagnostic_data etc.","title":"Making your own BEEPDatapath"},{"location":"tutorial2/#electrochemical-impedance-spectra","text":"More documentation for EIS coming soon!","title":"Electrochemical Impedance Spectra"},{"location":"tutorial2/#structuring-compatibility-with-processed-legacy-beep-files","text":"Both legacy and *Datapath processed (structured) files saved as json should load with *Datapath.from_json_file , but the capabilities between files serialized with legacy and files serialized with newer BEEPDatapath files will differ. The main discrepancy is that legacy files cannot be restructured once loaded. All of BEEPDatapath 's other structured attributes and properties should function for legacy files identically to those serialized with newer BEEPDatapath . See the auto_load_processed documentation for more info on loading legacy processed BEEPDatapath s.","title":"Structuring compatibility with processed legacy BEEP files"},{"location":"tutorial2/#batch-functions-for-structuring","text":"Aside from the CLI (shown in the command line interface guide , BEEP also contains lower-level python functions for helping loading and structuring many cycler output files in batches.","title":"Batch functions for structuring"},{"location":"tutorial2/#process_file_list_from_json","text":"from beep.structure import process_file_list_from_json json_spec = { \"mode\" : 'events_off' , # mode run|test|events_off \"file_list\" : file_list , # list of file paths ['path/test1.csv', 'path/test2.csv'] 'run_list' : list ( range ( len ( file_list ))) # list of run_ids [0, 1] } # The files will automatically be serialized and saved to disk as # individual .json for each cycler run/datapath batch_result = process_file_list_from_json ( json_spec ) # Get a report of the structuring print ( batch_result ) # Out: { \"file_list\" : [ \"/path/to/your/beep/processing/data-share/structure/2017-05-12_6C-50per_3_6C_CH36_structure.json\" ], \"run_list\" : [ 0 ], \"result_list\" : [ \"success\" ], \"message_list\" : [{ \"comment\" : \"\" , \"error\" : \"\" }], \"invalid_file_list\" : [], \"mode\" : \"events_off\" } See the first tutorial for a full usage example of structuring with process_file_list_from_json .","title":"process_file_list_from_json"},{"location":"tutorial2/#auto_load","text":"Auto load will look at the file signature of a raw cycler run output file and automatically load the correct datapath (provided the cycler is supported by BEEP). from beep.structure import auto_load arbin_datapath = auto_load ( \"/path/to/my_arbin_file.csv\" ) print ( arbin_datapath ) # Out: < ArbinDatapath object > maccor_datapath = auto_load ( \"/path/to/my_maccor_file\" ) print ( maccor_datapath ) # Out: < MaccorDatapath object >","title":"auto_load"},{"location":"tutorial2/#auto_load_processed","text":"Automatically loads the correct datapath for any previously serialized processed (structured) BEEP file. While processed run .json files serialized with *Datapath classes can be loaded with monty.serialization.loadfn , processed files serialized with older BEEP versions may not work with loadfn . auto_load_processed will automatically load the correct datapath, even for legacy BEEP processed .json files, though the functionality of these datapaths is restricted. For example, legacy datapaths cannot be restructured. from beep.structure import auto_load_processed arbin_datapath_processed = auto_load_processed ( \"/path/to/my_processed_arbin_file.json\" ) print ( arbin_datapath_processed ) # Out: < ArbinDatapath object > processed_datapath_legacy = auto_load_processed ( \"/path/to/my_legacy_neware_file\" ) print ( processed_datapath_legacy ) # Out: < NewareDatapath object >","title":"auto_load_processed"},{"location":"tutorial2/#featurization","text":"More documentation for featurization coming soon!","title":"Featurization"},{"location":"tutorial2/#running-and-analyzing-models","text":"More documentation for running models coming soon!","title":"Running and analyzing models"}]}
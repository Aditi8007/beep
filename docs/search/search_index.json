{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 BEEP is a set of tools designed to support Battery Evaluation and Early Prediction of cycle life corresponding to the research of the d3batt program and the Toyota Research Institute . BEEP enables parsing and handing of electrochemical battery cycling data via data objects reflecting cycling run data, experimental protocols, featurization, and modeling of cycle life. Currently beep supports arbin, maccor and biologic cyclers. We are currently looking for experienced python developers to help us improve this package and implement new features. Please contact any of the maintainers for more information. Installation \u00b6 To a base install, do: pip install beep If you want to develop BEEP and run tests, clone the repo via git and use pip (or python setup.py develop ) for an editable install: git clone git@github.com:ToyotaResearchInstitute/BEEP.git cd BEEP pip install -e . [ tests ] Environment \u00b6 To configure the use of AWS resources its necessary to set the environment variable BEEP_ENV . For most users 'dev' is the appropriate choice since it assumes that no AWS resources are available. export BEEP_ENV = 'dev' For processing file locally its necessary to configure the folder structure export BEEP_PROCESSING_DIR = '/path/to/beep/data/' Testing \u00b6 Make sure you have installed the required testing packages (see installation). You can use pytest for running unittests. In order to run tests the environment variable needs to be set (i.e. export BEEP_ENV='dev' ) pytest beep How to cite \u00b6 If you use BEEP, please cite this article: P. Herring, C. Balaji Gopal, M. Aykol, J.H. Montoya, A. Anapolsky, P.M. Attia, W. Gent, J.S. Hummelsh\u00f8j, L. Hung, H.-K. Kwon, P. Moore, D. Schweigert, K.A. Severson, S. Suram, Z. Yang, R.D. Braatz, B.D. Storey, SoftwareX 11 (2020) 100506. https://doi.org/10.1016/j.softx.2020.100506","title":"Introduction"},{"location":"#introduction","text":"BEEP is a set of tools designed to support Battery Evaluation and Early Prediction of cycle life corresponding to the research of the d3batt program and the Toyota Research Institute . BEEP enables parsing and handing of electrochemical battery cycling data via data objects reflecting cycling run data, experimental protocols, featurization, and modeling of cycle life. Currently beep supports arbin, maccor and biologic cyclers. We are currently looking for experienced python developers to help us improve this package and implement new features. Please contact any of the maintainers for more information.","title":"Introduction"},{"location":"#installation","text":"To a base install, do: pip install beep If you want to develop BEEP and run tests, clone the repo via git and use pip (or python setup.py develop ) for an editable install: git clone git@github.com:ToyotaResearchInstitute/BEEP.git cd BEEP pip install -e . [ tests ]","title":"Installation"},{"location":"#environment","text":"To configure the use of AWS resources its necessary to set the environment variable BEEP_ENV . For most users 'dev' is the appropriate choice since it assumes that no AWS resources are available. export BEEP_ENV = 'dev' For processing file locally its necessary to configure the folder structure export BEEP_PROCESSING_DIR = '/path/to/beep/data/'","title":"Environment"},{"location":"#testing","text":"Make sure you have installed the required testing packages (see installation). You can use pytest for running unittests. In order to run tests the environment variable needs to be set (i.e. export BEEP_ENV='dev' ) pytest beep","title":"Testing"},{"location":"#how-to-cite","text":"If you use BEEP, please cite this article: P. Herring, C. Balaji Gopal, M. Aykol, J.H. Montoya, A. Anapolsky, P.M. Attia, W. Gent, J.S. Hummelsh\u00f8j, L. Hung, H.-K. Kwon, P. Moore, D. Schweigert, K.A. Severson, S. Suram, Z. Yang, R.D. Braatz, B.D. Storey, SoftwareX 11 (2020) 100506. https://doi.org/10.1016/j.softx.2020.100506","title":"How to cite"},{"location":"cli/","text":"Commands \u00b6 Introduction \u00b6 BEEP provides a command line interface for easier usage of the BEEP pipeline. There are five main steps to the BEEP pipeline: Collation: logically organize your data from various battery cycler machines and experiments Validation: check that BEEP will be able to run on your data Structuring: convert cycler outputs into a minimal, universal format Featurization: adding features for machine learning Run model: run a machine learning model to predict battery lifetimes. Each command accepts a JSON string as input in order to provide flexibility and better automation. collate : standardize filenames among many cyclers/runs \u00b6 The collate script takes no input, and operates by assuming the BEEP_PROCESSING_DIR (default / ) has subdirectories /data-share/raw_cycler_files and data-share/renamed_cycler_files/FastCharge . The script moves files from the /data-share/raw_cycler_files directory, parses the metadata, and renames them according to a combination of protocol, channel number, and date, placing them in /data-share/renamed_cycler_files . The script output is a json string that contains the following fields: fid - The file id used internally for renaming filename - full paths for raw cycler filenames strname - the string name associated with the file (i. e. scrubbed of csv ) file_list - full paths for the new, renamed, cycler files protocol - the cycling protocol corresponding to each file channel_no - the channel number corresponding to each file date - the date corresponding to each file Example: $ collate { \"mode\" : \"events_off\" , \"fid\" : [ 0 , 1 , 2 ], \"strname\" : [ \"2017-05-09_test-TC-contact\" , \"2017-08-14_8C-5per_3_47C\" , \"2017-12-04_4_65C-69per_6C\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], \"protocol\" : [ null , \"8C(5%)-3.47C\" , \"4.65C(69%)-6C\" ], \"date\" : [ \"2017-05-09\" , \"2017-08-14\" , \"2017-12-04\" ], \"channel_no\" : [ \"CH33\" , \"CH44\" , \"CH29\" ], \"filename\" : [ \"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\" , \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\" , \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\" ] } validate : ensure your data is valid \u00b6 The validation script, validate , runs the validation procedure contained in beep.validate on renamed files according to the output of rename above. It also updates a general json validation record in /data-share/validation/validation.json . The input json must contain the following fields file_list - the list of filenames to be validated mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json will have the following fields: validity - a list of validation results, e. g. [\"valid\", \"valid\", \"invalid\"] file_list - a list of full path filenames which have been processed Example: $ validate '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"strname\": [\"2017-05-09_test-TC-contact\", \"2017-08-14_8C-5per_3_47C\", \"2017-12-04_4_65C-69per_6C\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"], \"protocol\": [null, \"8C(5%)-3.47C\", \"4.65C(69%)-6C\"], \"date\": [\"2017-05-09\", \"2017-08-14\", \"2017-12-04\"], \"channel_no\": [\"CH33\", \"CH44\", \"CH29\"], \"filename\": [\"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\", \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\", \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\"] }' { \"validity\" : [ \"invalid\" , \"invalid\" , \"valid\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], } structure : convert cycler data to universal formats \u00b6 The structure script will run the data structuring on specified filenames corresponding to validated raw cycler files. It places the structured datafiles in /data-share/structure . The input json must contain the following fields: * file_list - a list of full path filenames which have been processed * validity - a list of boolean validation results, e. g. [True, True, False] * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json contains the following fields: invalid_file_list - a list of invalid files according to the validity file_list - a list of files which have been structured into processed_cycler_runs Example: $ structure '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"validity\": [\"invalid\", \"invalid\", \"valid\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"]}' { \"invalid_file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" ], \"file_list\" : [ \"/data-share/structure/FastCharge_2_CH29_structure.json\" ], } featurize : add features for machine learning \u00b6 The featurize script will generate features according to the methods contained in beep.generate_features. It places output files corresponding to features in /data-share/features/ . The input json must contain the following fields file_list - a list of processed cycler runs for which to generate features mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json file will contain the following: file_list - a list of filenames corresponding to the locations of the features Example: $ featurize '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"invalid_file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\"], \"file_list\": [\"/data-share/structure/FastCharge_2_CH29_structure.json\"] }' { \"file_list\" : [ \"/data-share/features/FastCharge_2_CH29_full_model_features.json\" ]} run_model : run a machine learning model \u00b6 The run_model script will generate a model and create predictions based on the features previously generated by the generate_features. It stores its outputs in /data-share/predictions/ The input json must contain the following fields * file_list - list of files corresponding to model features * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json will contain the following fields * file_list - list of files corresponding to model predictions Example: $ run_model '{ \"mode\": \"events_off\", \"run_list\": [34], \"file_list\": [\"/data-share/features/FastCharge_2_CH29_full_model_features.json\"] }' { \"file_list\" : [ \"/data-share/predictions/FastCharge_2_CH29_full_model_predictions.json\" ], }","title":"Commands"},{"location":"cli/#commands","text":"","title":"Commands"},{"location":"cli/#introduction","text":"BEEP provides a command line interface for easier usage of the BEEP pipeline. There are five main steps to the BEEP pipeline: Collation: logically organize your data from various battery cycler machines and experiments Validation: check that BEEP will be able to run on your data Structuring: convert cycler outputs into a minimal, universal format Featurization: adding features for machine learning Run model: run a machine learning model to predict battery lifetimes. Each command accepts a JSON string as input in order to provide flexibility and better automation.","title":"Introduction"},{"location":"cli/#collate-standardize-filenames-among-many-cyclersruns","text":"The collate script takes no input, and operates by assuming the BEEP_PROCESSING_DIR (default / ) has subdirectories /data-share/raw_cycler_files and data-share/renamed_cycler_files/FastCharge . The script moves files from the /data-share/raw_cycler_files directory, parses the metadata, and renames them according to a combination of protocol, channel number, and date, placing them in /data-share/renamed_cycler_files . The script output is a json string that contains the following fields: fid - The file id used internally for renaming filename - full paths for raw cycler filenames strname - the string name associated with the file (i. e. scrubbed of csv ) file_list - full paths for the new, renamed, cycler files protocol - the cycling protocol corresponding to each file channel_no - the channel number corresponding to each file date - the date corresponding to each file Example: $ collate { \"mode\" : \"events_off\" , \"fid\" : [ 0 , 1 , 2 ], \"strname\" : [ \"2017-05-09_test-TC-contact\" , \"2017-08-14_8C-5per_3_47C\" , \"2017-12-04_4_65C-69per_6C\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], \"protocol\" : [ null , \"8C(5%)-3.47C\" , \"4.65C(69%)-6C\" ], \"date\" : [ \"2017-05-09\" , \"2017-08-14\" , \"2017-12-04\" ], \"channel_no\" : [ \"CH33\" , \"CH44\" , \"CH29\" ], \"filename\" : [ \"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\" , \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\" , \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\" ] }","title":"collate: standardize filenames among many cyclers/runs"},{"location":"cli/#validate-ensure-your-data-is-valid","text":"The validation script, validate , runs the validation procedure contained in beep.validate on renamed files according to the output of rename above. It also updates a general json validation record in /data-share/validation/validation.json . The input json must contain the following fields file_list - the list of filenames to be validated mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json will have the following fields: validity - a list of validation results, e. g. [\"valid\", \"valid\", \"invalid\"] file_list - a list of full path filenames which have been processed Example: $ validate '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"strname\": [\"2017-05-09_test-TC-contact\", \"2017-08-14_8C-5per_3_47C\", \"2017-12-04_4_65C-69per_6C\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"], \"protocol\": [null, \"8C(5%)-3.47C\", \"4.65C(69%)-6C\"], \"date\": [\"2017-05-09\", \"2017-08-14\", \"2017-12-04\"], \"channel_no\": [\"CH33\", \"CH44\", \"CH29\"], \"filename\": [\"/data-share/raw_cycler_files/2017-05-09_test-TC-contact_CH33.csv\", \"/data-share/raw_cycler_files/2017-08-14_8C-5per_3_47C_CH44.csv\", \"/data-share/raw_cycler_files/2017-12-04_4_65C-69per_6C_CH29.csv\"] }' { \"validity\" : [ \"invalid\" , \"invalid\" , \"valid\" ], \"file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\" ], }","title":"validate: ensure your data is valid"},{"location":"cli/#structure-convert-cycler-data-to-universal-formats","text":"The structure script will run the data structuring on specified filenames corresponding to validated raw cycler files. It places the structured datafiles in /data-share/structure . The input json must contain the following fields: * file_list - a list of full path filenames which have been processed * validity - a list of boolean validation results, e. g. [True, True, False] * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json contains the following fields: invalid_file_list - a list of invalid files according to the validity file_list - a list of files which have been structured into processed_cycler_runs Example: $ structure '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"validity\": [\"invalid\", \"invalid\", \"valid\"], \"file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_2_CH29.csv\"]}' { \"invalid_file_list\" : [ \"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\" , \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\" ], \"file_list\" : [ \"/data-share/structure/FastCharge_2_CH29_structure.json\" ], }","title":"structure: convert cycler data to universal formats"},{"location":"cli/#featurize-add-features-for-machine-learning","text":"The featurize script will generate features according to the methods contained in beep.generate_features. It places output files corresponding to features in /data-share/features/ . The input json must contain the following fields file_list - a list of processed cycler runs for which to generate features mode - mode for events i.e. 'test' or 'run' run_list - list of run_ids for each of the files, used by the database for linking data The output json file will contain the following: file_list - a list of filenames corresponding to the locations of the features Example: $ featurize '{ \"mode\": \"events_off\", \"run_list\": [1, 20, 34], \"invalid_file_list\": [\"/data-share/renamed_cycler_files/FastCharge/FastCharge_0_CH33.csv\", \"/data-share/renamed_cycler_files/FastCharge/FastCharge_1_CH44.csv\"], \"file_list\": [\"/data-share/structure/FastCharge_2_CH29_structure.json\"] }' { \"file_list\" : [ \"/data-share/features/FastCharge_2_CH29_full_model_features.json\" ]}","title":"featurize: add features for machine learning"},{"location":"cli/#run_model-run-a-machine-learning-model","text":"The run_model script will generate a model and create predictions based on the features previously generated by the generate_features. It stores its outputs in /data-share/predictions/ The input json must contain the following fields * file_list - list of files corresponding to model features * mode - mode for events i.e. 'test' or 'run' * run_list - list of run_ids for each of the files, used by the database for linking data The output json will contain the following fields * file_list - list of files corresponding to model predictions Example: $ run_model '{ \"mode\": \"events_off\", \"run_list\": [34], \"file_list\": [\"/data-share/features/FastCharge_2_CH29_full_model_features.json\"] }' { \"file_list\" : [ \"/data-share/predictions/FastCharge_2_CH29_full_model_predictions.json\" ], }","title":"run_model: run a machine learning model"},{"location":"data/","text":"Data requirements \u00b6 BEEP automatically parses and structures data based on specific outputs from various battery cyclers. The following column headers marked \"required\" are required for downstream processing of each cycler. BEEP currently supports five brands of battery cyclers: Arbin Maccor Indigo BioLogic Neware Arbin \u00b6 Arbin data files are of the form name_of_file_CHXX.csv with an associated metadata file name_of_file_CHXX_Metadata.csv Cycler Data \u00b6 Column name (case insensitive) Required Explanation Unit Data Type data_point index of this data point int32 test_time time of data point relative to start seconds float32 datetime \u2713 time of data point relative to epoch time seconds float32 step_time elapsed time counted from the starting point of present active step seconds float32 step_index \u2713 currently running step number in the active schedule int16 cycle_index \u2713 currently active test cycle number int32 current \u2713 measured value of present channel current Amps float32 voltage \u2713 measured value of present channel voltage Volts float32 charge_capacity \u2713 cumulative value of present channel charge capacity Amp-hr float64 discharge_capacity \u2713 cumulative value of present channel discharge capacity Amp-hr float64 charge_energy \u2713 cumulative value of present channel charge energy Watt-hr float64 discharge_energy \u2713 cumulative value of present channel discharge energy Watt-hr float64 dv/dt the first-order change rate of voltage Volts/seconds float32 internal_resistance calculated internal resistance Ohms float32 temperature cell temperature \u00b0Celsius float32 Metadata \u00b6 Field name Required test_id device_id iv_ch_id first_start_datetime schedule_file_name item_id resumed_times last_end_datetime databases grade_id has_aux has_special schedule_version log_aux_data_flag log_special_data_flag rowstate canconfig_filename m_ncanconfigmd5 value value2 Maccor \u00b6 Maccor files are single tabular text files matching the regex pattern \".*\\\\d{5,6}.*\\\\d{3}\" . Column name (case insensitive) Required Explanation Unit Data Type rec# \u2713 data point number (index) int32 cyc# \u2713 cycle number int32 step \u2713 step number int16 test (sec) \u2713 total time elapsed seconds float32 step (sec) \u2713 time within this step seconds float32 amp-hr \u2713 charge capacity Amp-hr float64 watt-hr \u2713 charge energy Watt-hr float64 amps \u2713 channel current Amps float32 volts \u2713 channel voltage Volts float32 state \u2713 charging/discharging/etc. state of the battery category es \u2713 category dpt time \u2713 date and time of data point Date-Time str acimp/ohms \u2713 AC impedance of circuit Ohm float32 dcir/ohms \u2713 DC internal resistance Ohm float32 wf chg cap \u2713 charge capacity (based on waveform, if available) Amp-hh float32 wf dis cap \u2713 discharge capacity (based on waveform, if available) Amp-hr float32 wf chg e \u2713 charge energy (based on waveform, if available) Watt-hr float32 wf dis e \u2713 discharge energy (based on waveform, if available) Watt-hr float32 range \u2713 uint8 var1 \u2713 float16 var2 \u2713 float16 var3 \u2713 float16 var4 \u2713 float16 var5 \u2713 float16 var6 \u2713 float16 var7 \u2713 float16 var8 \u2713 float16 var9 \u2713 float16 var10 \u2713 float16 var11 \u2713 float16 var12 \u2713 float16 var13 \u2713 float16 var14 \u2713 float16 var15 \u2713 float16 Indigo \u00b6 Indigo files are single hierarchical data files ( *.h5 ) with the mandatory group store field \"time_series_data\" . Column name (case insensitive) Required Explanation Unit Data Type cell_coulomb_count_c \u2713 instantaneous cell charge Coulombs cell_current_a \u2713 A cell_energy_j \u2713 cell energy Joules cell_id \u2713 identifier of the cell cell_power_w instantaneous cell power Watts cell_temperature_c temperature of the cell \u00b0Celsius cell_voltage_v \u2713 voltage of the cell Volts cycle_count \u2713 index of the cycle experiment_count index of the experiment experiment_type half_cycle_count \u2713 system_time_us \u2713 test time of data point relative to epoch microseconds time_s time elapsed since test beginning seconds BioLogic \u00b6 BioLogic files are ASCII text files of the form *.mpt with matching *.mpl log/metadata files. BioLogic cycler data is currently only supported for raw operations (e.g., ingestion via RawCyclerRun analysis) and is not supported for downstream processing. Column name Required Explanation Unit Data Type cycle number \u2713 index of this cycle int half cycle \u2713 int Ecell/V \u2713 cell potential Volts float I/mA \u2713 cell current mAmps float Q discharge/mA.h \u2713 discharge capacity mAmp-hr float Q charge/mA.h \u2713 charge capacty mAmp-hr float Energy charge/W.h \u2713 charge energy Watt-hr float Energy discharge/W.h \u2713 discharge energy Watt-hr float Various other fields in BioLogic data or metadata files are not required. Neware \u00b6 Neware files are singular *.csv files. Note: Neware files use non-standard csv formatting; some fields may require further processing or structuring before input to beep . Column name Required Explanation Unit Data Type Record ID \u2713 index of this data point int32 Realtime \u2713 date-time format for this point Time(h:min:s.ms) \u2713 recorded time for this point seconds float32 Step ID \u2713 index of this step int16 Cycle ID \u2713 index of this cycle int32 Current(mA) \u2713 cell current mAmps float32 Voltage(V) \u2713 cell voltage Volts float32 Capacitance_Chg(mAh) \u2713 charge capacity mAmp-hr float64 Capacitance_DChg(mAh) \u2713 discharge capacity mAmp-hr float64 Engy_Chg(mWh) \u2713 charge energy mWatt-hr float64 Engy_DChg(mWh) \u2713 discharge energy mWatt-hr float64 DCIR(O) \u2713 DC internal resistance float32 Capacity(mAh) \u2713 mAmp-hr Capacity Density(mAh/g) \u2713 mAmp-hr/gram Energy(mWh) \u2713 mWatt-hr CmpEng(mWh/g) \u2713 mWatt-hr/gram Min-T(C) \u2713 mimumum cell temperature \u00b0Celsius Max-T(C) \u2713 max cell temperature \u00b0Celsius Avg-T(C) \u2713 average cell temperature \u00b0Celsius Power(mW) \u2713 instantaneous power mWatt dQ/dV(mAh/V) \u2713 differential capacity mAmp-hr/Volt dQm/dV(mAh/V.g) \u2713 differential capacity density mAmp-hr/Volt-gram Temperature(C) \u2713 temperature (alternate sensor) \u00b0Celsius float32","title":"Data requirements"},{"location":"data/#data-requirements","text":"BEEP automatically parses and structures data based on specific outputs from various battery cyclers. The following column headers marked \"required\" are required for downstream processing of each cycler. BEEP currently supports five brands of battery cyclers: Arbin Maccor Indigo BioLogic Neware","title":"Data requirements"},{"location":"data/#arbin","text":"Arbin data files are of the form name_of_file_CHXX.csv with an associated metadata file name_of_file_CHXX_Metadata.csv","title":"Arbin"},{"location":"data/#cycler-data","text":"Column name (case insensitive) Required Explanation Unit Data Type data_point index of this data point int32 test_time time of data point relative to start seconds float32 datetime \u2713 time of data point relative to epoch time seconds float32 step_time elapsed time counted from the starting point of present active step seconds float32 step_index \u2713 currently running step number in the active schedule int16 cycle_index \u2713 currently active test cycle number int32 current \u2713 measured value of present channel current Amps float32 voltage \u2713 measured value of present channel voltage Volts float32 charge_capacity \u2713 cumulative value of present channel charge capacity Amp-hr float64 discharge_capacity \u2713 cumulative value of present channel discharge capacity Amp-hr float64 charge_energy \u2713 cumulative value of present channel charge energy Watt-hr float64 discharge_energy \u2713 cumulative value of present channel discharge energy Watt-hr float64 dv/dt the first-order change rate of voltage Volts/seconds float32 internal_resistance calculated internal resistance Ohms float32 temperature cell temperature \u00b0Celsius float32","title":"Cycler Data"},{"location":"data/#metadata","text":"Field name Required test_id device_id iv_ch_id first_start_datetime schedule_file_name item_id resumed_times last_end_datetime databases grade_id has_aux has_special schedule_version log_aux_data_flag log_special_data_flag rowstate canconfig_filename m_ncanconfigmd5 value value2","title":"Metadata"},{"location":"data/#maccor","text":"Maccor files are single tabular text files matching the regex pattern \".*\\\\d{5,6}.*\\\\d{3}\" . Column name (case insensitive) Required Explanation Unit Data Type rec# \u2713 data point number (index) int32 cyc# \u2713 cycle number int32 step \u2713 step number int16 test (sec) \u2713 total time elapsed seconds float32 step (sec) \u2713 time within this step seconds float32 amp-hr \u2713 charge capacity Amp-hr float64 watt-hr \u2713 charge energy Watt-hr float64 amps \u2713 channel current Amps float32 volts \u2713 channel voltage Volts float32 state \u2713 charging/discharging/etc. state of the battery category es \u2713 category dpt time \u2713 date and time of data point Date-Time str acimp/ohms \u2713 AC impedance of circuit Ohm float32 dcir/ohms \u2713 DC internal resistance Ohm float32 wf chg cap \u2713 charge capacity (based on waveform, if available) Amp-hh float32 wf dis cap \u2713 discharge capacity (based on waveform, if available) Amp-hr float32 wf chg e \u2713 charge energy (based on waveform, if available) Watt-hr float32 wf dis e \u2713 discharge energy (based on waveform, if available) Watt-hr float32 range \u2713 uint8 var1 \u2713 float16 var2 \u2713 float16 var3 \u2713 float16 var4 \u2713 float16 var5 \u2713 float16 var6 \u2713 float16 var7 \u2713 float16 var8 \u2713 float16 var9 \u2713 float16 var10 \u2713 float16 var11 \u2713 float16 var12 \u2713 float16 var13 \u2713 float16 var14 \u2713 float16 var15 \u2713 float16","title":"Maccor"},{"location":"data/#indigo","text":"Indigo files are single hierarchical data files ( *.h5 ) with the mandatory group store field \"time_series_data\" . Column name (case insensitive) Required Explanation Unit Data Type cell_coulomb_count_c \u2713 instantaneous cell charge Coulombs cell_current_a \u2713 A cell_energy_j \u2713 cell energy Joules cell_id \u2713 identifier of the cell cell_power_w instantaneous cell power Watts cell_temperature_c temperature of the cell \u00b0Celsius cell_voltage_v \u2713 voltage of the cell Volts cycle_count \u2713 index of the cycle experiment_count index of the experiment experiment_type half_cycle_count \u2713 system_time_us \u2713 test time of data point relative to epoch microseconds time_s time elapsed since test beginning seconds","title":"Indigo"},{"location":"data/#biologic","text":"BioLogic files are ASCII text files of the form *.mpt with matching *.mpl log/metadata files. BioLogic cycler data is currently only supported for raw operations (e.g., ingestion via RawCyclerRun analysis) and is not supported for downstream processing. Column name Required Explanation Unit Data Type cycle number \u2713 index of this cycle int half cycle \u2713 int Ecell/V \u2713 cell potential Volts float I/mA \u2713 cell current mAmps float Q discharge/mA.h \u2713 discharge capacity mAmp-hr float Q charge/mA.h \u2713 charge capacty mAmp-hr float Energy charge/W.h \u2713 charge energy Watt-hr float Energy discharge/W.h \u2713 discharge energy Watt-hr float Various other fields in BioLogic data or metadata files are not required.","title":"BioLogic"},{"location":"data/#neware","text":"Neware files are singular *.csv files. Note: Neware files use non-standard csv formatting; some fields may require further processing or structuring before input to beep . Column name Required Explanation Unit Data Type Record ID \u2713 index of this data point int32 Realtime \u2713 date-time format for this point Time(h:min:s.ms) \u2713 recorded time for this point seconds float32 Step ID \u2713 index of this step int16 Cycle ID \u2713 index of this cycle int32 Current(mA) \u2713 cell current mAmps float32 Voltage(V) \u2713 cell voltage Volts float32 Capacitance_Chg(mAh) \u2713 charge capacity mAmp-hr float64 Capacitance_DChg(mAh) \u2713 discharge capacity mAmp-hr float64 Engy_Chg(mWh) \u2713 charge energy mWatt-hr float64 Engy_DChg(mWh) \u2713 discharge energy mWatt-hr float64 DCIR(O) \u2713 DC internal resistance float32 Capacity(mAh) \u2713 mAmp-hr Capacity Density(mAh/g) \u2713 mAmp-hr/gram Energy(mWh) \u2713 mWatt-hr CmpEng(mWh/g) \u2713 mWatt-hr/gram Min-T(C) \u2713 mimumum cell temperature \u00b0Celsius Max-T(C) \u2713 max cell temperature \u00b0Celsius Avg-T(C) \u2713 average cell temperature \u00b0Celsius Power(mW) \u2713 instantaneous power mWatt dQ/dV(mAh/V) \u2713 differential capacity mAmp-hr/Volt dQm/dV(mAh/V.g) \u2713 differential capacity density mAmp-hr/Volt-gram Temperature(C) \u2713 temperature (alternate sensor) \u00b0Celsius float32","title":"Neware"},{"location":"tutorial/","text":"Tutorial \u00b6 This notebook is meant to demonstrate basic usage of the beep package with data from \"Data-driven prediction of battery cycle life before capacity degradation\" KA Severson, et al. Nature Energy 4 (5), 383-391 This data is available for download from https://data.matr.io/1/ . For brevity, only one test is included in this notebook but the example can easily be extended to a larger number of files. Step 0: Install beep and set environment \u00b6 If you have not already installed beep, run: pip install beep We will also need to set two environment variables for beep. BEEP_ENV : Set the compute environment for beep to use (AWS, local, etc.). We will set to dev for working locally. BEEP_PROCESSING_DIR : The central directory BEEP will use to process intermediate files and organize data. export BEEP_ENV = \"dev\" export BEEP_PROCESSING_DIR = \"tutorial\" Step 1: Download example battery cycler data \u00b6 The example data set we are using here comes from a set of A123 LFP cells cycled under fast charge conditions. While this tutorial is configured for downloading a single cell, its also possible to download the entire data set and run all of the processing steps on all of the data. Note that for Arbin files, we recommend having the metadata file in addition to the data file in order to perform the data structuring correctly (though it is not required). import os import requests print ( 'Beginning file download with requests' ) data_dir = './Severson-et-al/' try : os . makedirs ( data_dir ) except FileExistsError : pass url = 'https://data.matr.io/1/api/v1/file/5c86c0bafa2ede00015ddf70/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36.csv' ), 'wb' ) as f : f . write ( r . content ) url = 'https://data.matr.io/1/api/v1/file/5c86c0b5fa2ede00015ddf6d/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36_Metadata.csv' ), 'wb' ) as f : f . write ( r . content ) # Retrieve HTTP meta-data print ( \"Status code\" , r . status_code ) print ( \"File type recieved\" , r . headers [ 'content-type' ]) print ( \"File encoding\" , r . encoding ) # output Beginning file download with requests Status code 200 File type recieved text / csv File encoding ISO - 8859 - 1 You should now have two files in your data directory: \u251c\u2500\u2500 Severson-et-al \u2502 \u251c\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36.csv \u2502 \u2514\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36_Metadata.csv Step 2: Data pipelining - validation, structuring, featurization \u00b6 Now that we have our data, we can start using BEEP! Fist, we can create a list of all of the files in the data directory and then runs the three data pipeline processing steps on each of the files. a. Validation \u00b6 This module determine if the data conforms to expected format with the correct column names and with values inside an expected range. b. Structuring \u00b6 The structuring module turns the time series data from the cycler machine into a json-like structure with DataFrame objects. The DataFrame objects include a summary DataFrame with per cycle statistics, and a DataFrame with interpolated charge and discharge steps of the regular cycles. For files that have diagnostic cycles that were programmatically inserted, separate DataFrame objects are created with summary statistics and interpolated steps for the diagnostic cycles. c. Featurization \u00b6 Featurization uses the structured objects to calculate statistically and physically relevant quantities for the purpose of building predictive machine learning models. The objects can be selected and joined for the purposes of training the model, or used for predicting individual outcomes. import json import glob # Import beep scripts from beep import validate , structure , featurize file_list = glob . glob ( os . path . join ( data_dir , '*[0-9].csv' )) mode = 'events_off' mapped = { \"mode\" : 'events_off' , # mode run|test|events_off \"file_list\" : file_list , # list of file paths ['path/test1.csv', 'path/test2.csv'] 'run_list' : list ( range ( len ( file_list ))) # list of run_ids [0, 1] } mapped = json . dumps ( mapped ) # Validation validated = validate . validate_file_list_from_json ( mapped ) validated_output = json . loads ( validated ) validated_output [ 'mode' ] = mode # mode run|test|events_off validated_output [ 'run_list' ] = list ( range ( len ( validated_output [ 'file_list' ]))) validated = json . dumps ( validated_output ) print ( validated ) # Data structuring structured = structure . process_file_list_from_json ( validated ) structured_output = json . loads ( structured ) structured_output [ 'mode' ] = mode # mode run|test|events_off structured_output [ 'run_list' ] = list ( range ( len ( file_list ))) structured = json . dumps ( structured_output ) print ( structured ) # Featurization featurized = featurize . process_file_list_from_json ( structured ) featurized_output = json . loads ( featurized ) featurized_output [ 'mode' ] = mode # mode run|test|events_off featurized_output [ 'run_list' ] = list ( range ( len ( file_list ))) featurized = json . dumps ( featurized_output ) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00, 1.74s/it] {\"file_list\": [\"./Severson-et-al/2017-05-12_6C-50per_3_6C_CH36.csv\"], \"run_list\": [0], \"validity\": [\"valid\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"mode\": \"events_off\"} 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [03:48<00:00, 3.85it/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [02:07<00:00, 6.89it/s] {\"file_list\": [\"/path/to/your/beep/processing/data-share/structure/2017-05-12_6C-50per_3_6C_CH36_structure.json\"], \"run_list\": [0], \"result_list\": [\"success\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"invalid_file_list\": [], \"mode\": \"events_off\"} Step 3: Examine data in the structure file \u00b6 Interpolation data \u00b6 The code below demonstrates how to access the DataFrame objects in the structure file. Loading the file is substantially faster than analyzing the raw time series data. The interpolated data also provides the ability to calculate differences between cycles. from matplotlib import pyplot as plt from monty.serialization import loadfn processing_dir = os . environ . get ( \"BEEP_PROCESSING_DIR\" , \"tutorial\" ) struct = loadfn ( os . path . join ( processing_dir , 'data-share' , 'structure' , '2017-05-12_6C-50per_3_6C_CH36_structure.json' )) reg_charge = struct . cycles_interpolated [ struct . cycles_interpolated . step_type == 'charge' ] print ( reg_charge . current [ reg_charge . cycle_index == 25 ] . mean ()) print ( reg_charge . cycle_index . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 25 ] . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ] . max ()) plt . plot ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ], reg_charge . voltage [ reg_charge . cycle_index == 600 ]) plt . show () # output 4.697416 876 1.1737735 1.1737735 Summary data \u00b6 The summary data provides a quick way of determine how the battery cell degrades during the cycling experiment. Quantities such as energy efficiency per cycle and total charge throughput at a given cycle number are calculated. plt . plot ( struct . summary . cycle_index , struct . summary . energy_efficiency ) plt . show () Congrats! \u00b6 You've made it to the end of the tutorial.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"This notebook is meant to demonstrate basic usage of the beep package with data from \"Data-driven prediction of battery cycle life before capacity degradation\" KA Severson, et al. Nature Energy 4 (5), 383-391 This data is available for download from https://data.matr.io/1/ . For brevity, only one test is included in this notebook but the example can easily be extended to a larger number of files.","title":"Tutorial"},{"location":"tutorial/#step-0-install-beep-and-set-environment","text":"If you have not already installed beep, run: pip install beep We will also need to set two environment variables for beep. BEEP_ENV : Set the compute environment for beep to use (AWS, local, etc.). We will set to dev for working locally. BEEP_PROCESSING_DIR : The central directory BEEP will use to process intermediate files and organize data. export BEEP_ENV = \"dev\" export BEEP_PROCESSING_DIR = \"tutorial\"","title":"Step 0: Install beep and set environment"},{"location":"tutorial/#step-1-download-example-battery-cycler-data","text":"The example data set we are using here comes from a set of A123 LFP cells cycled under fast charge conditions. While this tutorial is configured for downloading a single cell, its also possible to download the entire data set and run all of the processing steps on all of the data. Note that for Arbin files, we recommend having the metadata file in addition to the data file in order to perform the data structuring correctly (though it is not required). import os import requests print ( 'Beginning file download with requests' ) data_dir = './Severson-et-al/' try : os . makedirs ( data_dir ) except FileExistsError : pass url = 'https://data.matr.io/1/api/v1/file/5c86c0bafa2ede00015ddf70/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36.csv' ), 'wb' ) as f : f . write ( r . content ) url = 'https://data.matr.io/1/api/v1/file/5c86c0b5fa2ede00015ddf6d/download' r = requests . get ( url ) with open ( os . path . join ( data_dir , '2017-05-12_6C-50per_3_6C_CH36_Metadata.csv' ), 'wb' ) as f : f . write ( r . content ) # Retrieve HTTP meta-data print ( \"Status code\" , r . status_code ) print ( \"File type recieved\" , r . headers [ 'content-type' ]) print ( \"File encoding\" , r . encoding ) # output Beginning file download with requests Status code 200 File type recieved text / csv File encoding ISO - 8859 - 1 You should now have two files in your data directory: \u251c\u2500\u2500 Severson-et-al \u2502 \u251c\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36.csv \u2502 \u2514\u2500\u2500 2017-05-12_6C-50per_3_6C_CH36_Metadata.csv","title":"Step 1: Download example battery cycler data"},{"location":"tutorial/#step-2-data-pipelining-validation-structuring-featurization","text":"Now that we have our data, we can start using BEEP! Fist, we can create a list of all of the files in the data directory and then runs the three data pipeline processing steps on each of the files.","title":"Step 2: Data pipelining - validation, structuring, featurization"},{"location":"tutorial/#a-validation","text":"This module determine if the data conforms to expected format with the correct column names and with values inside an expected range.","title":"a. Validation"},{"location":"tutorial/#b-structuring","text":"The structuring module turns the time series data from the cycler machine into a json-like structure with DataFrame objects. The DataFrame objects include a summary DataFrame with per cycle statistics, and a DataFrame with interpolated charge and discharge steps of the regular cycles. For files that have diagnostic cycles that were programmatically inserted, separate DataFrame objects are created with summary statistics and interpolated steps for the diagnostic cycles.","title":"b. Structuring"},{"location":"tutorial/#c-featurization","text":"Featurization uses the structured objects to calculate statistically and physically relevant quantities for the purpose of building predictive machine learning models. The objects can be selected and joined for the purposes of training the model, or used for predicting individual outcomes. import json import glob # Import beep scripts from beep import validate , structure , featurize file_list = glob . glob ( os . path . join ( data_dir , '*[0-9].csv' )) mode = 'events_off' mapped = { \"mode\" : 'events_off' , # mode run|test|events_off \"file_list\" : file_list , # list of file paths ['path/test1.csv', 'path/test2.csv'] 'run_list' : list ( range ( len ( file_list ))) # list of run_ids [0, 1] } mapped = json . dumps ( mapped ) # Validation validated = validate . validate_file_list_from_json ( mapped ) validated_output = json . loads ( validated ) validated_output [ 'mode' ] = mode # mode run|test|events_off validated_output [ 'run_list' ] = list ( range ( len ( validated_output [ 'file_list' ]))) validated = json . dumps ( validated_output ) print ( validated ) # Data structuring structured = structure . process_file_list_from_json ( validated ) structured_output = json . loads ( structured ) structured_output [ 'mode' ] = mode # mode run|test|events_off structured_output [ 'run_list' ] = list ( range ( len ( file_list ))) structured = json . dumps ( structured_output ) print ( structured ) # Featurization featurized = featurize . process_file_list_from_json ( structured ) featurized_output = json . loads ( featurized ) featurized_output [ 'mode' ] = mode # mode run|test|events_off featurized_output [ 'run_list' ] = list ( range ( len ( file_list ))) featurized = json . dumps ( featurized_output ) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00, 1.74s/it] {\"file_list\": [\"./Severson-et-al/2017-05-12_6C-50per_3_6C_CH36.csv\"], \"run_list\": [0], \"validity\": [\"valid\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"mode\": \"events_off\"} 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [03:48<00:00, 3.85it/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 877/877 [02:07<00:00, 6.89it/s] {\"file_list\": [\"/path/to/your/beep/processing/data-share/structure/2017-05-12_6C-50per_3_6C_CH36_structure.json\"], \"run_list\": [0], \"result_list\": [\"success\"], \"message_list\": [{\"comment\": \"\", \"error\": \"\"}], \"invalid_file_list\": [], \"mode\": \"events_off\"}","title":"c. Featurization"},{"location":"tutorial/#step-3-examine-data-in-the-structure-file","text":"","title":"Step 3: Examine data in the structure file"},{"location":"tutorial/#interpolation-data","text":"The code below demonstrates how to access the DataFrame objects in the structure file. Loading the file is substantially faster than analyzing the raw time series data. The interpolated data also provides the ability to calculate differences between cycles. from matplotlib import pyplot as plt from monty.serialization import loadfn processing_dir = os . environ . get ( \"BEEP_PROCESSING_DIR\" , \"tutorial\" ) struct = loadfn ( os . path . join ( processing_dir , 'data-share' , 'structure' , '2017-05-12_6C-50per_3_6C_CH36_structure.json' )) reg_charge = struct . cycles_interpolated [ struct . cycles_interpolated . step_type == 'charge' ] print ( reg_charge . current [ reg_charge . cycle_index == 25 ] . mean ()) print ( reg_charge . cycle_index . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 25 ] . max ()) print ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ] . max ()) plt . plot ( reg_charge . charge_capacity [ reg_charge . cycle_index == 600 ], reg_charge . voltage [ reg_charge . cycle_index == 600 ]) plt . show () # output 4.697416 876 1.1737735 1.1737735","title":"Interpolation data"},{"location":"tutorial/#summary-data","text":"The summary data provides a quick way of determine how the battery cell degrades during the cycling experiment. Quantities such as energy efficiency per cycle and total charge throughput at a given cycle number are calculated. plt . plot ( struct . summary . cycle_index , struct . summary . energy_efficiency ) plt . show ()","title":"Summary data"},{"location":"tutorial/#congrats","text":"You've made it to the end of the tutorial.","title":"Congrats!"}]}